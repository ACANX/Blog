<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#33363b">
    <meta name="msapplication-TileColor" content="#33363b">
    
    
    
    <meta name="keywords" content="Life, ARIA, Hexo">
    
    
    <link rel="apple-touch-icon" sizes="180x180" href="/Blog/favicons/apple-touch-icon.png">
    
    
    <link rel="icon" type="image/png" sizes="192x192" href="/Blog/favicons/android-chrome-192x192.png">
    
    
    <link rel="icon" type="image/png" sizes="32x32" href="/Blog/favicons/favicon-32x32.png">
    
    
    <link rel="icon" type="image/png" sizes="16x16" href="/Blog/favicons/favicon-16x16.png">
    
    
    <link rel="mask-icon" href="/Blog/favicons/safari-pinned-tab.svg" color="#33363b">
    
    
    <link rel="manifest" href="/Blog/favicons/site.webmanifest">
    
    
    <meta name="msapplication-config" content="/Blog/favicons/browserconfig.xml">
    
    
    <link rel="alternate" href="/Blog/atom.xml" title="ACANX" type="application/atom+xml" />
    
    
    <link rel="shortcut icon" type="image/x-icon" href="/Blog/favicons/favicon.ico">
    
    
    <link rel="stylesheet" type="text/css" href="/Blog/css/normalize.css">
    <link rel="stylesheet" type="text/css" href="/Blog/css/index.css">
    
    <link rel="stylesheet" type="text/css" href="/Blog/css/sidebar.css">
    
    
<link rel="stylesheet" type="text/css" href="/Blog/css/page.css">
<link rel="stylesheet" type="text/css" href="/Blog/css/post.css">

    <link rel="stylesheet" type="text/css" href="/Blog/css/custom.css">
    <link rel="stylesheet" type="text/css" href="/Blog/css/atom-one-dark.css">
    <link rel="stylesheet" type="text/css" href="/Blog/css/lightgallery.min.css">
    <script type="text/javascript" src="/Blog/js/jquery.min.js"></script>
    <script defer type="text/javascript" src="/Blog/js/util.js"></script>
    <script defer type="text/javascript" src="/Blog/js/scrollspy.js"></script>
    <script defer type="text/javascript" src="/Blog/js/fontawesome-all.min.js"></script>
    <script defer type="text/javascript" src="/Blog/js/lightgallery.min.js"></script>
    <script defer type="text/javascript" src="/Blog/js/lg-fullscreen.min.js"></script>
    <script defer type="text/javascript" src="/Blog/js/lg-hash.min.js"></script>
    <script defer type="text/javascript" src="/Blog/js/lg-pager.min.js"></script>
    <script defer type="text/javascript" src="/Blog/js/lg-thumbnail.min.js"></script>
    <script defer type="text/javascript" src="/Blog/js/lg-zoom.min.js"></script>
    
    <script defer src="/Blog/js/busuanzi.pure.mini.js"></script>
    
    
    <script defer type="text/javascript" src="/Blog/js/search.js"></script>
    <script type="text/javascript">
    $(document).ready(function () {
      var searchPath = "search.xml";
      if (searchPath.length === 0) {
        searchPath = "search.xml";
      }
      var path = "/Blog/" + searchPath;
      searchFunc(path, "search-input", "search-result");
    });
    </script>
    
    
    <script defer type="text/javascript" src="/Blog/js/index.js"></script>
    
    <script defer type="text/javascript" src="/Blog/js/custom.js"></script>
    <title>Kubernetes集群部署实战(基于v1.32.3版本) | ACANX - 博客</title>
  <meta name="generator" content="Hexo 5.4.0"></head>
  <body itemscope itemtype="http://schema.org/WebPage" lang="zh-cn"  data-spy="scroll" data-target=".list-group">
    
<header id="header" class="header" style="background: #33363b;">
  <div class="container">
    <div class="header-container">
      <div class="header-title">
        <h1 class="title"><a href="/Blog/">ACANX</a></h1>
        <h2 class="subtitle">博客</h2>
      </div>
      <div class="logo">
        <img src="/Blog/images/ARIA_logo.png" alt="logo">
      </div>
    </div>
    
<nav id="nav" class="nav">
  <a id="nav-toggle" class="nav-toggle"><i class="fas fa-bars"></i></a>
  <ul id="menu">
    
    <li><a href="/Blog/">首页</a></li>
    
    <li><a href="/Blog/archives/">归档</a></li>
    
    <li><a href="/Blog/categories/">分类</a></li>
    
    <li><a href="/Blog/tags/">标签</a></li>
    
    <li><a href="/Blog/about/">关于</a></li>
    
  </ul>
</nav>


  </div>
</header>


    <main id="main" class="main">
      <div class="container">
        <div class="main-container">
          <div class="content">
            
<div id="post" class="post">
  
  <article class="post-container card animate" itemscope itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="https://acanx.gitee.io/Blog/2025/03/23/Kubernetes%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E5%AE%9E%E6%88%98(V1.32.3)/">
      <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
       <meta itemprop="name" content="ACANX">
       <meta itemprop="description" content="面朝大海的静态博客 <a target="_blank" rel="noopener" href="https://blog.acanx.com">另一个博客</a>">
       <meta itemprop="image" content="/Blog/images/avatar.png">
      </span>
      <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
       <meta itemprop="name" content="ACANX">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">Kubernetes集群部署实战(基于v1.32.3版本)</h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2025-03-23T10:10:00+08:00">2025-03-23 10:10:00</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/Blog/categories/Kubernetes/" itemprop="url" rel="index"><span itemprop="name">Kubernetes</span></a></span>
        </span>
        
        
      </div>
    </header>
    <main class="post-main" itemprop="articleBody">
      <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><img src="https://kubernetes.io/images/docs/components-of-kubernetes.svg" alt="components-of-kubernetes"></p>
<p><a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/concepts/overview/components/">Kubernetes集群</a>部署实战，基于Kubernetes v1.32.3、Ubuntu 24.04.2 LTS、Containerd v1.7.27版本搭建。</p>
<h2 id="1-1-前置准备"><a href="#1-1-前置准备" class="headerlink" title="1.1 前置准备"></a>1.1 前置准备</h2><h3 id="1-1-1-前置依赖软件及物料准备"><a href="#1-1-1-前置依赖软件及物料准备" class="headerlink" title="1.1.1 前置依赖软件及物料准备"></a>1.1.1 前置依赖软件及物料准备</h3><ul>
<li>服务器系统：PVE 8.1 </li>
<li>虚拟机操作系统 Ubuntu 24.04.2 LTS ISO</li>
<li>Kubernetes v1.32.3 （kubeadm、kubelet、kubectl、kube-apiserver、kube-controller-manager、kube-scheduler、kube-proxy）</li>
<li>Cri-Containerd v1.7.27    <a target="_blank" rel="noopener" href="https://github.com/containerd/containerd/releases">releases</a>       crictl</li>
<li>CoreDNS v1.11.3</li>
<li>Pause v3.10</li>
<li>Etcd v3.5.16-0</li>
<li>Calico v3.29.2</li>
<li>Nginx镜像</li>
<li>Helm v3.17.2</li>
<li>Kubernetes Dashboard v7.11.1</li>
</ul>
<h3 id="1-1-2-K8S集群网络IP规划"><a href="#1-1-2-K8S集群网络IP规划" class="headerlink" title="1.1.2 K8S集群网络IP规划"></a>1.1.2 K8S集群网络IP规划</h3><table>
<thead>
<tr>
<th align="center">节点名称</th>
<th align="center">规划IP</th>
<th align="center">当前验证实际使用IP</th>
<th align="center">备注</th>
</tr>
</thead>
<tbody><tr>
<td align="center">K8S-Master01</td>
<td align="center">10.200.10.11</td>
<td align="center">192.168.11.161</td>
<td align="center">…</td>
</tr>
<tr>
<td align="center">K8S-Master02</td>
<td align="center">10.200.10.12</td>
<td align="center"></td>
<td align="center">…</td>
</tr>
<tr>
<td align="center">K8S-Master03</td>
<td align="center">10.200.10.13</td>
<td align="center"></td>
<td align="center">…</td>
</tr>
<tr>
<td align="center">k8S-Worker01</td>
<td align="center">10.200.10.21</td>
<td align="center">192.168.11.165</td>
<td align="center">…</td>
</tr>
<tr>
<td align="center">K8S-Worker02</td>
<td align="center">10.200.10.22</td>
<td align="center">192.168.11.166</td>
<td align="center">…</td>
</tr>
<tr>
<td align="center">K8S-Worker03</td>
<td align="center">10.200.10.23</td>
<td align="center"></td>
<td align="center">…</td>
</tr>
<tr>
<td align="center">K8S-Worker04</td>
<td align="center">10.200.10.24</td>
<td align="center"></td>
<td align="center">…</td>
</tr>
<tr>
<td align="center">K8S-Worker05</td>
<td align="center">10.200.10.25</td>
<td align="center"></td>
<td align="center">…</td>
</tr>
</tbody></table>
<h3 id="1-1-3-主机硬件配置说明"><a href="#1-1-3-主机硬件配置说明" class="headerlink" title="1.1.3 主机硬件配置说明"></a>1.1.3 主机硬件配置说明</h3><table>
<thead>
<tr>
<th align="center">节点名称</th>
<th>角色</th>
<th align="center">CPU</th>
<th align="center">内存</th>
<th align="center">硬盘</th>
<th align="center">备注</th>
</tr>
</thead>
<tbody><tr>
<td align="center">K8S-Master01</td>
<td>master</td>
<td align="center">4C</td>
<td align="center">8G</td>
<td align="center">200GB</td>
<td align="center">最低4C8G</td>
</tr>
<tr>
<td align="center">k8S-Worker01</td>
<td>worker</td>
<td align="center">8C</td>
<td align="center">16G</td>
<td align="center">200GB</td>
<td align="center">最低8C16G</td>
</tr>
<tr>
<td align="center">K8S-Worker02</td>
<td>worker</td>
<td align="center">8C</td>
<td align="center">16G</td>
<td align="center">200GB</td>
<td align="center">最低8C16G</td>
</tr>
</tbody></table>
<h2 id="1-2-主机系统基础环境准备"><a href="#1-2-主机系统基础环境准备" class="headerlink" title="1.2 主机系统基础环境准备"></a>1.2 主机系统基础环境准备</h2><h3 id="1-2-1-正式安装前，系统需要检查及准备以下操作"><a href="#1-2-1-正式安装前，系统需要检查及准备以下操作" class="headerlink" title="1.2.1 正式安装前，系统需要检查及准备以下操作"></a>1.2.1 正式安装前，系统需要检查及准备以下操作</h3><ul>
<li>更新基础软件版本  </li>
<li>安装 net-tools、iputils-ping 工具，查看IP配置、网络状况</li>
<li>安装必要的编辑器</li>
<li>启用SSH连接 OpenSSH  开启SSH服务</li>
<li>支持cron定时任务</li>
<li>远程时间同步服务支持 </li>
<li>初始化系统 systemd 支持程序开机自启动</li>
<li>网络下载工具：wget、curl</li>
<li>签名校验工具gpg</li>
</ul>
<p>安装必要的软件及工具</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># sudo apt-get update</span><br>~<span class="hljs-comment"># sudo apt install net-tools iputils-ping systemd nano openssh-server cron ntpdate ipset ipvsadm debianutils tar which apt-transport-https ca-certificates curl wget gpg -y</span><br>~<span class="hljs-comment"># sudo apt-get upgrade -y</span><br></code></pre></td></tr></table></figure>



<h3 id="1-2-2-开启SSH远程登录服务"><a href="#1-2-2-开启SSH远程登录服务" class="headerlink" title="1.2.2 开启SSH远程登录服务"></a>1.2.2 开启SSH远程登录服务</h3><p>确认你的系统使用的是哪种初始化系统：</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># ps -p 1 -o comm=</span><br></code></pre></td></tr></table></figure>

<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">~$ sudo systemctl <span class="hljs-built_in">enable</span> ssh<br><br>~$ sudo systemctl start ssh<br><br>~$ sudo system status ssh      <span class="hljs-comment"># 查看ssh状态 </span><br></code></pre></td></tr></table></figure>


<h2 id="1-3-集群主机配置"><a href="#1-3-集群主机配置" class="headerlink" title="1.3 集群主机配置"></a>1.3 集群主机配置</h2><h3 id="1-3-1-主机名配置"><a href="#1-3-1-主机名配置" class="headerlink" title="1.3.1 主机名配置"></a>1.3.1 主机名配置</h3><p>由于本次使用3台主机完成kubernetes集群部署，其中1台为master节点,名称为k8s-master01;其中2台为worker节点，名称分别为：k8s-worker01及k8s-worker02</p>
<p>master01节点</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># hostnamectl set-hostname k8s-master01</span><br></code></pre></td></tr></table></figure>

<p>worker01节点</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># hostnamectl set-hostname k8s-worker01</span><br></code></pre></td></tr></table></figure>


<p>worker02节点</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># hostnamectl set-hostname k8s-worker02</span><br></code></pre></td></tr></table></figure>


<h3 id="1-3-2-主机IP地址配置"><a href="#1-3-2-主机IP地址配置" class="headerlink" title="1.3.2 主机IP地址配置"></a>1.3.2 主机IP地址配置</h3><p>k8s-master01节点IP地址为：192.168.11.161/24</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># nano /etc/netplan/50-cloud-init.yaml</span><br>root@k8s-master01:~<span class="hljs-comment"># cat /etc/netplan/50-cloud-init.yaml</span><br></code></pre></td></tr></table></figure>

<p>50-cloud-init.yaml文件中添加或修改IP地址（注意网卡名称需要与系统中的以太网卡一致）</p>
<figure class="hljs highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">network:</span><br>  <span class="hljs-attr">version:</span> <span class="hljs-number">2</span><br>  <span class="hljs-attr">renderer:</span> <span class="hljs-string">networkd</span><br>  <span class="hljs-attr">ethernets:</span><br>    <span class="hljs-attr">ens18:</span><br>      <span class="hljs-attr">dhcp4:</span> <span class="hljs-literal">no</span><br>      <span class="hljs-attr">addresses:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-number">192.168</span><span class="hljs-number">.11</span><span class="hljs-number">.161</span><span class="hljs-string">/24</span><br>      <span class="hljs-attr">routes:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">to:</span> <span class="hljs-string">default</span><br>          <span class="hljs-attr">via:</span> <span class="hljs-number">192.168</span><span class="hljs-number">.11</span><span class="hljs-number">.1</span><br>      <span class="hljs-attr">nameservers:</span><br>        <span class="hljs-attr">addresses:</span> [<span class="hljs-number">119.29</span><span class="hljs-number">.29</span><span class="hljs-number">.29</span>,<span class="hljs-number">114.114</span><span class="hljs-number">.114</span><span class="hljs-number">.114</span>,<span class="hljs-number">8.8</span><span class="hljs-number">.8</span><span class="hljs-number">.8</span>]<br></code></pre></td></tr></table></figure>

<p>保存k8s-master01的网卡配置</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># sudo netplan apply</span><br></code></pre></td></tr></table></figure>

<p>重新按新ip连接主机，然后使用以下命名查看ip地址信息</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ip a s<br></code></pre></td></tr></table></figure>

<p>k8s-worker01节点IP地址为：192.168.11.165/24</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-worker01:~<span class="hljs-comment"># nano /etc/netplan/50-cloud-init.yaml</span><br>root@k8s-worker01:~<span class="hljs-comment"># cat /etc/netplan/50-cloud-init.yaml</span><br></code></pre></td></tr></table></figure>

<figure class="hljs highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">network:</span><br>  <span class="hljs-attr">version:</span> <span class="hljs-number">2</span><br>  <span class="hljs-attr">renderer:</span> <span class="hljs-string">networkd</span><br>  <span class="hljs-attr">ethernets:</span><br>    <span class="hljs-attr">enp6s18:</span><br>      <span class="hljs-attr">dhcp4:</span> <span class="hljs-literal">no</span><br>      <span class="hljs-attr">addresses:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-number">192.168</span><span class="hljs-number">.11</span><span class="hljs-number">.165</span><span class="hljs-string">/24</span><br>      <span class="hljs-attr">routes:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">to:</span> <span class="hljs-string">default</span><br>          <span class="hljs-attr">via:</span> <span class="hljs-number">192.168</span><span class="hljs-number">.11</span><span class="hljs-number">.1</span><br>      <span class="hljs-attr">nameservers:</span><br>        <span class="hljs-attr">addresses:</span> [<span class="hljs-number">119.29</span><span class="hljs-number">.29</span><span class="hljs-number">.29</span>,<span class="hljs-number">114.114</span><span class="hljs-number">.114</span><span class="hljs-number">.114</span>,<span class="hljs-number">8.8</span><span class="hljs-number">.8</span><span class="hljs-number">.8</span>]<br></code></pre></td></tr></table></figure>

<p>保存k8s-worker01的网卡配置</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-worker01:~<span class="hljs-comment"># sudo netplan apply</span><br></code></pre></td></tr></table></figure>


<p>k8s-worker02节点IP地址为：192.168.11.166/24</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-worker02:~<span class="hljs-comment"># nano /etc/netplan/50-cloud-init.yaml</span><br>root@k8s-worker02:~<span class="hljs-comment"># cat /etc/netplan/50-cloud-init.yaml</span><br></code></pre></td></tr></table></figure>

<figure class="hljs highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">network:</span><br>  <span class="hljs-attr">version:</span> <span class="hljs-number">2</span><br>  <span class="hljs-attr">renderer:</span> <span class="hljs-string">networkd</span><br>  <span class="hljs-attr">ethernets:</span><br>    <span class="hljs-attr">enp6s18:</span><br>      <span class="hljs-attr">dhcp4:</span> <span class="hljs-literal">no</span><br>      <span class="hljs-attr">addresses:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-number">192.168</span><span class="hljs-number">.11</span><span class="hljs-number">.166</span><span class="hljs-string">/24</span><br>      <span class="hljs-attr">routes:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">to:</span> <span class="hljs-string">default</span><br>          <span class="hljs-attr">via:</span> <span class="hljs-number">192.168</span><span class="hljs-number">.11</span><span class="hljs-number">.1</span><br>      <span class="hljs-attr">nameservers:</span><br>        <span class="hljs-attr">addresses:</span> [<span class="hljs-number">119.29</span><span class="hljs-number">.29</span><span class="hljs-number">.29</span>,<span class="hljs-number">114.114</span><span class="hljs-number">.114</span><span class="hljs-number">.114</span>,<span class="hljs-number">8.8</span><span class="hljs-number">.8</span><span class="hljs-number">.8</span>]<br></code></pre></td></tr></table></figure>

<p>保存k8s-worker02的网卡配置</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-worker02:~<span class="hljs-comment"># sudo netplan apply</span><br></code></pre></td></tr></table></figure>




<h3 id="1-3-3-主机名与IP地址解析"><a href="#1-3-3-主机名与IP地址解析" class="headerlink" title="1.3.3 主机名与IP地址解析"></a>1.3.3 主机名与IP地址解析</h3><p>所有集群主机均需要进行配置。</p>
<p>在没有DNS服务器的环境中需要先能解析到各个节点的IP地址</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># sudo nano /etc/hosts</span><br></code></pre></td></tr></table></figure>

<ul>
<li>在文件后面追加以下内容</li>
</ul>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">192.168.11.161 k8s-master01<br>192.168.11.165 k8s-worker01<br>192.168.11.166 k8s-worker02<br></code></pre></td></tr></table></figure>


<p>修改后Ctrl+O,然后Enter键，再Ctrl+X保存文件修改并退出</p>
<p>查看IP解析配置是否生效命令</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">~$ ping -c 4 k8s-master01<br>~$ ping -c 4 k8s-worker01<br>~$ ping -c 4 k8s-worker02<br></code></pre></td></tr></table></figure>

<h3 id="1-3-4-时间同步配置"><a href="#1-3-4-时间同步配置" class="headerlink" title="1.3.4 时间同步配置"></a>1.3.4 时间同步配置</h3><p>查看时间</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># date</span><br> Thu Sep  7 05:39:21 AM UTC 2024<br></code></pre></td></tr></table></figure>

<p>更换时区</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># timedatectl set-timezone Asia/Shanghai</span><br></code></pre></td></tr></table></figure>
<p>再次查看时间</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># date</span><br> Thu Sep  7 01:39:51 PM CST 2024<br></code></pre></td></tr></table></figure>

<p>安装ntpdate命令</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># apt install ntpdate -y</span><br></code></pre></td></tr></table></figure>

<p>使用ntpdate命令同步时间</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># ntpdate time1.aliyun.com</span><br></code></pre></td></tr></table></figure>


<p>通过计划任务实现时间同步</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># apt install cron -y</span><br>~<span class="hljs-comment"># crontab -e</span><br> no crontab <span class="hljs-keyword">for</span> root - using an empty one<br> Select an editor.  To change later, run <span class="hljs-string">&#x27;select-editor&#x27;</span>.<br>  1. /bin/nano        &lt;---- easiest<br>  2. /usr/bin/vim.basic<br>  3. /usr/bin/vim.tiny<br>  4. /bin/ed<br> Choose 1-4 [1]: 2<br> ......<br>0 */1 * * * ntpdate time1.aliyun.com           // 写入配置文件<br>~<span class="hljs-comment"># crontab -l   // 查看crontab配置</span><br> ......<br>0 */1 * * * ntpdate time1.aliyun.com        <br></code></pre></td></tr></table></figure>


<h3 id="1-3-5-配置内核转发及网桥过滤"><a href="#1-3-5-配置内核转发及网桥过滤" class="headerlink" title="1.3.5 配置内核转发及网桥过滤"></a>1.3.5 配置内核转发及网桥过滤</h3><p>所有主机均需要操作。</p>
<p>Way1：手动执行，手动加载内核转发及网桥过滤模块</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># modprobe overlay</span><br>~<span class="hljs-comment"># modprobe br_netfilter</span><br></code></pre></td></tr></table></figure>


<p>Way2：创建加载内核模块文件</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># sudo cat &lt;&lt; EOF | tee /etc/modules-load.d/k8s.conf</span><br>overlay<br>br_netfilter<br>EOF<br></code></pre></td></tr></table></figure>

<ul>
<li>查看已加载的模块</li>
</ul>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># lsmod | egrep &quot;overlay&quot;</span><br>overlay               151552  0<br></code></pre></td></tr></table></figure>


<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># lsmod | egrep &quot;br_netfilter&quot;</span><br>br_netfilter    32768   0       <br>bridge           307200  1 br_netfilter<br></code></pre></td></tr></table></figure>


<ul>
<li>添加网桥过滤及内核转发配置文件</li>
</ul>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># cat &lt;&lt; EOF| tee /etc/sysctl.d/k8s.conf</span><br>net.bridge.bridge-nf-call-ip6tables = 1<br>net.bridge.bridge-nf-call-iptables = 1<br>net.ipv4.ip_forward = 1<br>EOF<br></code></pre></td></tr></table></figure>

<p>查看配置文件</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># nano /etc/modules-load.d/k8s.conf</span><br>~<span class="hljs-comment"># cat /etc/modules-load.d/k8s.conf</span><br></code></pre></td></tr></table></figure>

<p>加载内核参数,使之生效</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># sysctl --system</span><br></code></pre></td></tr></table></figure>

<p>检查输出的结果中是否包含以下三项：</p>
<figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs plain">net.bridge.bridge-nf-call-ip6tables &#x3D; 1<br>net.bridge.bridge-nf-call-iptables &#x3D; 1<br>net.ipv4.ip_forward &#x3D; 1<br></code></pre></td></tr></table></figure>



<h3 id="1-3-6-安装ipset及ipvsadm"><a href="#1-3-6-安装ipset及ipvsadm" class="headerlink" title="1.3.6 安装ipset及ipvsadm"></a>1.3.6 安装ipset及ipvsadm</h3><p>所有主机均需要操作。</p>
<p>安装ipset及ipvsadm命令</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># apt install ipset ipvsadm -y</span><br></code></pre></td></tr></table></figure>

<p>配置ipvsadm模块加载</p>
<p>添加系统启动需要加载的模块文件</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># cat &lt;&lt; EOF | tee /etc/modules-load.d/ipvs.conf</span><br>ip_vs<br>ip_vs_rr<br>ip_vs_wrr<br>ip_vs_sh<br>nf_conntrack<br>EOF<br></code></pre></td></tr></table></figure>

<p>创建加载模块脚本文件</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># cat &lt;&lt; EOF | tee ipvs.sh</span><br><span class="hljs-meta">#!/bin/sh</span><br>modprobe -- ip_vs<br>modprobe -- ip_vs_rr<br>modprobe -- ip_vs_wrr<br>modprobe -- ip_vs_sh<br>modprobe -- nf_conntrack<br>EOF<br></code></pre></td></tr></table></figure>

<p>上述命令执行完成后，当前目录下会生成一个ipvs.sh脚本文件，接下来使用bash命令执行它</p>
<p>执行ipvs.sh脚本文件，以加载模块</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># sh ipvs.sh</span><br></code></pre></td></tr></table></figure>

<p>查看ipvs配置是否已生效</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># lsmod | grep ip_vs</span><br>ip_vs_sh               12288  0<br>ip_vs_wrr              12288  0<br>ip_vs_rr               12288  0<br>ip_vs                 221184  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr<br>nf_conntrack          196608  1 ip_vs<br>nf_defrag_ipv6         24576  2 nf_conntrack,ip_vs<br>libcrc32c              12288  4 nf_conntrack,btrfs,raid456,ip_vs<br></code></pre></td></tr></table></figure>

<h3 id="1-3-7-关闭SWAP分区"><a href="#1-3-7-关闭SWAP分区" class="headerlink" title="1.3.7 关闭SWAP分区"></a>1.3.7 关闭SWAP分区</h3><p>修改完成后需要重启操作系统，</p>
<p>Way1：临时关闭（不推荐），若不重启，命令为</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># swapoff -a</span><br></code></pre></td></tr></table></figure>

<p>Way2：永久关闭swap分区（推荐，操作需要重启操作系统）</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># nano /etc/fstab    // 进入分区配置文件</span><br> ......<br><br> <span class="hljs-comment">#/swap.img   none    swap   sw      0       0    // 在此行首添加“#”以注释swap分区的配置</span><br></code></pre></td></tr></table></figure>

<p>修改完成后保存文件并退出</p>
<h1 id="二、K8S集群容器运行时-Containerd-准备"><a href="#二、K8S集群容器运行时-Containerd-准备" class="headerlink" title="二、K8S集群容器运行时 Containerd 准备"></a>二、K8S集群容器运行时 Containerd 准备</h1><ul>
<li><p>安装docker-ce方法：<a target="_blank" rel="noopener" href="https://docs.docker.com/engine/install/ubuntu/">https://docs.docker.com/engine/install/ubuntu/</a></p>
</li>
<li><p>本文实际采用containerd作为集群容器镜像的运行平台</p>
</li>
</ul>
<h2 id="2-1-Containerd部署文件获取"><a href="#2-1-Containerd部署文件获取" class="headerlink" title="2.1 Containerd部署文件获取"></a>2.1 Containerd部署文件获取</h2><p>wget下载1.7.27版本containerd</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># wget https://github.com/containerd/containerd/releases/download/v1.7.27/cri-containerd-1.7.27-linux-amd64.tar.gz</span><br></code></pre></td></tr></table></figure>

<p>解压安装</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># sudo apt install debianutils</span><br>~<span class="hljs-comment"># sudo apt install --reinstall libc6</span><br>~<span class="hljs-comment"># sudo apt install --reinstall which</span><br><br><br>~<span class="hljs-comment"># sudo tar xf /home/acanx/cri-containerd-1.7.27-linux-amd64.tar.gz  -C /</span><br><br>~<span class="hljs-comment"># which containerd</span><br><br>/usr/<span class="hljs-built_in">local</span>/bin/containerd<br>~<span class="hljs-comment"># which runc</span><br><br>/usr/<span class="hljs-built_in">local</span>/sbin/runc<br></code></pre></td></tr></table></figure>

<p>验证containerd、runc是否安装成功</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># which containerd</span><br>~<span class="hljs-comment"># which runc</span><br>~<span class="hljs-comment"># whereis containerd</span><br></code></pre></td></tr></table></figure>

<h2 id="2-2-Containerd配置文件生成并修改"><a href="#2-2-Containerd配置文件生成并修改" class="headerlink" title="2.2 Containerd配置文件生成并修改"></a>2.2 Containerd配置文件生成并修改</h2><p>创建containerd配置文件目录/etc/containerd</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># mkdir /etc/containerd</span><br>~<span class="hljs-comment"># sudo chmod -R 777 /etc/containerd/       // 然后可以上传配置文件</span><br></code></pre></td></tr></table></figure>

<p>生成配置文件config.toml及默认配置</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># containerd config default &gt; /etc/containerd/config.toml</span><br></code></pre></td></tr></table></figure>

<p>修改配置文件的第67行</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># nano /etc/containerd/config.toml</span><br></code></pre></td></tr></table></figure>

<figure class="hljs highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs txt">sandbox_image = &quot;registry.k8s.io/pause:3.10&quot;  // 由3.9修改为3.10<br></code></pre></td></tr></table></figure>

<ul>
<li>如果使用阿里云容器镜像仓库，也可以修改为：</li>
</ul>
<figure class="hljs highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs txt">sandbox_image = &quot;registry.aliyuncs.com/google_containers/pause:3.9&quot;  // 由3.9修改为3.10<br></code></pre></td></tr></table></figure>

<p>修改配置文件的第139行</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># vim /etc/containerd/config.toml</span><br> SystemdCgroup = <span class="hljs-literal">true</span> 由<span class="hljs-literal">false</span>修改为<span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure>


<h2 id="2-3-Containerd启动及开机自启动"><a href="#2-3-Containerd启动及开机自启动" class="headerlink" title="2.3 Containerd启动及开机自启动"></a>2.3 Containerd启动及开机自启动</h2><p>设置containerd开机自启并立即启动</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># sudo tee /etc/systemd/system/containerd.service &lt;&lt;EOF</span><br>[Unit]<br>Description=containerd container runtime<br>Documentation=https://containerd.io<br>After=network.target local-fs.target<br> <br>[Service]<br>ExecStartPre=-/sbin/modprobe overlay<br>ExecStart=/usr/<span class="hljs-built_in">local</span>/bin/containerd<br> <br>Type=notify<br>Delegate=yes<br>KillMode=process<br>Restart=always<br>RestartSec=5<br> <br><span class="hljs-comment"># 限制日志大小</span><br>LimitNOFILE=infinity<br> <br>[Install]<br>WantedBy=multi-user.target<br>EOF<br></code></pre></td></tr></table></figure>


<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># ls /etc/systemd/system/containerd.service</span><br>~<span class="hljs-comment"># systemctl enable --now containerd</span><br></code></pre></td></tr></table></figure>

<p>验证containerd版本</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># containerd --version</span><br></code></pre></td></tr></table></figure>



<h1 id="三、K8S集群部署"><a href="#三、K8S集群部署" class="headerlink" title="三、K8S集群部署"></a>三、K8S集群部署</h1><h2 id="3-1-K8S集群软件apt源准备"><a href="#3-1-K8S集群软件apt源准备" class="headerlink" title="3.1 K8S集群软件apt源准备"></a>3.1 K8S集群软件apt源准备</h2><p>本次使用kubernetes社区软件源仓库或阿里云软件源仓库，建议网络不畅通的选择阿里云软件源仓库</p>
<p>下载用于 Kubernetes 软件包仓库的公共签名密钥,所有仓库都使用相同的签名密钥，因此你可以忽略URL中的版本：</p>
<ul>
<li>K8S社区软件源仓库签名文件下载</li>
</ul>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><br>~<span class="hljs-comment"># curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.32/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg</span><br>~<span class="hljs-comment"># ls /etc/apt/keyrings/kubernetes-apt-keyring.gpg</span><br></code></pre></td></tr></table></figure>

<ul>
<li>阿里云软件源仓库签名文件下载</li>
</ul>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># curl -fsSL https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg</span><br></code></pre></td></tr></table></figure>

<h3 id="添加-Kubernetes-apt-仓库"><a href="#添加-Kubernetes-apt-仓库" class="headerlink" title="添加 Kubernetes apt 仓库"></a>添加 Kubernetes apt 仓库</h3><p>请注意，此仓库仅包含适用于 Kubernetes 1.32.3 的软件包； 对于其他 Kubernetes 次要版本，则需要更改 URL 中的 Kubernetes 次要版本以匹配你所需的次要版本 。</p>
<p>此操作会覆盖 /etc/apt/sources.list.d/kubernetes.list 中现存的所有配置，如果有的情况下。</p>
<h4 id="K8S社区"><a href="#K8S社区" class="headerlink" title="K8S社区"></a>K8S社区</h4><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># echo &#x27;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.32/deb/ /&#x27; | sudo tee /etc/apt/sources.list.d/kubernetes.list</span><br></code></pre></td></tr></table></figure>

<h4 id="阿里云"><a href="#阿里云" class="headerlink" title="阿里云"></a>阿里云</h4><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># echo &quot;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/deb/ /&quot; | tee /etc/apt/sources.list.d/kubernetes.list</span><br></code></pre></td></tr></table></figure>


<p>更新 apt 包索引</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># sudo apt-get update</span><br></code></pre></td></tr></table></figure>




<h2 id="3-2-K8S集群软件安装及kubelet配置"><a href="#3-2-K8S集群软件安装及kubelet配置" class="headerlink" title="3.2 K8S集群软件安装及kubelet配置"></a>3.2 K8S集群软件安装及kubelet配置</h2><p>所有节点均可安装</p>
<h3 id="3-2-1-k8s集群软件安装"><a href="#3-2-1-k8s集群软件安装" class="headerlink" title="3.2.1 k8s集群软件安装"></a>3.2.1 k8s集群软件安装</h3><p>查看软件列表</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># apt-cache policy kubeadm</span><br><br>kubeadm:<br>  Installed: (none)<br>  Candidate: 1.32.3-1.1<br>  Version table:<br>     1.32.3-1.1 500<br>        500 https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/deb  Packages<br>     1.32.2-1.1 500<br>        500 https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/deb  Packages<br>     1.32.1-1.1 500<br>        500 https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/deb  Packages<br>     1.32.0-1.1 500<br>        500 https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/deb  Packages<br></code></pre></td></tr></table></figure>


<p>查看软件列表及其依赖关系</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># apt-cache showpkg kubeadm</span><br><br>Package: kubeadm<br>Versions: <br>1.32.3-1.1 (/var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages)<br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br><br>1.32.2-1.1 (/var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages)<br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br><br>1.32.1-1.1 (/var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages)<br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br><br>1.32.0-1.1 (/var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages)<br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br> Description Language: <br>                 File: /var/lib/apt/lists/mirrors.aliyun.com_kubernetes-new_core_stable_v1.32_deb_Packages<br>                  MD5: <br><br><br>Reverse Depends: <br>  kubeadm:ppc64el,kubeadm<br>  kubeadm:s390x,kubeadm<br>  kubeadm:arm64,kubeadm<br>  kubeadm:ppc64el,kubeadm<br>  kubeadm:s390x,kubeadm<br>  kubeadm:arm64,kubeadm<br>  kubeadm:ppc64el,kubeadm<br>  kubeadm:s390x,kubeadm<br>  kubeadm:arm64,kubeadm<br>  kubeadm:ppc64el,kubeadm<br>  kubeadm:s390x,kubeadm<br>  kubeadm:arm64,kubeadm<br>Dependencies: <br>1.32.3-1.1 - cri-tools (2 1.30.0) kubeadm:ppc64el (32 (null)) kubeadm:arm64 (32 (null)) kubeadm:s390x (32 (null)) <br>1.32.2-1.1 - cri-tools (2 1.30.0) kubeadm:ppc64el (32 (null)) kubeadm:arm64 (32 (null)) kubeadm:s390x (32 (null)) <br>1.32.1-1.1 - cri-tools (2 1.30.0) kubeadm:ppc64el (32 (null)) kubeadm:arm64 (32 (null)) kubeadm:s390x (32 (null)) <br>1.32.0-1.1 - cri-tools (2 1.30.0) kubeadm:ppc64el (32 (null)) kubeadm:arm64 (32 (null)) kubeadm:s390x (32 (null)) <br>Provides: <br>1.32.3-1.1 - <br>1.32.2-1.1 - <br>1.32.1-1.1 - <br>1.32.0-1.1 - <br>Reverse Provides: <br></code></pre></td></tr></table></figure>

<p>查看可用软件列表</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># apt-cache madison kubeadm</span><br><br>   kubeadm | 1.32.3-1.1 | https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/deb  Packages<br>   kubeadm | 1.32.2-1.1 | https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/deb  Packages<br>   kubeadm | 1.32.1-1.1 | https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/deb  Packages<br>   kubeadm | 1.32.0-1.1 | https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/deb  Packages<br></code></pre></td></tr></table></figure>

<p>Way1：采用默认安装</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># sudo apt-get install kubelet kubeadm kubectl -y</span><br></code></pre></td></tr></table></figure>


<p>Way2：安装指定版本(v1.32.3-1.1)</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># sudo apt-get install -y kubelet=1.32.3-1.1 kubeadm=1.32.3-1.1 kubectl=1.32.3-1.1</span><br></code></pre></td></tr></table></figure>

<ul>
<li>如有报错：</li>
</ul>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">E: Could not get lock /var/lib/dpkg/lock-frontend. It is held by process 5005 <br>(unattended-upgr)<br> N: Be aware that removing the lock file is not a solution and may <span class="hljs-built_in">break</span> your <br>system.<br> E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), is <br>another process using it?<br></code></pre></td></tr></table></figure>
<p>可稍等等</p>
<p>锁定版本，防止后期自动更新</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># sudo apt-mark hold kubelet kubeadm kubectl</span><br></code></pre></td></tr></table></figure>


<p>解锁版本，则可以执行更新</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># sudo apt-mark unhold kubelet kubeadm kubectl</span><br></code></pre></td></tr></table></figure>


<h3 id="3-2-2-配置kubelet"><a href="#3-2-2-配置kubelet" class="headerlink" title="3.2.2 配置kubelet"></a>3.2.2 配置kubelet</h3><p>为了实现容器运行时使用的cgroupdriver与kubelet使用的cgroup的一致性，建议修改如下文件内容。</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># nano /etc/default/kubelet</span><br> KUBELET_EXTRA_ARGS=<span class="hljs-string">&quot;--cgroup-driver=systemd&quot;</span><br></code></pre></td></tr></table></figure>

<ul>
<li>设置kubelet为开机自启动，由于没有生成配置文件，集群初始化后自动启动</li>
</ul>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># systemctl enable kubelet</span><br></code></pre></td></tr></table></figure>


<h2 id="3-3-K8S集群初始化"><a href="#3-3-K8S集群初始化" class="headerlink" title="3.3 K8S集群初始化"></a>3.3 K8S集群初始化</h2><h3 id="3-3-1-查看版本"><a href="#3-3-1-查看版本" class="headerlink" title="3.3.1 查看版本"></a>3.3.1 查看版本</h3><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubeadm version</span><br><br>kubeadm version: &amp;version.Info&#123;Major:<span class="hljs-string">&quot;1&quot;</span>, Minor:<span class="hljs-string">&quot;32&quot;</span>, GitVersion:<span class="hljs-string">&quot;v1.32.3&quot;</span>, GitCommit:<span class="hljs-string">&quot;32cc146f75aad04beaaa245a7157eb35063a9f99&quot;</span>, GitTreeState:<span class="hljs-string">&quot;clean&quot;</span>, BuildDate:<span class="hljs-string">&quot;2025-03-11T19:57:38Z&quot;</span>, GoVersion:<span class="hljs-string">&quot;go1.23.6&quot;</span>, Compiler:<span class="hljs-string">&quot;gc&quot;</span>, Platform:<span class="hljs-string">&quot;linux/amd64&quot;</span>&#125;<br><br></code></pre></td></tr></table></figure>



<h3 id="3-3-2-生成部署配置文件"><a href="#3-3-2-生成部署配置文件" class="headerlink" title="3.3.2 生成部署配置文件"></a>3.3.2 生成部署配置文件</h3><p>生成kubeadm部署默认配置文件</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubeadm config print init-defaults &gt; /home/acanx/kubeadm-config.yaml</span><br></code></pre></td></tr></table></figure>

<h4 id="使用kubernetes社区版容器镜像仓库"><a href="#使用kubernetes社区版容器镜像仓库" class="headerlink" title="使用kubernetes社区版容器镜像仓库"></a>使用kubernetes社区版容器镜像仓库</h4><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># nano /home/acanx/kubeadm-config.yaml</span><br>root@k8s-master01:~<span class="hljs-comment"># cat kubeadm-config.yaml</span><br></code></pre></td></tr></table></figure>

<p>kubeadm-config.yaml文件中 的配置</p>
<figure class="hljs highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs yaml"> <span class="hljs-attr">apiVersion:</span> <span class="hljs-string">kubeadm.k8s.io/v1beta3</span><br> <span class="hljs-string">bootstrapTokens:-</span> <span class="hljs-string">groups:-</span> <span class="hljs-string">system:bootstrappers:kubeadm:default-node-token</span><br> <span class="hljs-attr">token:</span> <span class="hljs-string">abcdef.0123456789abcdef</span><br> <span class="hljs-attr">ttl:</span> <span class="hljs-string">24h0m0s</span><br> <span class="hljs-string">usages:-</span> <span class="hljs-string">signing-</span> <span class="hljs-string">authentication</span><br> <span class="hljs-attr">kind:</span> <span class="hljs-string">InitConfiguration</span><br> <span class="hljs-attr">localAPIEndpoint:</span><br> <span class="hljs-attr">advertiseAddress:</span> <span class="hljs-number">192.168</span><span class="hljs-number">.10</span><span class="hljs-number">.140</span><br> <span class="hljs-attr">bindPort:</span> <span class="hljs-number">6443</span><br> <span class="hljs-attr">nodeRegistration:</span><br> <span class="hljs-attr">criSocket:</span> <span class="hljs-string">unix:///var/run/containerd/containerd.sock</span><br> <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">IfNotPresent</span><br> <span class="hljs-attr">name:</span> <span class="hljs-string">k8s-master01</span><br> <span class="hljs-attr">taints:</span> <span class="hljs-literal">null</span><span class="hljs-string">--</span><br><span class="hljs-attr">apiServer:</span><br> <span class="hljs-attr">timeoutForControlPlane:</span> <span class="hljs-string">4m0s</span><br> <span class="hljs-attr">apiVersion:</span> <span class="hljs-string">kubeadm.k8s.io/v1beta3</span><br> <span class="hljs-attr">certificatesDir:</span> <span class="hljs-string">/etc/kubernetes/pki</span><br> <span class="hljs-attr">clusterName:</span> <span class="hljs-string">kubernetes</span><br> <span class="hljs-attr">controllerManager:</span> &#123;&#125;<br> <span class="hljs-attr">dns:</span> &#123;&#125;<br> <span class="hljs-attr">etcd:</span><br> <span class="hljs-attr">local:</span><br> <span class="hljs-attr">dataDir:</span> <span class="hljs-string">/var/lib/etcd</span><br> <span class="hljs-attr">imageRepository:</span> <span class="hljs-string">registry.k8s.io</span><br> <span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterConfiguration</span><br> <span class="hljs-attr">kubernetesVersion:</span> <span class="hljs-number">1.30</span><span class="hljs-number">.0</span><br> <span class="hljs-attr">networking:</span><br> <span class="hljs-attr">dnsDomain:</span> <span class="hljs-string">cluster.local</span><br> <span class="hljs-attr">serviceSubnet:</span> <span class="hljs-number">10.96</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><span class="hljs-string">/12</span><br> <span class="hljs-attr">podSubnet:</span> <span class="hljs-number">10.244</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><span class="hljs-string">/16</span><br><span class="hljs-attr">scheduler:</span> &#123;&#125;<br><span class="hljs-string">--</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">KubeletConfiguration</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">kubelet.config.k8s.io/v1beta1</span><br><span class="hljs-attr">cgroupDriver:</span> <span class="hljs-string">systemd</span><br></code></pre></td></tr></table></figure>



<h4 id="使用阿里云容器镜像仓库"><a href="#使用阿里云容器镜像仓库" class="headerlink" title="使用阿里云容器镜像仓库"></a>使用阿里云容器镜像仓库</h4><p>编辑kubeadm配置文件（使用阿里云容器镜像仓库）</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># nano kubeadm-config.yaml</span><br></code></pre></td></tr></table></figure>

<figure class="hljs highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">kubeadm.k8s.io/v1beta4</span><br><span class="hljs-attr">bootstrapTokens:</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">groups:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">system:bootstrappers:kubeadm:default-node-token</span><br>  <span class="hljs-attr">token:</span> <span class="hljs-string">abcdef.0123456789abcdef</span><br>  <span class="hljs-attr">ttl:</span> <span class="hljs-string">24h0m0s</span><br>  <span class="hljs-attr">usages:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">signing</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">authentication</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">InitConfiguration</span><br><span class="hljs-attr">localAPIEndpoint:</span><br>  <span class="hljs-attr">advertiseAddress:</span> <span class="hljs-number">192.168</span><span class="hljs-number">.11</span><span class="hljs-number">.161</span>   <span class="hljs-comment"># 设置节点IP地址</span><br>  <span class="hljs-attr">bindPort:</span> <span class="hljs-number">6443</span><br><span class="hljs-attr">nodeRegistration:</span><br>  <span class="hljs-attr">criSocket:</span> <span class="hljs-string">unix:///var/run/containerd/containerd.sock</span><br>  <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">IfNotPresent</span><br>  <span class="hljs-attr">imagePullSerial:</span> <span class="hljs-literal">true</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">k8s-master01</span>      <span class="hljs-comment"># 修改节点名称</span><br>  <span class="hljs-attr">taints:</span> <span class="hljs-literal">null</span><br><span class="hljs-attr">timeouts:</span><br>  <span class="hljs-attr">controlPlaneComponentHealthCheck:</span> <span class="hljs-string">4m0s</span><br>  <span class="hljs-attr">discovery:</span> <span class="hljs-string">5m0s</span><br>  <span class="hljs-attr">etcdAPICall:</span> <span class="hljs-string">2m0s</span><br>  <span class="hljs-attr">kubeletHealthCheck:</span> <span class="hljs-string">4m0s</span><br>  <span class="hljs-attr">kubernetesAPICall:</span> <span class="hljs-string">1m0s</span><br>  <span class="hljs-attr">tlsBootstrap:</span> <span class="hljs-string">5m0s</span><br>  <span class="hljs-attr">upgradeManifests:</span> <span class="hljs-string">5m0s</span><br><span class="hljs-meta">---</span><br><span class="hljs-attr">apiServer:</span> &#123;&#125;<br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">kubeadm.k8s.io/v1beta4</span><br><span class="hljs-attr">caCertificateValidityPeriod:</span> <span class="hljs-string">87600h0m0s</span><br><span class="hljs-attr">certificateValidityPeriod:</span> <span class="hljs-string">8760h0m0s</span><br><span class="hljs-attr">certificatesDir:</span> <span class="hljs-string">/etc/kubernetes/pki</span><br><span class="hljs-attr">clusterName:</span> <span class="hljs-string">kubernetes</span><br><span class="hljs-attr">controllerManager:</span> &#123;&#125;<br><span class="hljs-attr">dns:</span> &#123;&#125;<br><span class="hljs-attr">encryptionAlgorithm:</span> <span class="hljs-string">RSA-2048</span><br><span class="hljs-attr">etcd:</span><br>  <span class="hljs-attr">local:</span><br>    <span class="hljs-attr">dataDir:</span> <span class="hljs-string">/var/lib/etcd</span><br><span class="hljs-attr">imageRepository:</span> <span class="hljs-string">registry.aliyuncs.com/google_containers</span>   <span class="hljs-comment"># 修改镜像地址</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterConfiguration</span><br><span class="hljs-attr">kubernetesVersion:</span> <span class="hljs-number">1.32</span><span class="hljs-number">.0</span><br><span class="hljs-attr">networking:</span><br>  <span class="hljs-attr">dnsDomain:</span> <span class="hljs-string">cluster.local</span><br>  <span class="hljs-attr">serviceSubnet:</span> <span class="hljs-number">10.96</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><span class="hljs-string">/12</span><br>  <span class="hljs-attr">podSubnet:</span> <span class="hljs-number">10.244</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><span class="hljs-string">/16</span>    <span class="hljs-comment"># 可按需修改，原则：不与已有的节点网段重合</span><br><span class="hljs-attr">proxy:</span> &#123;&#125;<br><span class="hljs-attr">scheduler:</span> &#123;&#125;<br><span class="hljs-meta">---</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">KubeletConfiguration</span>                   <span class="hljs-comment"># 最后四行是补加的</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">kubelet.config.k8s.io/v1beta1</span><br><span class="hljs-attr">cgroupDriver:</span> <span class="hljs-string">systemd</span><br></code></pre></td></tr></table></figure>

<h3 id="3-3-3-查看并下载镜像"><a href="#3-3-3-查看并下载镜像" class="headerlink" title="3.3.3 查看并下载镜像"></a>3.3.3 查看并下载镜像</h3><h4 id="查看及使用Kubernetes社区镜像仓库下载镜像"><a href="#查看及使用Kubernetes社区镜像仓库下载镜像" class="headerlink" title="查看及使用Kubernetes社区镜像仓库下载镜像"></a>查看及使用Kubernetes社区镜像仓库下载镜像</h4><p>查看镜像列表（K8S社区镜像仓库）</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubeadm config images list   # 查看kubernetes镜像默认版本</span><br><br>root@k8s-master01:~<span class="hljs-comment"># kubeadm config images list --kubernetes-version=v1.32.3    # 指定kubernetes镜像版本</span><br><br>registry.k8s.io/kube-apiserver:v1.32.3<br>registry.k8s.io/kube-controller-manager:v1.32.3<br>registry.k8s.io/kube-scheduler:v1.32.3<br>registry.k8s.io/kube-proxy:v1.32.3<br>registry.k8s.io/coredns/coredns:v1.11.3<br>registry.k8s.io/pause:3.10<br>registry.k8s.io/etcd:3.5.16-0<br></code></pre></td></tr></table></figure>


<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubeadm config images pull           # 默认从K8S社区镜像仓库下载镜像</span><br><br>[config/images] Pulled registry.k8s.io/kube-apiserver:v1.32.3<br>[config/images] Pulled registry.k8s.io/kube-controller-manager:v1.32.3<br>[config/images] Pulled registry.k8s.io/kube-scheduler:v1.32.3<br>[config/images] Pulled registry.k8s.io/kube-proxy:v1.32.3<br>[config/images] Pulled registry.k8s.io/coredns/coredns:v1.11.3<br>[config/images] Pulled registry.k8s.io/pause:3.10<br>[config/images] Pulled registry.k8s.io/etcd:3.5.16-0<br></code></pre></td></tr></table></figure>


<h4 id="查看及使用阿里云容器镜像仓库下载镜像"><a href="#查看及使用阿里云容器镜像仓库下载镜像" class="headerlink" title="查看及使用阿里云容器镜像仓库下载镜像"></a>查看及使用阿里云容器镜像仓库下载镜像</h4><p>查看镜像列表（阿里云容器镜像仓库）</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubeadm config images list --image-repository registry.aliyuncs.com/google_containers</span><br><br>registry.aliyuncs.com/google_containers/kube-apiserver:v1.32.3<br>registry.aliyuncs.com/google_containers/kube-controller-manager:v1.32.3<br>registry.aliyuncs.com/google_containers/kube-scheduler:v1.32.3<br>registry.aliyuncs.com/google_containers/kube-proxy:v1.32.3<br>registry.aliyuncs.com/google_containers/coredns:v1.11.3<br>registry.aliyuncs.com/google_containers/pause:3.10<br>registry.aliyuncs.com/google_containers/etcd:3.5.16-0<br></code></pre></td></tr></table></figure>

<p>使用阿里云容器镜像仓库下载</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubeadm config images pull --image-repository registry.aliyuncs.com/google_containers --cri-socket=unix:///run/containerd/containerd.sock</span><br><br>[config/images] Pulled registry.aliyuncs.com/google_containers/kube-apiserver:v1.32.3<br>[config/images] Pulled registry.aliyuncs.com/google_containers/kube-controller-manager:v1.32.3<br>[config/images] Pulled registry.aliyuncs.com/google_containers/kube-scheduler:v1.32.3<br>[config/images] Pulled registry.aliyuncs.com/google_containers/kube-proxy:v1.32.3<br>[config/images] Pulled registry.aliyuncs.com/google_containers/coredns:v1.11.3<br>[config/images] Pulled registry.aliyuncs.com/google_containers/pause:3.10<br>[config/images] Pulled registry.aliyuncs.com/google_containers/etcd:3.5.16-0<br></code></pre></td></tr></table></figure>


<h4 id="查看下载的镜像"><a href="#查看下载的镜像" class="headerlink" title="查看下载的镜像"></a>查看下载的镜像</h4><p>查看本地下载的containerd镜像</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># crictl images</span><br><br>WARN[0000] Config <span class="hljs-string">&quot;/etc/crictl.yaml&quot;</span> does not exist, trying next: <span class="hljs-string">&quot;/usr/bin/crictl.yaml&quot;</span> <br>WARN[0000] Image connect using default endpoints: [unix:///run/containerd/containerd.sock unix:///run/crio/crio.sock unix:///var/run/cri-dockerd.sock]. As the default settings are now deprecated, you should <span class="hljs-built_in">set</span> the endpoint instead. <br>IMAGE                                                             TAG                 IMAGE ID            SIZE<br>registry.aliyuncs.com/google_containers/coredns                   v1.11.3             c69fa2e9cbf5f       18.6MB<br>registry.aliyuncs.com/google_containers/etcd                      3.5.16-0            a9e7e6b294baf       57.7MB<br>registry.aliyuncs.com/google_containers/kube-apiserver            v1.32.0             c2e17b8d0f4a3       28.7MB<br>registry.aliyuncs.com/google_containers/kube-apiserver            v1.32.3             f8bdc4cfa0651       28.7MB<br>registry.aliyuncs.com/google_containers/kube-controller-manager   v1.32.0             8cab3d2a8bd0f       26.3MB<br>registry.aliyuncs.com/google_containers/kube-controller-manager   v1.32.3             085818208a521       26.3MB<br>registry.aliyuncs.com/google_containers/kube-proxy                v1.32.0             040f9f8aac8cd       30.9MB<br>registry.aliyuncs.com/google_containers/kube-proxy                v1.32.3             a1ae78fd2f9d8       30.9MB<br>registry.aliyuncs.com/google_containers/kube-scheduler            v1.32.0             a389e107f4ff1       20.7MB<br>registry.aliyuncs.com/google_containers/kube-scheduler            v1.32.3             b4260bf5078ab       20.7MB<br>registry.aliyuncs.com/google_containers/pause                     3.10                873ed75102791       320kB<br></code></pre></td></tr></table></figure>




<h3 id="3-3-4-使用部署配置文件初始化K8S集群"><a href="#3-3-4-使用部署配置文件初始化K8S集群" class="headerlink" title="3.3.4 使用部署配置文件初始化K8S集群"></a>3.3.4 使用部署配置文件初始化K8S集群</h3><p>使用命令初始化Kubeadm（只在Master节点操作）</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubeadm init --config /home/acanx/kubeadm-config.yaml  --upload-certs --v=9  --cri-socket=unix:///run/containerd/containerd.sock</span><br></code></pre></td></tr></table></figure>
<p>输出内容如下：</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br></pre></td><td class="code"><pre><code class="hljs bash">I0322 20:07:35.623621    4886 initconfiguration.go:261] loading configuration from <span class="hljs-string">&quot;/home/acanx/kubeadm-config.yaml&quot;</span><br>[init] Using Kubernetes version: v1.32.0<br>[preflight] Running pre-flight checks<br>I0322 20:07:35.633576    4886 checks.go:561] validating Kubernetes and kubeadm version<br>I0322 20:07:35.633610    4886 checks.go:166] validating <span class="hljs-keyword">if</span> the firewall is enabled and active<br>I0322 20:07:35.651826    4886 checks.go:201] validating availability of port 6443<br>I0322 20:07:35.652309    4886 checks.go:201] validating availability of port 10259<br>I0322 20:07:35.652373    4886 checks.go:201] validating availability of port 10257<br>I0322 20:07:35.652434    4886 checks.go:278] validating the existence of file /etc/kubernetes/manifests/kube-apiserver.yaml<br>I0322 20:07:35.652491    4886 checks.go:278] validating the existence of file /etc/kubernetes/manifests/kube-controller-manager.yaml<br>I0322 20:07:35.652520    4886 checks.go:278] validating the existence of file /etc/kubernetes/manifests/kube-scheduler.yaml<br>I0322 20:07:35.652560    4886 checks.go:278] validating the existence of file /etc/kubernetes/manifests/etcd.yaml<br>I0322 20:07:35.652582    4886 checks.go:428] validating <span class="hljs-keyword">if</span> the connectivity <span class="hljs-built_in">type</span> is via proxy or direct<br>I0322 20:07:35.652631    4886 checks.go:467] validating http connectivity to first IP address <span class="hljs-keyword">in</span> the CIDR<br>I0322 20:07:35.652672    4886 checks.go:467] validating http connectivity to first IP address <span class="hljs-keyword">in</span> the CIDR<br>I0322 20:07:35.652699    4886 checks.go:102] validating the container runtime<br>I0322 20:07:35.653795    4886 checks.go:637] validating whether swap is enabled or not<br>I0322 20:07:35.653855    4886 checks.go:368] validating the presence of executable ip<br>I0322 20:07:35.653947    4886 checks.go:368] validating the presence of executable iptables<br>I0322 20:07:35.654055    4886 checks.go:368] validating the presence of executable mount<br>I0322 20:07:35.654080    4886 checks.go:368] validating the presence of executable nsenter<br>I0322 20:07:35.654117    4886 checks.go:368] validating the presence of executable ethtool<br>I0322 20:07:35.654145    4886 checks.go:368] validating the presence of executable tc<br>I0322 20:07:35.654182    4886 checks.go:368] validating the presence of executable touch<br>I0322 20:07:35.654210    4886 checks.go:514] running all checks<br>I0322 20:07:35.680418    4886 checks.go:399] checking whether the given node name is valid and reachable using net.LookupHost<br>I0322 20:07:35.680635    4886 checks.go:603] validating kubelet version<br>I0322 20:07:35.753081    4886 checks.go:128] validating <span class="hljs-keyword">if</span> the <span class="hljs-string">&quot;kubelet&quot;</span> service is enabled and active<br>I0322 20:07:35.774195    4886 checks.go:201] validating availability of port 10250<br>I0322 20:07:35.774355    4886 checks.go:327] validating the contents of file /proc/sys/net/ipv4/ip_forward<br>I0322 20:07:35.774477    4886 checks.go:201] validating availability of port 2379<br>I0322 20:07:35.774568    4886 checks.go:201] validating availability of port 2380<br>I0322 20:07:35.774631    4886 checks.go:241] validating the existence and emptiness of directory /var/lib/etcd<br>[preflight] Pulling images required <span class="hljs-keyword">for</span> setting up a Kubernetes cluster<br>[preflight] This might take a minute or two, depending on the speed of your internet connection<br>[preflight] You can also perform this action beforehand using <span class="hljs-string">&#x27;kubeadm config images pull&#x27;</span><br>I0322 20:07:35.777659    4886 checks.go:832] using image pull policy: IfNotPresent<br>I0322 20:07:35.779807    4886 checks.go:868] pulling: registry.aliyuncs.com/google_containers/kube-apiserver:v1.32.0<br>I0322 20:08:11.358938    4886 checks.go:868] pulling: registry.aliyuncs.com/google_containers/kube-controller-manager:v1.32.0<br>I0322 20:08:38.140994    4886 checks.go:868] pulling: registry.aliyuncs.com/google_containers/kube-scheduler:v1.32.0<br>I0322 20:09:00.270475    4886 checks.go:868] pulling: registry.aliyuncs.com/google_containers/kube-proxy:v1.32.0<br>I0322 20:09:26.947685    4886 checks.go:863] image exists: registry.aliyuncs.com/google_containers/coredns:v1.11.3<br>I0322 20:09:26.948207    4886 checks.go:863] image exists: registry.aliyuncs.com/google_containers/pause:3.10<br>I0322 20:09:26.948594    4886 checks.go:863] image exists: registry.aliyuncs.com/google_containers/etcd:3.5.16-0<br>[certs] Using certificateDir folder <span class="hljs-string">&quot;/etc/kubernetes/pki&quot;</span><br>I0322 20:09:26.948692    4886 certs.go:112] creating a new certificate authority <span class="hljs-keyword">for</span> ca<br>[certs] Generating <span class="hljs-string">&quot;ca&quot;</span> certificate and key<br>I0322 20:09:27.066597    4886 certs.go:473] validating certificate period <span class="hljs-keyword">for</span> ca certificate<br>[certs] Generating <span class="hljs-string">&quot;apiserver&quot;</span> certificate and key<br>[certs] apiserver serving cert is signed <span class="hljs-keyword">for</span> DNS names [k8s-master01 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.11.161]<br>[certs] Generating <span class="hljs-string">&quot;apiserver-kubelet-client&quot;</span> certificate and key<br>I0322 20:09:27.313725    4886 certs.go:112] creating a new certificate authority <span class="hljs-keyword">for</span> front-proxy-ca<br>[certs] Generating <span class="hljs-string">&quot;front-proxy-ca&quot;</span> certificate and key<br>I0322 20:09:27.439421    4886 certs.go:473] validating certificate period <span class="hljs-keyword">for</span> front-proxy-ca certificate<br>[certs] Generating <span class="hljs-string">&quot;front-proxy-client&quot;</span> certificate and key<br>I0322 20:09:27.532545    4886 certs.go:112] creating a new certificate authority <span class="hljs-keyword">for</span> etcd-ca<br>[certs] Generating <span class="hljs-string">&quot;etcd/ca&quot;</span> certificate and key<br>I0322 20:09:27.631261    4886 certs.go:473] validating certificate period <span class="hljs-keyword">for</span> etcd/ca certificate<br>[certs] Generating <span class="hljs-string">&quot;etcd/server&quot;</span> certificate and key<br>[certs] etcd/server serving cert is signed <span class="hljs-keyword">for</span> DNS names [k8s-master01 localhost] and IPs [192.168.11.161 127.0.0.1 ::1]<br>[certs] Generating <span class="hljs-string">&quot;etcd/peer&quot;</span> certificate and key<br>[certs] etcd/peer serving cert is signed <span class="hljs-keyword">for</span> DNS names [k8s-master01 localhost] and IPs [192.168.11.161 127.0.0.1 ::1]<br>[certs] Generating <span class="hljs-string">&quot;etcd/healthcheck-client&quot;</span> certificate and key<br>[certs] Generating <span class="hljs-string">&quot;apiserver-etcd-client&quot;</span> certificate and key<br>I0322 20:09:28.312889    4886 certs.go:78] creating new public/private key files <span class="hljs-keyword">for</span> signing service account users<br>[certs] Generating <span class="hljs-string">&quot;sa&quot;</span> key and public key<br>[kubeconfig] Using kubeconfig folder <span class="hljs-string">&quot;/etc/kubernetes&quot;</span><br>I0322 20:09:28.495281    4886 kubeconfig.go:111] creating kubeconfig file <span class="hljs-keyword">for</span> admin.conf<br>[kubeconfig] Writing <span class="hljs-string">&quot;admin.conf&quot;</span> kubeconfig file<br>I0322 20:09:28.848054    4886 kubeconfig.go:111] creating kubeconfig file <span class="hljs-keyword">for</span> super-admin.conf<br>[kubeconfig] Writing <span class="hljs-string">&quot;super-admin.conf&quot;</span> kubeconfig file<br>I0322 20:09:29.129094    4886 kubeconfig.go:111] creating kubeconfig file <span class="hljs-keyword">for</span> kubelet.conf<br>[kubeconfig] Writing <span class="hljs-string">&quot;kubelet.conf&quot;</span> kubeconfig file<br>I0322 20:09:29.386206    4886 kubeconfig.go:111] creating kubeconfig file <span class="hljs-keyword">for</span> controller-manager.conf<br>[kubeconfig] Writing <span class="hljs-string">&quot;controller-manager.conf&quot;</span> kubeconfig file<br>I0322 20:09:29.483874    4886 kubeconfig.go:111] creating kubeconfig file <span class="hljs-keyword">for</span> scheduler.conf<br>[kubeconfig] Writing <span class="hljs-string">&quot;scheduler.conf&quot;</span> kubeconfig file<br>[etcd] Creating static Pod manifest <span class="hljs-keyword">for</span> <span class="hljs-built_in">local</span> etcd <span class="hljs-keyword">in</span> <span class="hljs-string">&quot;/etc/kubernetes/manifests&quot;</span><br>I0322 20:09:29.607843    4886 local.go:66] [etcd] wrote Static Pod manifest <span class="hljs-keyword">for</span> a <span class="hljs-built_in">local</span> etcd member to <span class="hljs-string">&quot;/etc/kubernetes/manifests/etcd.yaml&quot;</span><br>[control-plane] Using manifest folder <span class="hljs-string">&quot;/etc/kubernetes/manifests&quot;</span><br>[control-plane] Creating static Pod manifest <span class="hljs-keyword">for</span> <span class="hljs-string">&quot;kube-apiserver&quot;</span><br>I0322 20:09:29.607888    4886 manifests.go:104] [control-plane] getting StaticPodSpecs<br>I0322 20:09:29.608085    4886 certs.go:473] validating certificate period <span class="hljs-keyword">for</span> CA certificate<br>I0322 20:09:29.608178    4886 manifests.go:130] [control-plane] adding volume <span class="hljs-string">&quot;ca-certs&quot;</span> <span class="hljs-keyword">for</span> component <span class="hljs-string">&quot;kube-apiserver&quot;</span><br>I0322 20:09:29.608192    4886 manifests.go:130] [control-plane] adding volume <span class="hljs-string">&quot;etc-ca-certificates&quot;</span> <span class="hljs-keyword">for</span> component <span class="hljs-string">&quot;kube-apiserver&quot;</span><br>I0322 20:09:29.608198    4886 manifests.go:130] [control-plane] adding volume <span class="hljs-string">&quot;k8s-certs&quot;</span> <span class="hljs-keyword">for</span> component <span class="hljs-string">&quot;kube-apiserver&quot;</span><br>I0322 20:09:29.608206    4886 manifests.go:130] [control-plane] adding volume <span class="hljs-string">&quot;usr-local-share-ca-certificates&quot;</span> <span class="hljs-keyword">for</span> component <span class="hljs-string">&quot;kube-apiserver&quot;</span><br>I0322 20:09:29.608214    4886 manifests.go:130] [control-plane] adding volume <span class="hljs-string">&quot;usr-share-ca-certificates&quot;</span> <span class="hljs-keyword">for</span> component <span class="hljs-string">&quot;kube-apiserver&quot;</span><br>I0322 20:09:29.609567    4886 manifests.go:159] [control-plane] wrote static Pod manifest <span class="hljs-keyword">for</span> component <span class="hljs-string">&quot;kube-apiserver&quot;</span> to <span class="hljs-string">&quot;/etc/kubernetes/manifests/kube-apiserver.yaml&quot;</span><br>[control-plane] Creating static Pod manifest <span class="hljs-keyword">for</span> <span class="hljs-string">&quot;kube-controller-manager&quot;</span><br>I0322 20:09:29.609599    4886 manifests.go:104] [control-plane] getting StaticPodSpecs<br>I0322 20:09:29.609807    4886 manifests.go:130] [control-plane] adding volume <span class="hljs-string">&quot;ca-certs&quot;</span> <span class="hljs-keyword">for</span> component <span class="hljs-string">&quot;kube-controller-manager&quot;</span><br>I0322 20:09:29.609819    4886 manifests.go:130] [control-plane] adding volume <span class="hljs-string">&quot;etc-ca-certificates&quot;</span> <span class="hljs-keyword">for</span> component <span class="hljs-string">&quot;kube-controller-manager&quot;</span><br>I0322 20:09:29.609824    4886 manifests.go:130] [control-plane] adding volume <span class="hljs-string">&quot;flexvolume-dir&quot;</span> <span class="hljs-keyword">for</span> component <span class="hljs-string">&quot;kube-controller-manager&quot;</span><br>I0322 20:09:29.609835    4886 manifests.go:130] [control-plane] adding volume <span class="hljs-string">&quot;k8s-certs&quot;</span> <span class="hljs-keyword">for</span> component <span class="hljs-string">&quot;kube-controller-manager&quot;</span><br>I0322 20:09:29.609841    4886 manifests.go:130] [control-plane] adding volume <span class="hljs-string">&quot;kubeconfig&quot;</span> <span class="hljs-keyword">for</span> component <span class="hljs-string">&quot;kube-controller-manager&quot;</span><br>I0322 20:09:29.609846    4886 manifests.go:130] [control-plane] adding volume <span class="hljs-string">&quot;usr-local-share-ca-certificates&quot;</span> <span class="hljs-keyword">for</span> component <span class="hljs-string">&quot;kube-controller-manager&quot;</span><br>I0322 20:09:29.609854    4886 manifests.go:130] [control-plane] adding volume <span class="hljs-string">&quot;usr-share-ca-certificates&quot;</span> <span class="hljs-keyword">for</span> component <span class="hljs-string">&quot;kube-controller-manager&quot;</span><br>I0322 20:09:29.610610    4886 manifests.go:159] [control-plane] wrote static Pod manifest <span class="hljs-keyword">for</span> component <span class="hljs-string">&quot;kube-controller-manager&quot;</span> to <span class="hljs-string">&quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&quot;</span><br>[control-plane] Creating static Pod manifest <span class="hljs-keyword">for</span> <span class="hljs-string">&quot;kube-scheduler&quot;</span><br>I0322 20:09:29.610640    4886 manifests.go:104] [control-plane] getting StaticPodSpecs<br>I0322 20:09:29.610848    4886 manifests.go:130] [control-plane] adding volume <span class="hljs-string">&quot;kubeconfig&quot;</span> <span class="hljs-keyword">for</span> component <span class="hljs-string">&quot;kube-scheduler&quot;</span><br>I0322 20:09:29.611322    4886 manifests.go:159] [control-plane] wrote static Pod manifest <span class="hljs-keyword">for</span> component <span class="hljs-string">&quot;kube-scheduler&quot;</span> to <span class="hljs-string">&quot;/etc/kubernetes/manifests/kube-scheduler.yaml&quot;</span><br>I0322 20:09:29.611339    4886 kubelet.go:70] Stopping the kubelet<br>[kubelet-start] Writing kubelet environment file with flags to file <span class="hljs-string">&quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br>[kubelet-start] Writing kubelet configuration to file <span class="hljs-string">&quot;/var/lib/kubelet/config.yaml&quot;</span><br>[kubelet-start] Starting the kubelet<br>I0322 20:09:29.948568    4886 loader.go:402] Config loaded from file:  /etc/kubernetes/admin.conf<br>I0322 20:09:29.949088    4886 envvar.go:172] <span class="hljs-string">&quot;Feature gate default state&quot;</span> feature=<span class="hljs-string">&quot;ClientsAllowCBOR&quot;</span> enabled=<span class="hljs-literal">false</span><br>I0322 20:09:29.949115    4886 envvar.go:172] <span class="hljs-string">&quot;Feature gate default state&quot;</span> feature=<span class="hljs-string">&quot;ClientsPreferCBOR&quot;</span> enabled=<span class="hljs-literal">false</span><br>I0322 20:09:29.949124    4886 envvar.go:172] <span class="hljs-string">&quot;Feature gate default state&quot;</span> feature=<span class="hljs-string">&quot;InformerResourceVersion&quot;</span> enabled=<span class="hljs-literal">false</span><br>I0322 20:09:29.949144    4886 envvar.go:172] <span class="hljs-string">&quot;Feature gate default state&quot;</span> feature=<span class="hljs-string">&quot;WatchListClient&quot;</span> enabled=<span class="hljs-literal">false</span><br>[wait-control-plane] Waiting <span class="hljs-keyword">for</span> the kubelet to boot up the control plane as static Pods from directory <span class="hljs-string">&quot;/etc/kubernetes/manifests&quot;</span><br>[kubelet-check] Waiting <span class="hljs-keyword">for</span> a healthy kubelet at http://127.0.0.1:10248/healthz. This can take up to 4m0s<br>[kubelet-check] The kubelet is healthy after 502.456949ms<br>[api-check] Waiting <span class="hljs-keyword">for</span> a healthy API server. This can take up to 4m0s<br>I0322 20:09:30.452200    4886 wait.go:220] <span class="hljs-string">&quot;Request Body&quot;</span> body=<span class="hljs-string">&quot;&quot;</span><br>I0322 20:09:30.452302    4886 round_trippers.go:473] curl -v -XGET  -H <span class="hljs-string">&quot;Accept: application/json, */*&quot;</span> -H <span class="hljs-string">&quot;User-Agent: kubeadm/v1.32.3 (linux/amd64) kubernetes/32cc146&quot;</span> <span class="hljs-string">&#x27;https://192.168.11.161:6443/healthz?timeout=10s&#x27;</span><br>I0322 20:09:30.452515    4886 round_trippers.go:515] HTTP Trace: Dial to tcp:192.168.11.161:6443 failed: dial tcp 192.168.11.161:6443: connect: connection refused<br>I0322 20:09:30.452547    4886 round_trippers.go:560] GET https://192.168.11.161:6443/healthz?timeout=10s  <span class="hljs-keyword">in</span> 0 milliseconds<br>I0322 20:09:30.452664    4886 round_trippers.go:577] HTTP Statistics: DNSLookup 0 ms Dial 0 ms TLSHandshake 0 ms Duration 0 ms<br>I0322 20:09:30.452746    4886 round_trippers.go:584] Response Headers:<br>I0322 20:09:30.952488    4886 wait.go:220] <span class="hljs-string">&quot;Request Body&quot;</span> body=<span class="hljs-string">&quot;&quot;</span><br>I0322 20:09:30.952695    4886 round_trippers.go:473] curl -v -XGET  -H <span class="hljs-string">&quot;Accept: application/json, */*&quot;</span> -H <span class="hljs-string">&quot;User-Agent: kubeadm/v1.32.3 (linux/amd64) kubernetes/32cc146&quot;</span> <span class="hljs-string">&#x27;https://192.168.11.161:6443/healthz?timeout=10s&#x27;</span><br>I0322 20:09:30.953055    4886 round_trippers.go:515] HTTP Trace: Dial to tcp:192.168.11.161:6443 failed: dial tcp 192.168.11.161:6443: connect: connection refused<br>I0322 20:09:30.953141    4886 round_trippers.go:560] GET https://192.168.11.161:6443/healthz?timeout=10s  <span class="hljs-keyword">in</span> 0 milliseconds<br>I0322 20:09:30.953178    4886 round_trippers.go:577] HTTP Statistics: DNSLookup 0 ms Dial 0 ms TLSHandshake 0 ms Duration 0 ms<br>I0322 20:09:30.953196    4886 round_trippers.go:584] Response Headers:<br>I0322 20:09:31.453072    4886 wait.go:220] <span class="hljs-string">&quot;Request Body&quot;</span> body=<span class="hljs-string">&quot;&quot;</span><br>I0322 20:09:31.453425    4886 round_trippers.go:473] curl -v -XGET  -H <span class="hljs-string">&quot;Accept: application/json, */*&quot;</span> -H <span class="hljs-string">&quot;User-Agent: kubeadm/v1.32.3 (linux/amd64) kubernetes/32cc146&quot;</span> <span class="hljs-string">&#x27;https://192.168.11.161:6443/healthz?timeout=10s&#x27;</span><br>I0322 20:09:31.453892    4886 round_trippers.go:515] HTTP Trace: Dial to tcp:192.168.11.161:6443 failed: dial tcp 192.168.11.161:6443: connect: connection refused<br>I0322 20:09:31.453935    4886 round_trippers.go:560] GET https://192.168.11.161:6443/healthz?timeout=10s  <span class="hljs-keyword">in</span> 0 milliseconds<br>I0322 20:09:31.453947    4886 round_trippers.go:577] HTTP Statistics: DNSLookup 0 ms Dial 0 ms TLSHandshake 0 ms Duration 0 ms<br>I0322 20:09:31.453955    4886 round_trippers.go:584] Response Headers:<br>I0322 20:09:31.952836    4886 wait.go:220] <span class="hljs-string">&quot;Request Body&quot;</span> body=<span class="hljs-string">&quot;&quot;</span><br>I0322 20:09:31.953094    4886 round_trippers.go:473] curl -v -XGET  -H <span class="hljs-string">&quot;Accept: application/json, */*&quot;</span> -H <span class="hljs-string">&quot;User-Agent: kubeadm/v1.32.3 (linux/amd64) kubernetes/32cc146&quot;</span> <span class="hljs-string">&#x27;https://192.168.11.161:6443/healthz?timeout=10s&#x27;</span><br>I0322 20:09:31.953553    4886 round_trippers.go:517] HTTP Trace: Dial to tcp:192.168.11.161:6443 succeed<br>I0322 20:09:33.315605    4886 round_trippers.go:560] GET https://192.168.11.161:6443/healthz?timeout=10s 403 Forbidden <span class="hljs-keyword">in</span> 1362 milliseconds<br>I0322 20:09:33.315644    4886 round_trippers.go:577] HTTP Statistics: DNSLookup 0 ms Dial 0 ms TLSHandshake 1336 ms ServerProcessing 25 ms Duration 1362 ms<br>I0322 20:09:33.315657    4886 round_trippers.go:584] Response Headers:<br>I0322 20:09:33.315670    4886 round_trippers.go:587]     X-Content-Type-Options: nosniff<br>I0322 20:09:33.315701    4886 round_trippers.go:587]     X-Kubernetes-Pf-Flowschema-Uid: <br>I0322 20:09:33.315710    4886 round_trippers.go:587]     X-Kubernetes-Pf-Prioritylevel-Uid: <br>I0322 20:09:33.315717    4886 round_trippers.go:587]     Content-Length: 192<br>I0322 20:09:33.315723    4886 round_trippers.go:587]     Date: Sat, 22 Mar 2025 12:09:33 GMT<br>I0322 20:09:33.315731    4886 round_trippers.go:587]     Audit-Id: 989b38d0-29d4-4450-b564-12e6142c52b7<br>I0322 20:09:33.315737    4886 round_trippers.go:587]     Cache-Control: no-cache, private<br>I0322 20:09:33.315741    4886 round_trippers.go:587]     Content-Type: application/json<br>I0322 20:09:33.316997    4886 wait.go:220] <span class="hljs-string">&quot;Response Body&quot;</span> body=&lt;<br>	&#123;<span class="hljs-string">&quot;kind&quot;</span>:<span class="hljs-string">&quot;Status&quot;</span>,<span class="hljs-string">&quot;apiVersion&quot;</span>:<span class="hljs-string">&quot;v1&quot;</span>,<span class="hljs-string">&quot;metadata&quot;</span>:&#123;&#125;,<span class="hljs-string">&quot;status&quot;</span>:<span class="hljs-string">&quot;Failure&quot;</span>,<span class="hljs-string">&quot;message&quot;</span>:<span class="hljs-string">&quot;forbidden: User \&quot;kubernetes-admin\&quot; cannot get path \&quot;/healthz\&quot;&quot;</span>,<span class="hljs-string">&quot;reason&quot;</span>:<span class="hljs-string">&quot;Forbidden&quot;</span>,<span class="hljs-string">&quot;details&quot;</span>:&#123;&#125;,<span class="hljs-string">&quot;code&quot;</span>:403&#125;<br> &gt;<br><br>.......   中间冗长的日志省略<br><br>I0322 20:09:37.294961    4886 round_trippers.go:473] curl -v -XPOST  -H <span class="hljs-string">&quot;User-Agent: kubeadm/v1.32.3 (linux/amd64) kubernetes/32cc146&quot;</span> -H <span class="hljs-string">&quot;Accept: application/vnd.kubernetes.protobuf,application/json&quot;</span> -H <span class="hljs-string">&quot;Content-Type: application/vnd.kubernetes.protobuf&quot;</span> <span class="hljs-string">&#x27;https://192.168.11.161:6443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings?timeout=10s&#x27;</span><br>I0322 20:09:37.298583    4886 round_trippers.go:560] POST https://192.168.11.161:6443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings?timeout=10s 201 Created <span class="hljs-keyword">in</span> 3 milliseconds<br>I0322 20:09:37.298609    4886 round_trippers.go:577] HTTP Statistics: GetConnection 0 ms ServerProcessing 3 ms Duration 3 ms<br>I0322 20:09:37.298634    4886 round_trippers.go:584] Response Headers:<br>I0322 20:09:37.298649    4886 round_trippers.go:587]     X-Kubernetes-Pf-Flowschema-Uid: 9a8a526f-0630-4d03-b851-7ace48e8dc05<br>I0322 20:09:37.298661    4886 round_trippers.go:587]     X-Kubernetes-Pf-Prioritylevel-Uid: d044472a-2a80-46df-8bc8-7d94366f6e34<br>I0322 20:09:37.298667    4886 round_trippers.go:587]     Content-Length: 385<br>I0322 20:09:37.298675    4886 round_trippers.go:587]     Date: Sat, 22 Mar 2025 12:09:37 GMT<br>I0322 20:09:37.298680    4886 round_trippers.go:587]     Audit-Id: ece06481-523b-4fe4-9d2c-2d369eceecc1<br>I0322 20:09:37.298690    4886 round_trippers.go:587]     Cache-Control: no-cache, private<br>I0322 20:09:37.298695    4886 round_trippers.go:587]     Content-Type: application/vnd.kubernetes.protobuf<br>I0322 20:09:37.298744    4886 type.go:252] <span class="hljs-string">&quot;Response Body&quot;</span> body=&lt;<br>	00000000  6b 38 73 00 0a 2b 0a 1c  72 62 61 63 2e 61 75 74  |k8s..+..rbac.aut|<br>	00000010  68 6f 72 69 7a 61 74 69  6f 6e 2e 6b 38 73 2e 69  |horization.k8s.i|<br>	00000020  6f 2f 76 31 12 0b 52 6f  6c 65 42 69 6e 64 69 6e  |o/v1..RoleBindin|<br>	00000030  67 12 c9 02 0a c0 01 0a  0a 6b 75 62 65 2d 70 72  |g........kube-pr|<br>	00000040  6f 78 79 12 00 1a 0b 6b  75 62 65 2d 73 79 73 74  |oxy....kube-syst|<br>	00000050  65 6d 22 00 2a 24 63 38  62 62 36 66 63 64 2d 38  |em<span class="hljs-string">&quot;.*<span class="hljs-variable">$c8bb6fcd</span>-8|</span><br><span class="hljs-string">	00000060  66 35 38 2d 34 35 35 34  2d 39 66 36 30 2d 38 39  |f58-4554-9f60-89|</span><br><span class="hljs-string">	00000070  39 32 61 39 65 36 64 36  64 39 32 03 33 30 33 38  |92a9e6d6d92.3038|</span><br><span class="hljs-string">	00000080  00 42 08 08 81 d1 fa be  06 10 00 8a 01 69 0a 07  |.B...........i..|</span><br><span class="hljs-string">	00000090  6b 75 62 65 61 64 6d 12  06 55 70 64 61 74 65 1a  |kubeadm..Update.|</span><br><span class="hljs-string">	000000a0  1c 72 62 61 63 2e 61 75  74 68 6f 72 69 7a 61 74  |.rbac.authorizat|</span><br><span class="hljs-string">	000000b0  69 6f 6e 2e 6b 38 73 2e  69 6f 2f 76 31 22 08 08  |ion.k8s.io/v1&quot;</span>..|<br>	000000c0  81 d1 fa be 06 10 00 32  08 46 69 65 6c 64 73 56  |.......2.FieldsV|<br>	000000d0  31 3a 22 0a 20 7b 22 66  3a 72 6f 6c 65 52 65 66  |1:<span class="hljs-string">&quot;. &#123;&quot;</span>f:roleRef|<br>	000000e0  22 3a 7b 7d 2c 22 66 3a  73 75 62 6a 65 63 74 73  |<span class="hljs-string">&quot;:&#123;&#125;,&quot;</span>f:subjects|<br>	000000f0  22 3a 7b 7d 7d 42 00 12  55 0a 05 47 72 6f 75 70  |<span class="hljs-string">&quot;:&#123;&#125;&#125;B..U..Group|</span><br><span class="hljs-string">	00000100  12 19 72 62 61 63 2e 61  75 74 68 6f 72 69 7a 61  |..rbac.authoriza|</span><br><span class="hljs-string">	00000110  74 69 6f 6e 2e 6b 38 73  2e 69 6f 1a 2f 73 79 73  |tion.k8s.io./sys|</span><br><span class="hljs-string">	00000120  74 65 6d 3a 62 6f 6f 74  73 74 72 61 70 70 65 72  |tem:bootstrapper|</span><br><span class="hljs-string">	00000130  73 3a 6b 75 62 65 61 64  6d 3a 64 65 66 61 75 6c  |s:kubeadm:defaul|</span><br><span class="hljs-string">	00000140  74 2d 6e 6f 64 65 2d 74  6f 6b 65 6e 22 00 1a 2d  |t-node-token&quot;</span>..-|<br>	00000150  0a 19 72 62 61 63 2e 61  75 74 68 6f 72 69 7a 61  |..rbac.authoriza|<br>	00000160  74 69 6f 6e 2e 6b 38 73  2e 69 6f 12 04 52 6f 6c  |tion.k8s.io..Rol|<br>	00000170  65 1a 0a 6b 75 62 65 2d  70 72 6f 78 79 1a 00 22  |e..kube-proxy..<span class="hljs-string">&quot;|</span><br><span class="hljs-string">	00000180  00                                                |.|</span><br><span class="hljs-string"> &gt;</span><br><span class="hljs-string">[addons] Applied essential addon: kube-proxy</span><br><span class="hljs-string">I0322 20:09:37.299409    4886 loader.go:402] Config loaded from file:  /etc/kubernetes/admin.conf</span><br><span class="hljs-string">I0322 20:09:37.300120    4886 loader.go:402] Config loaded from file:  /etc/kubernetes/admin.conf</span><br><span class="hljs-string"></span><br><span class="hljs-string">Your Kubernetes control-plane has initialized successfully!</span><br><span class="hljs-string"></span><br><span class="hljs-string">To start using your cluster, you need to run the following as a regular user:</span><br><span class="hljs-string"></span><br><span class="hljs-string">  mkdir -p <span class="hljs-variable">$HOME</span>/.kube</span><br><span class="hljs-string">  sudo cp -i /etc/kubernetes/admin.conf <span class="hljs-variable">$HOME</span>/.kube/config</span><br><span class="hljs-string">  sudo chown <span class="hljs-subst">$(id -u)</span>:<span class="hljs-subst">$(id -g)</span> <span class="hljs-variable">$HOME</span>/.kube/config</span><br><span class="hljs-string"></span><br><span class="hljs-string">Alternatively, if you are the root user, you can run:</span><br><span class="hljs-string"></span><br><span class="hljs-string">  export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="hljs-string"></span><br><span class="hljs-string">You should now deploy a pod network to the cluster.</span><br><span class="hljs-string">Run &quot;</span>kubectl apply -f [podnetwork].yaml<span class="hljs-string">&quot; with one of the options listed at:</span><br><span class="hljs-string">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="hljs-string"></span><br><span class="hljs-string">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="hljs-string"></span><br><span class="hljs-string">kubeadm join 192.168.11.161:6443 --token abcdef.0123456789abcdef \</span><br><span class="hljs-string">	--discovery-token-ca-cert-hash sha256:c7a1d928a82c30bec6dec880092339e64309b24cc01782d8a9d9c6c0ecfde58f </span><br><span class="hljs-string"></span><br></code></pre></td></tr></table></figure>


<h2 id="3-4-准备kubectl配置文件"><a href="#3-4-准备kubectl配置文件" class="headerlink" title="3.4 准备kubectl配置文件"></a>3.4 准备kubectl配置文件</h2><p>以下操作仅在Master节点上进行。</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">mkdir -p <span class="hljs-variable">$HOME</span>/.kube<br>sudo cp -i /etc/kubernetes/admin.conf <span class="hljs-variable">$HOME</span>/.kube/config<br>sudo chown $(id -u):$(id -g) <span class="hljs-variable">$HOME</span>/.kube/config<br></code></pre></td></tr></table></figure>

<h2 id="3-5-工作节点加入集群"><a href="#3-5-工作节点加入集群" class="headerlink" title="3.5 工作节点加入集群"></a>3.5 工作节点加入集群</h2><h3 id="k8s-worker01节点加入集群"><a href="#k8s-worker01节点加入集群" class="headerlink" title="k8s-worker01节点加入集群"></a>k8s-worker01节点加入集群</h3><p>以下操作仅在Worker节点操作</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-worker01:~<span class="hljs-comment"># kubeadm join 192.168.11.161:6443 --token abcdef.0123456789abcdef --discovery-token-ca-cert-hash sha256:c7a1d928a82c30bec6dec880092339e64309b24cc01782d8a9d9c6c0ecfde58f </span><br></code></pre></td></tr></table></figure>

<h3 id="k8s-worker02节点加入集群"><a href="#k8s-worker02节点加入集群" class="headerlink" title="k8s-worker02节点加入集群"></a>k8s-worker02节点加入集群</h3><p>以下操作仅在Worker节点操作</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-worker02:~<span class="hljs-comment"># kubeadm join 192.168.11.161:6443 --token abcdef.0123456789abcdef --discovery-token-ca-cert-hash sha256:c7a1d928a82c30bec6dec880092339e64309b24cc01782d8a9d9c6c0ecfde58f</span><br></code></pre></td></tr></table></figure>


<h2 id="3-6-验证K8S集群节点是否可用"><a href="#3-6-验证K8S集群节点是否可用" class="headerlink" title="3.6 验证K8S集群节点是否可用"></a>3.6 验证K8S集群节点是否可用</h2><p>在Master节点检查集群节点是否可用 </p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubectl get nodes</span><br><br>NAME           STATUS     ROLES           AGE     VERSION<br>k8s-master01   NotReady   control-plane   103m    v1.32.3<br>k8s-worker01   NotReady   &lt;none&gt;          4m12s   v1.32.3<br>k8s-worker02   NotReady   &lt;none&gt;          4m12s   v1.32.3<br></code></pre></td></tr></table></figure>

<p>在Master节点检查集群Pod状态（按命名空间筛选） </p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubectl get pods -n kube-system</span><br><br>NAME                                   READY   STATUS    RESTARTS   AGE<br>coredns-6766b7b6bb-6dtl7               0/1     Pending   0          104m<br>coredns-6766b7b6bb-lrpw7               0/1     Pending   0          104m<br>etcd-k8s-master01                      1/1     Running   0          104m      // 静态pod<br>kube-apiserver-k8s-master01            1/1     Running   0          104m      // 静态pod<br>kube-controller-manager-k8s-master01   1/1     Running   0          104m      // 静态pod    <br>kube-proxy-6g8dn                       1/1     Running   0          104m      <br>kube-proxy-kmzv6                       1/1     Running   0          5m1s<br>kube-proxy-pj2t5                       1/1     Running   0          5m1s<br>kube-scheduler-k8s-master01            1/1     Running   0          104m      // 静态pod <br></code></pre></td></tr></table></figure>

<p>查看命名空间</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubectl get cs</span><br><br>Warning: v1 ComponentStatus is deprecated <span class="hljs-keyword">in</span> v1.19+<br>NAME                 STATUS    MESSAGE   ERROR<br>etcd-0               Healthy   ok        <br>scheduler            Healthy   ok        <br>controller-manager   Healthy   ok  <br></code></pre></td></tr></table></figure>


<h1 id="四、K8S集群网络插件calico部署"><a href="#四、K8S集群网络插件calico部署" class="headerlink" title="四、K8S集群网络插件calico部署"></a>四、K8S集群网络插件calico部署</h1><p><a target="_blank" rel="noopener" href="https://projectcalico.docs.tigera.io/about/about-calico">calico网络插件</a></p>
<h2 id="4-1-第一步：安装tigera-operator"><a href="#4-1-第一步：安装tigera-operator" class="headerlink" title="4.1 第一步：安装tigera-operator"></a>4.1 第一步：安装tigera-operator</h2><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.29.2/manifests/tigera-operator.yaml</span><br></code></pre></td></tr></table></figure>

<h3 id="4-1-1-输出内容："><a href="#4-1-1-输出内容：" class="headerlink" title="4.1.1 输出内容："></a>4.1.1 输出内容：</h3><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.29.2/manifests/tigera-operator.yaml</span><br><br>namespace/tigera-operator created<br>customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created<br>customresourcedefinition.apiextensions.k8s.io/bgpfilters.crd.projectcalico.org created<br>customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created<br>customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created<br>customresourcedefinition.apiextensions.k8s.io/caliconodestatuses.crd.projectcalico.org created<br>customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created<br>customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created<br>customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created<br>customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org created<br>customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created<br>customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created<br>customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created<br>customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created<br>customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created<br>customresourcedefinition.apiextensions.k8s.io/ipreservations.crd.projectcalico.org created<br>customresourcedefinition.apiextensions.k8s.io/kubecontrollersconfigurations.crd.projectcalico.org created<br>customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created<br>customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created<br>customresourcedefinition.apiextensions.k8s.io/tiers.crd.projectcalico.org created<br>customresourcedefinition.apiextensions.k8s.io/adminnetworkpolicies.policy.networking.k8s.io created<br>customresourcedefinition.apiextensions.k8s.io/apiservers.operator.tigera.io created<br>customresourcedefinition.apiextensions.k8s.io/imagesets.operator.tigera.io created<br>customresourcedefinition.apiextensions.k8s.io/installations.operator.tigera.io created<br>customresourcedefinition.apiextensions.k8s.io/tigerastatuses.operator.tigera.io created<br>serviceaccount/tigera-operator created<br>clusterrole.rbac.authorization.k8s.io/tigera-operator created<br>clusterrolebinding.rbac.authorization.k8s.io/tigera-operator created<br>deployment.apps/tigera-operator created<br></code></pre></td></tr></table></figure>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubectl get ns</span><br><br>NAME              STATUS   AGE<br>default           Active   116m<br>kube-node-lease   Active   116m<br>kube-public       Active   116m<br>kube-system       Active   116m<br>tigera-operator   Active   106s      // 新增的pod<br></code></pre></td></tr></table></figure>


<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubectl get pods -n tigera-operator</span><br><br>NAME                              READY   STATUS             RESTARTS   AGE<br>tigera-operator-ccfc44587-vswlt   0/1     ImagePullBackOff   0          3m44s<br></code></pre></td></tr></table></figure>


<h2 id="4-2-第二步：安装calico-system"><a href="#4-2-第二步：安装calico-system" class="headerlink" title="4.2 第二步：安装calico-system"></a>4.2 第二步：安装calico-system</h2><h3 id="4-2-1-下载custom-resources-yaml"><a href="#4-2-1-下载custom-resources-yaml" class="headerlink" title="4.2.1 下载custom-resources.yaml"></a>4.2.1 下载custom-resources.yaml</h3><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># wget https://raw.githubusercontent.com/projectcalico/calico/v3.29.2/manifests/custom-resources.yaml</span><br></code></pre></td></tr></table></figure>


<h3 id="4-2-2-修改custom-resources-yaml中的网段cidr配置"><a href="#4-2-2-修改custom-resources-yaml中的网段cidr配置" class="headerlink" title="4.2.2 修改custom-resources.yaml中的网段cidr配置"></a>4.2.2 修改custom-resources.yaml中的网段cidr配置</h3><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># nano custom-resources.yaml</span><br></code></pre></td></tr></table></figure>

<figure class="hljs highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># This section includes base Calico installation configuration.</span><br><span class="hljs-comment"># For more information, see: https://projectcalico.docs.tigera.io/master/reference/installation/api#operator.tigera.io/v1.Installation</span><br> <span class="hljs-attr">apiVersion:</span> <span class="hljs-string">operator.tigera.io/v1</span><br> <span class="hljs-attr">kind:</span> <span class="hljs-string">Installation</span><br> <span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">default</span><br> <span class="hljs-attr">spec:</span><br>  <span class="hljs-comment"># Configures Calico networking.</span><br>  <span class="hljs-attr">calicoNetwork:</span><br>    <span class="hljs-comment"># <span class="hljs-doctag">Note:</span> The ipPools section cannot be modified post-install.</span><br>    <span class="hljs-attr">ipPools:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">blockSize:</span> <span class="hljs-number">26</span><br>      <span class="hljs-attr">cidr:</span> <span class="hljs-number">10.244</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><span class="hljs-string">/16</span>                <span class="hljs-comment"># 修改此行内容为初始化时定义的pod network cidr</span><br>      <span class="hljs-attr">encapsulation:</span> <span class="hljs-string">VXLANCrossSubnet</span><br>      <span class="hljs-attr">natOutgoing:</span> <span class="hljs-string">Enabled</span><br>      <span class="hljs-attr">nodeSelector:</span> <span class="hljs-string">all()</span><br>      <br><span class="hljs-meta">---</span><br><span class="hljs-comment"># This section configures the Calico API server.</span><br><span class="hljs-comment"># For more information, see: https://projectcalico.docs.tigera.io/master/reference/installation/api#operator.tigera.io/v1.APIServer</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">operator.tigera.io/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">APIServer</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">default</span><br> <span class="hljs-attr">spec:</span> &#123;&#125;<br></code></pre></td></tr></table></figure>


<ul>
<li>再次检查修改后的配置文件</li>
</ul>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># cat custom-resources.yaml</span><br></code></pre></td></tr></table></figure>


<h3 id="4-2-3-应用部署配置文件，进行部署"><a href="#4-2-3-应用部署配置文件，进行部署" class="headerlink" title="4.2.3 应用部署配置文件，进行部署"></a>4.2.3 应用部署配置文件，进行部署</h3><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubectl create -f custom-resources.yaml</span><br><br>installation.operator.tigera.io/default created<br>apiserver.operator.tigera.io/default created<br></code></pre></td></tr></table></figure>


<h3 id="4-2-4-检查calico安装结果"><a href="#4-2-4-检查calico安装结果" class="headerlink" title="4.2.4 检查calico安装结果"></a>4.2.4 检查calico安装结果</h3><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># watch kubectl get pods -n calico-system</span><br></code></pre></td></tr></table></figure>

<p>经过一段时间的下载安装，全部署完成后大致如下输出所示：</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubectl get pods -n calico-system</span><br><br>NAME                                      READY   STATUS    RESTARTS   AGE<br>calico-kube-controllers-cf49d8944-6zv2z   1/1     Running   0          53m<br>calico-node-2nfvf                         1/1     Running   0          53m<br>calico-node-nxhvj                         1/1     Running   0          53m<br>calico-node-v9lp9                         1/1     Running   0          53m<br>calico-typha-7b6f98bc78-49bf5             1/1     Running   0          53m<br>calico-typha-7b6f98bc78-7vhd6             1/1     Running   0          53m<br>csi-node-driver-6nbvr                     2/2     Running   0          53m<br>csi-node-driver-9cqq5                     2/2     Running   0          53m<br>csi-node-driver-9pm4t                     2/2     Running   0          53m   <br></code></pre></td></tr></table></figure>


<p>查看节点状态变化：</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubectl get nodes</span><br><br>NAME           STATUS   ROLES           AGE     VERSION<br>k8s-master01   Ready    control-plane   3h40m   v1.32.3<br>k8s-worker01   Ready    &lt;none&gt;          121m    v1.32.3<br>k8s-worker02   Ready    &lt;none&gt;          121m    v1.32.3<br></code></pre></td></tr></table></figure>

<p>查看pod状态</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubectl get pods -n kube-system</span><br><br>NAME                                   READY   STATUS    RESTARTS   AGE<br>coredns-6766b7b6bb-6dtl7               1/1     Running   0          3h42m<br>coredns-6766b7b6bb-lrpw7               1/1     Running   0          3h42m<br>etcd-k8s-master01                      1/1     Running   0          3h42m<br>kube-apiserver-k8s-master01            1/1     Running   0          3h42m<br>kube-controller-manager-k8s-master01   1/1     Running   0          3h42m<br>kube-proxy-6g8dn                       1/1     Running   0          3h42m<br>kube-proxy-kmzv6                       1/1     Running   0          122m<br>kube-proxy-pj2t5                       1/1     Running   0          122m<br>kube-scheduler-k8s-master01            1/1     Running   0          3h42m<br></code></pre></td></tr></table></figure>

<p>查看pod的IP及网段</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubectl get pods -n kube-system -o wide</span><br><br>NAME                                   READY   STATUS    RESTARTS   AGE     IP               NODE           NOMINATED NODE   READINESS GATES<br>coredns-6766b7b6bb-6dtl7               1/1     Running   0          3h43m   10.244.69.198    k8s-worker02   &lt;none&gt;           &lt;none&gt;<br>coredns-6766b7b6bb-lrpw7               1/1     Running   0          3h43m   10.244.69.197    k8s-worker02   &lt;none&gt;           &lt;none&gt;<br>etcd-k8s-master01                      1/1     Running   0          3h44m   192.168.11.161   k8s-master01   &lt;none&gt;           &lt;none&gt;<br>kube-apiserver-k8s-master01            1/1     Running   0          3h44m   192.168.11.161   k8s-master01   &lt;none&gt;           &lt;none&gt;<br>kube-controller-manager-k8s-master01   1/1     Running   0          3h44m   192.168.11.161   k8s-master01   &lt;none&gt;           &lt;none&gt;<br>kube-proxy-6g8dn                       1/1     Running   0          3h43m   192.168.11.161   k8s-master01   &lt;none&gt;           &lt;none&gt;<br>kube-proxy-kmzv6                       1/1     Running   0          124m    192.168.11.165   k8s-worker01   &lt;none&gt;           &lt;none&gt;<br>kube-proxy-pj2t5                       1/1     Running   0          124m    192.168.11.166   k8s-worker02   &lt;none&gt;           &lt;none&gt;<br>kube-scheduler-k8s-master01            1/1     Running   0          3h44m   192.168.11.161   k8s-master01   &lt;none&gt;           &lt;none&gt;<br></code></pre></td></tr></table></figure>



<h1 id="五、部署Nginx应用验证K8S集群可用性"><a href="#五、部署Nginx应用验证K8S集群可用性" class="headerlink" title="五、部署Nginx应用验证K8S集群可用性"></a>五、部署Nginx应用验证K8S集群可用性</h1><p>本章以Nginx为例，先添加nginx应用配置文件nginx.yaml，再添加相关应用配置</p>
<h2 id="5-1-配置NginxWeb部署配置文件nginx-website-yaml"><a href="#5-1-配置NginxWeb部署配置文件nginx-website-yaml" class="headerlink" title="5.1 配置NginxWeb部署配置文件nginx-website.yaml"></a>5.1 配置NginxWeb部署配置文件nginx-website.yaml</h2><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># nano /home/acanx/nginx-website.yaml</span><br></code></pre></td></tr></table></figure>

<figure class="hljs highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">apps/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Deployment</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">nginxweb</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">matchLabels:</span><br>      <span class="hljs-attr">app:</span> <span class="hljs-string">nginxwebsite</span><br>  <span class="hljs-attr">replicas:</span> <span class="hljs-number">3</span><br>  <span class="hljs-attr">template:</span><br>    <span class="hljs-attr">metadata:</span><br>      <span class="hljs-attr">labels:</span><br>        <span class="hljs-attr">app:</span> <span class="hljs-string">nginxwebsite</span><br>    <span class="hljs-attr">spec:</span><br>      <span class="hljs-attr">containers:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">nginxwebsite</span><br>        <span class="hljs-attr">image:</span> <span class="hljs-string">nginx:latest</span><br>        <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">IfNotPresent</span><br>        <span class="hljs-attr">ports:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">80</span><br><span class="hljs-meta">---</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Service</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">nginxweb-service</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">externalTrafficPolicy:</span> <span class="hljs-string">Cluster</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">app:</span> <span class="hljs-string">nginxwebsite</span><br>  <span class="hljs-attr">ports:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span><br>    <span class="hljs-attr">port:</span> <span class="hljs-number">80</span><br>    <span class="hljs-attr">targetPort:</span> <span class="hljs-number">80</span><br>    <span class="hljs-attr">nodePort:</span> <span class="hljs-number">30080</span><br>  <span class="hljs-attr">type:</span> <span class="hljs-string">NodePort</span><br></code></pre></td></tr></table></figure>


<h2 id="5-2-执行命令部署nginx服务"><a href="#5-2-执行命令部署nginx服务" class="headerlink" title="5.2 执行命令部署nginx服务"></a>5.2 执行命令部署nginx服务</h2><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubectl apply -f /home/acanx/nginx-website.yaml</span><br></code></pre></td></tr></table></figure>

<figure class="hljs highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs plain">deployment.apps&#x2F;nginxweb created<br>service&#x2F;nginxweb-service created<br></code></pre></td></tr></table></figure>


<h2 id="5-3-检查部署结果"><a href="#5-3-检查部署结果" class="headerlink" title="5.3 检查部署结果"></a>5.3 检查部署结果</h2><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubectl get deployment</span><br><br>NAME       READY   UP-TO-DATE   AVAILABLE   AGE<br>nginxweb   0/3     3            0           2m35s<br></code></pre></td></tr></table></figure>

<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubectl get pods</span><br><br>NAME                       READY   STATUS              RESTARTS   AGE<br>nginxweb-7c88f6c77-pck4f   0/1     ContainerCreating   0          3m43s<br>nginxweb-7c88f6c77-rv76n   0/1     ContainerCreating   0          3m43s<br>nginxweb-7c88f6c77-vb8xj   0/1     ContainerCreating   0          3m43s<br></code></pre></td></tr></table></figure>


<h3 id="5-3-1-测试K8S集群内访问"><a href="#5-3-1-测试K8S集群内访问" class="headerlink" title="5.3.1 测试K8S集群内访问"></a>5.3.1 测试K8S集群内访问</h3><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubectl get service</span><br><br>NAME               TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE<br>kubernetes         ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP        4h11m<br>nginxweb-service   NodePort    10.106.65.218   &lt;none&gt;        80:30080/TCP   10m<br>root@k8s-master01:~<span class="hljs-comment"># curl http://10.106.65.218               // 验证在K8S集群内布访问</span><br><br>&lt;!DOCTYPE html&gt;<br>&lt;html&gt;<br>&lt;head&gt;<br>&lt;title&gt;Welcome to nginx!&lt;/title&gt;<br>&lt;style&gt;<br>html &#123; color-scheme: light dark; &#125;<br>body &#123; width: 35em; margin: 0 auto;<br>font-family: Tahoma, Verdana, Arial, sans-serif; &#125;<br>&lt;/style&gt;<br>&lt;/head&gt;<br>&lt;body&gt;<br>&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;<br>&lt;p&gt;If you see this page, the nginx web server is successfully installed and<br>working. Further configuration is required.&lt;/p&gt;<br><br>&lt;p&gt;For online documentation and support please refer to<br>&lt;a href=<span class="hljs-string">&quot;http://nginx.org/&quot;</span>&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;<br>Commercial support is available at<br>&lt;a href=<span class="hljs-string">&quot;http://nginx.com/&quot;</span>&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;<br><br>&lt;p&gt;&lt;em&gt;Thank you <span class="hljs-keyword">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;<br>&lt;/body&gt;<br>&lt;/html&gt;<br></code></pre></td></tr></table></figure>

<h3 id="5-3-2-测试集群外访问"><a href="#5-3-2-测试集群外访问" class="headerlink" title="5.3.2 测试集群外访问"></a>5.3.2 测试集群外访问</h3><p>打开集群外的局域网内内主机，正常情况下集群内任意一个节点IP加对应端口号都可以访问，实际分别测试访问 <a target="_blank" rel="noopener" href="http://192.168.11.161:30080/">http://192.168.11.161:30080/</a> <a target="_blank" rel="noopener" href="http://192.168.11.165:30080/">http://192.168.11.165:30080/</a>  <a target="_blank" rel="noopener" href="http://192.168.11.166:30080/">http://192.168.11.166:30080/</a> 页面，以上三个url链接均可以正常打开。</p>
<p>效果如下图所示：</p>
<p><img src="/Node/imgs/03_02/Nginx-K8SMaster01.png" alt="Master01"><br><img src="/Node/imgs/03_02/Nginx-K8SWorker01.png" alt="Worker01"><br><img src="/Node/imgs/03_02/Nginx-K8SWorker02.png" alt="Worker02"></p>
<p>上述页面可以正常显示则说明nginx演示应用部署成功！</p>
<h1 id="六、-部署Kubernetes-Dashboard应用"><a href="#六、-部署Kubernetes-Dashboard应用" class="headerlink" title="六、 部署Kubernetes Dashboard应用"></a>六、 部署Kubernetes Dashboard应用</h1><ul>
<li><a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/tasks/access-application-cluster/web-ui-dashboard/">部署和访问 Kubernetes 仪表板（Dashboard）</a></li>
</ul>
<h2 id="6-1-安装Helm"><a href="#6-1-安装Helm" class="headerlink" title="6.1 安装Helm"></a>6.1 安装Helm</h2><h3 id="6-1-1-Helm介绍及下载"><a href="#6-1-1-Helm介绍及下载" class="headerlink" title="6.1.1 Helm介绍及下载"></a>6.1.1 Helm介绍及下载</h3><p>Helm 是查找、分享和使用软件构建 Kubernetes 的最优方式。</p>
<ul>
<li>官网 <a target="_blank" rel="noopener" href="https://helm.sh/">https://helm.sh/</a></li>
<li>项目地址 <a target="_blank" rel="noopener" href="https://github.com/helm/helm">https://github.com/helm/helm</a></li>
<li>Helm安装文档 <a target="_blank" rel="noopener" href="https://helm.sh/zh/docs/intro/install/">https://helm.sh/zh/docs/intro/install/</a></li>
</ul>
<h3 id="6-1-2-Helm安装"><a href="#6-1-2-Helm安装" class="headerlink" title="6.1.2 Helm安装"></a>6.1.2 Helm安装</h3><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># wget https://get.helm.sh/helm-v3.17.2-linux-amd64.tar.gz   # 下载文件</span><br><br>root@k8s-master01:~<span class="hljs-comment"># tar -zxvf /home/acanx/helm-v3.0.0-linux-amd64.tar.gz         # 解压文件</span><br><br>root@k8s-master01:~<span class="hljs-comment"># sudo mv linux-amd64/helm /usr/local/bin/helm                    # 移动到指定目录</span><br>root@k8s-master01:~<span class="hljs-comment"># sudo mv /home/acanx/helm /usr/local/bin/helm                    # 移动到指定目录</span><br><br>root@k8s-master01:~<span class="hljs-comment"># ls -l /usr/local/bin/helm</span><br><br>root@k8s-master01:~<span class="hljs-comment"># chmod 755 /usr/local/bin/helm</span><br><br>root@k8s-master01:~<span class="hljs-comment"># helm </span><br></code></pre></td></tr></table></figure>

<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># helm</span><br><br>The Kubernetes package manager<br><br>Common actions <span class="hljs-keyword">for</span> Helm:<br><br>- helm search:    search <span class="hljs-keyword">for</span> charts<br>- helm pull:      download a chart to your <span class="hljs-built_in">local</span> directory to view<br>- helm install:   upload the chart to Kubernetes<br>- helm list:      list releases of charts<br><br>Environment variables:<br><br>| Name                               | Description                                                                                                |<br>|------------------------------------|------------------------------------------------------------------------------------------------------------|<br>| <span class="hljs-variable">$HELM_CACHE_HOME</span>                   | <span class="hljs-built_in">set</span> an alternative location <span class="hljs-keyword">for</span> storing cached files.                                                      |<br>| <span class="hljs-variable">$HELM_CONFIG_HOME</span>                  | <span class="hljs-built_in">set</span> an alternative location <span class="hljs-keyword">for</span> storing Helm configuration.                                                |<br>| <span class="hljs-variable">$HELM_DATA_HOME</span>                    | <span class="hljs-built_in">set</span> an alternative location <span class="hljs-keyword">for</span> storing Helm data.                                                         |<br>| <span class="hljs-variable">$HELM_DEBUG</span>                        | indicate whether or not Helm is running <span class="hljs-keyword">in</span> Debug mode                                                      |<br>| <span class="hljs-variable">$HELM_DRIVER</span>                       | <span class="hljs-built_in">set</span> the backend storage driver. Values are: configmap, secret, memory, sql.                                |<br>| <span class="hljs-variable">$HELM_DRIVER_SQL_CONNECTION_STRING</span> | <span class="hljs-built_in">set</span> the connection string the SQL storage driver should use.                                               |<br>| <span class="hljs-variable">$HELM_MAX_HISTORY</span>                  | <span class="hljs-built_in">set</span> the maximum number of helm release <span class="hljs-built_in">history</span>.                                                            |<br>| <span class="hljs-variable">$HELM_NAMESPACE</span>                    | <span class="hljs-built_in">set</span> the namespace used <span class="hljs-keyword">for</span> the helm operations.                                                            |<br>| <span class="hljs-variable">$HELM_NO_PLUGINS</span>                   | <span class="hljs-built_in">disable</span> plugins. Set HELM_NO_PLUGINS=1 to <span class="hljs-built_in">disable</span> plugins.                                                 |<br>| <span class="hljs-variable">$HELM_PLUGINS</span>                      | <span class="hljs-built_in">set</span> the path to the plugins directory                                                                      |<br>| <span class="hljs-variable">$HELM_REGISTRY_CONFIG</span>              | <span class="hljs-built_in">set</span> the path to the registry config file.                                                                  |<br>| <span class="hljs-variable">$HELM_REPOSITORY_CACHE</span>             | <span class="hljs-built_in">set</span> the path to the repository cache directory                                                             |<br>| <span class="hljs-variable">$HELM_REPOSITORY_CONFIG</span>            | <span class="hljs-built_in">set</span> the path to the repositories file.                                                                     |<br>| <span class="hljs-variable">$KUBECONFIG</span>                        | <span class="hljs-built_in">set</span> an alternative Kubernetes configuration file (default <span class="hljs-string">&quot;~/.kube/config&quot;</span>)                                |<br>| <span class="hljs-variable">$HELM_KUBEAPISERVER</span>                | <span class="hljs-built_in">set</span> the Kubernetes API Server Endpoint <span class="hljs-keyword">for</span> authentication                                                  |<br>| <span class="hljs-variable">$HELM_KUBECAFILE</span>                   | <span class="hljs-built_in">set</span> the Kubernetes certificate authority file.                                                             |<br>| <span class="hljs-variable">$HELM_KUBEASGROUPS</span>                 | <span class="hljs-built_in">set</span> the Groups to use <span class="hljs-keyword">for</span> impersonation using a comma-separated list.                                      |<br>| <span class="hljs-variable">$HELM_KUBEASUSER</span>                   | <span class="hljs-built_in">set</span> the Username to impersonate <span class="hljs-keyword">for</span> the operation.                                                         |<br>| <span class="hljs-variable">$HELM_KUBECONTEXT</span>                  | <span class="hljs-built_in">set</span> the name of the kubeconfig context.                                                                    |<br>| <span class="hljs-variable">$HELM_KUBETOKEN</span>                    | <span class="hljs-built_in">set</span> the Bearer KubeToken used <span class="hljs-keyword">for</span> authentication.                                                          |<br>| <span class="hljs-variable">$HELM_KUBEINSECURE_SKIP_TLS_VERIFY</span> | indicate <span class="hljs-keyword">if</span> the Kubernetes API server<span class="hljs-string">&#x27;s certificate validation should be skipped (insecure)                |</span><br><span class="hljs-string">| $HELM_KUBETLS_SERVER_NAME          | set the server name used to validate the Kubernetes API server certificate                                 |</span><br><span class="hljs-string">| $HELM_BURST_LIMIT                  | set the default burst limit in the case the server contains many CRDs (default 100, -1 to disable)         |</span><br><span class="hljs-string">| $HELM_QPS                          | set the Queries Per Second in cases where a high number of calls exceed the option for higher burst values |</span><br><span class="hljs-string"></span><br><span class="hljs-string">Helm stores cache, configuration, and data based on the following configuration order:</span><br><span class="hljs-string"></span><br><span class="hljs-string">- If a HELM_*_HOME environment variable is set, it will be used</span><br><span class="hljs-string">- Otherwise, on systems supporting the XDG base directory specification, the XDG variables will be used</span><br><span class="hljs-string">- When no other location is set a default location will be used based on the operating system</span><br><span class="hljs-string"></span><br><span class="hljs-string">By default, the default directories depend on the Operating System. The defaults are listed below:</span><br><span class="hljs-string"></span><br><span class="hljs-string">| Operating System | Cache Path                | Configuration Path             | Data Path               |</span><br><span class="hljs-string">|------------------|---------------------------|--------------------------------|-------------------------|</span><br><span class="hljs-string">| Linux            | $HOME/.cache/helm         | $HOME/.config/helm             | $HOME/.local/share/helm |</span><br><span class="hljs-string">| macOS            | $HOME/Library/Caches/helm | $HOME/Library/Preferences/helm | $HOME/Library/helm      |</span><br><span class="hljs-string">| Windows          | %TEMP%\helm               | %APPDATA%\helm                 | %APPDATA%\helm          |</span><br><span class="hljs-string"></span><br><span class="hljs-string">Usage:</span><br><span class="hljs-string">  helm [command]</span><br><span class="hljs-string"></span><br><span class="hljs-string">Available Commands:</span><br><span class="hljs-string">  completion  generate autocompletion scripts for the specified shell</span><br><span class="hljs-string">  create      create a new chart with the given name</span><br><span class="hljs-string">  dependency  manage a chart&#x27;</span>s dependencies<br>  env         helm client environment information<br>  get         download extended information of a named release<br>  <span class="hljs-built_in">help</span>        Help about any <span class="hljs-built_in">command</span><br>  <span class="hljs-built_in">history</span>     fetch release <span class="hljs-built_in">history</span><br>  install     install a chart<br>  lint        examine a chart <span class="hljs-keyword">for</span> possible issues<br>  list        list releases<br>  package     package a chart directory into a chart archive<br>  plugin      install, list, or uninstall Helm plugins<br>  pull        download a chart from a repository and (optionally) unpack it <span class="hljs-keyword">in</span> <span class="hljs-built_in">local</span> directory<br>  push        push a chart to remote<br>  registry    login to or <span class="hljs-built_in">logout</span> from a registry<br>  repo        add, list, remove, update, and index chart repositories<br>  rollback    roll back a release to a previous revision<br>  search      search <span class="hljs-keyword">for</span> a keyword <span class="hljs-keyword">in</span> charts<br>  show        show information of a chart<br>  status      display the status of the named release<br>  template    locally render templates<br>  <span class="hljs-built_in">test</span>        run tests <span class="hljs-keyword">for</span> a release<br>  uninstall   uninstall a release<br>  upgrade     upgrade a release<br>  verify      verify that a chart at the given path has been signed and is valid<br>  version     <span class="hljs-built_in">print</span> the client version information<br><br>Flags:<br>      --burst-limit int                 client-side default throttling <span class="hljs-built_in">limit</span> (default 100)<br>      --debug                           <span class="hljs-built_in">enable</span> verbose output<br>  -h, --<span class="hljs-built_in">help</span>                            <span class="hljs-built_in">help</span> <span class="hljs-keyword">for</span> helm<br>      --kube-apiserver string           the address and the port <span class="hljs-keyword">for</span> the Kubernetes API server<br>      --kube-as-group stringArray       group to impersonate <span class="hljs-keyword">for</span> the operation, this flag can be repeated to specify multiple groups.<br>      --kube-as-user string             username to impersonate <span class="hljs-keyword">for</span> the operation<br>      --kube-ca-file string             the certificate authority file <span class="hljs-keyword">for</span> the Kubernetes API server connection<br>      --kube-context string             name of the kubeconfig context to use<br>      --kube-insecure-skip-tls-verify   <span class="hljs-keyword">if</span> <span class="hljs-literal">true</span>, the Kubernetes API server<span class="hljs-string">&#x27;s certificate will not be checked for validity. This will make your HTTPS connections insecure</span><br><span class="hljs-string">      --kube-tls-server-name string     server name to use for Kubernetes API server certificate validation. If it is not provided, the hostname used to contact the server is used</span><br><span class="hljs-string">      --kube-token string               bearer token used for authentication</span><br><span class="hljs-string">      --kubeconfig string               path to the kubeconfig file</span><br><span class="hljs-string">  -n, --namespace string                namespace scope for this request</span><br><span class="hljs-string">      --qps float32                     queries per second used when communicating with the Kubernetes API, not including bursting</span><br><span class="hljs-string">      --registry-config string          path to the registry config file (default &quot;/root/.config/helm/registry/config.json&quot;)</span><br><span class="hljs-string">      --repository-cache string         path to the directory containing cached repository indexes (default &quot;/root/.cache/helm/repository&quot;)</span><br><span class="hljs-string">      --repository-config string        path to the file containing repository names and URLs (default &quot;/root/.config/helm/repositories.yaml&quot;)</span><br><span class="hljs-string"></span><br><span class="hljs-string">Use &quot;helm [command] --help&quot; for more information about a command.</span><br><span class="hljs-string">root@k8s-master01:~# </span><br></code></pre></td></tr></table></figure>

<p>若输出上述内容，则说明安装成功</p>
<h2 id="6-2-安装kubernetes-dashboard"><a href="#6-2-安装kubernetes-dashboard" class="headerlink" title="6.2 安装kubernetes-dashboard"></a>6.2 安装kubernetes-dashboard</h2><h3 id="6-2-1-添加-kubernetes-dashboard-仓库"><a href="#6-2-1-添加-kubernetes-dashboard-仓库" class="headerlink" title="6.2.1 添加 kubernetes-dashboard 仓库"></a>6.2.1 添加 kubernetes-dashboard 仓库</h3><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">helm repo add kubernetes-dashboard https://kubernetes.github.io/dashboard/<br></code></pre></td></tr></table></figure>

<ul>
<li>/root/.cache/helm/repository/kubernetes-dashboard-charts.txt</li>
<li>/root/.cache/helm/repository/kubernetes-dashboard-index.yaml</li>
</ul>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~/.cache/helm/repository<span class="hljs-comment"># helm repo list</span><br><br>NAME                	URL                                    <br>kubernetes-dashboard	https://kubernetes.github.io/dashboard/<br>root@k8s-master01:~/.cache/helm/repository<span class="hljs-comment"># </span><br></code></pre></td></tr></table></figure>



<h3 id="6-2-2-使用-kubernetes-dashboard-Chart-部署名为“kubernetes-dashboard”-的-Helm-Release"><a href="#6-2-2-使用-kubernetes-dashboard-Chart-部署名为“kubernetes-dashboard”-的-Helm-Release" class="headerlink" title="6.2.2 使用 kubernetes-dashboard Chart 部署名为“kubernetes-dashboard” 的 Helm Release"></a>6.2.2 使用 kubernetes-dashboard Chart 部署名为“kubernetes-dashboard” 的 Helm Release</h3><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">helm upgrade --install kubernetes-dashboard kubernetes-dashboard/kubernetes-dashboard --create-namespace --namespace kubernetes-dashboard<br></code></pre></td></tr></table></figure>

<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># helm upgrade --install kubernetes-dashboard kubernetes-dashboard/kubernetes-dashboard --create-namespace --namespace kubernetes-dashboard</span><br><br>Release <span class="hljs-string">&quot;kubernetes-dashboard&quot;</span> does not exist. Installing it now.<br>NAME: kubernetes-dashboard<br>LAST DEPLOYED: Sun Mar 23 17:44:31 2025<br>NAMESPACE: kubernetes-dashboard<br>STATUS: deployed<br>REVISION: 1<br>TEST SUITE: None<br>NOTES:<br>*************************************************************************************************<br>*** PLEASE BE PATIENT: Kubernetes Dashboard may need a few minutes to get up and become ready ***<br>*************************************************************************************************<br><br>Congratulations! You have just installed Kubernetes Dashboard <span class="hljs-keyword">in</span> your cluster.<br><br>To access Dashboard run:<br>  kubectl -n kubernetes-dashboard port-forward svc/kubernetes-dashboard-kong-proxy 8443:443<br><br>NOTE: In <span class="hljs-keyword">case</span> port-forward <span class="hljs-built_in">command</span> does not work, make sure that kong service name is correct.<br>      Check the services <span class="hljs-keyword">in</span> Kubernetes Dashboard namespace using:<br>        kubectl -n kubernetes-dashboard get svc<br><br>Dashboard will be available at:<br>  https://localhost:8443<br>root@k8s-master01:~<span class="hljs-comment"># </span><br><br><br><br><span class="hljs-comment"># 注意：以下命令未做验证，后续可以测试确认</span><br><span class="hljs-comment"># 我的集群使用默认参数安装 kubernetes-dashboard-kong 出现异常 8444 端口占用</span><br><span class="hljs-comment"># 使用下面的命令进行安装，在安装时关闭kong.tls功能</span><br>root@k8s-master01:~<span class="hljs-comment"># helm upgrade --install kubernetes-dashboard kubernetes-dashboard/kubernetes-dashboard --namespace kubernetes-dashboard --set kong.admin.tls.enabled=false   # 原文链接：https://blog.csdn.net/qq_33921750/article/details/136668014</span><br></code></pre></td></tr></table></figure>

<h4 id="查看kubernetes-dashboard相关的pod的安装情况"><a href="#查看kubernetes-dashboard相关的pod的安装情况" class="headerlink" title="查看kubernetes-dashboard相关的pod的安装情况"></a>查看kubernetes-dashboard相关的pod的安装情况</h4><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># watch kubectl get pod -A</span><br><br>NAMESPACE              NAME                                                    READY   STATUS              RESTARTS   AGE<br>calico-apiserver       calico-apiserver-7b7bbf4d75-b77ph                       1/1     Running             0          18h<br>calico-apiserver       calico-apiserver-7b7bbf4d75-gqq5w                       1/1     Running             0          18h<br>calico-system          calico-kube-controllers-cf49d8944-6zv2z                 1/1     Running             0          18h<br>calico-system          calico-node-2nfvf                                       1/1     Running             0          18h<br>calico-system          calico-node-nxhvj                                       1/1     Running             0          18h<br>calico-system          calico-node-v9lp9                                       1/1     Running             0          18h<br>calico-system          calico-typha-7b6f98bc78-49bf5                           1/1     Running             0          18h<br>calico-system          calico-typha-7b6f98bc78-7vhd6                           1/1     Running             0          18h<br>calico-system          csi-node-driver-6nbvr                                   2/2     Running             0          18h<br>calico-system          csi-node-driver-9cqq5                                   2/2     Running             0          18h<br>calico-system          csi-node-driver-9pm4t                                   2/2     Running             0          18h<br>default                nginxweb-7c88f6c77-pck4f                                1/1     Running             0          17h<br>default                nginxweb-7c88f6c77-rv76n                                1/1     Running             0          17h<br>default                nginxweb-7c88f6c77-vb8xj                                1/1     Running             0          17h<br>kube-system            coredns-6766b7b6bb-6dtl7                                1/1     Running             0          21h<br>kube-system            coredns-6766b7b6bb-lrpw7                                1/1     Running             0          21h<br>kube-system            etcd-k8s-master01                                       1/1     Running             0          21h<br>kube-system            kube-apiserver-k8s-master01                             1/1     Running             0          21h<br>kube-system            kube-controller-manager-k8s-master01                    1/1     Running             0          21h<br>kube-system            kube-proxy-6g8dn                                        1/1     Running             0          21h<br>kube-system            kube-proxy-kmzv6                                        1/1     Running             0          19h<br>kube-system            kube-proxy-pj2t5                                        1/1     Running             0          19h<br>kube-system            kube-scheduler-k8s-master01                             1/1     Running             0          21h<br>kubernetes-dashboard   kubernetes-dashboard-api-c787c9d97-5rqvp                0/1     ContainerCreating   0          2m35s<br>kubernetes-dashboard   kubernetes-dashboard-auth-7ff7855689-vmltw              0/1     ContainerCreating   0          2m35s<br>kubernetes-dashboard   kubernetes-dashboard-kong-79867c9c48-txfql              0/1     Init:0/1            0          2m35s<br>kubernetes-dashboard   kubernetes-dashboard-metrics-scraper-84655b9bd8-mq8h7   0/1     ContainerCreating   0          2m35s<br>kubernetes-dashboard   kubernetes-dashboard-web-658946f7f9-crj69               0/1     ContainerCreating   0          2m35s<br>tigera-operator        tigera-operator-ccfc44587-vswlt                         1/1     Running             0          19h<br><br><br><br>root@k8s-master01:~/.cache/helm/repository<span class="hljs-comment"># kubectl get pod -A</span><br><br>NAMESPACE              NAME                                                    READY   STATUS    RESTARTS   AGE<br>calico-apiserver       calico-apiserver-7b7bbf4d75-b77ph                       1/1     Running   0          19h<br>calico-apiserver       calico-apiserver-7b7bbf4d75-gqq5w                       1/1     Running   0          19h<br>calico-system          calico-kube-controllers-cf49d8944-6zv2z                 1/1     Running   0          19h<br>calico-system          calico-node-2nfvf                                       1/1     Running   0          19h<br>calico-system          calico-node-nxhvj                                       1/1     Running   0          19h<br>calico-system          calico-node-v9lp9                                       1/1     Running   0          19h<br>calico-system          calico-typha-7b6f98bc78-49bf5                           1/1     Running   0          19h<br>calico-system          calico-typha-7b6f98bc78-7vhd6                           1/1     Running   0          19h<br>calico-system          csi-node-driver-6nbvr                                   2/2     Running   0          19h<br>calico-system          csi-node-driver-9cqq5                                   2/2     Running   0          19h<br>calico-system          csi-node-driver-9pm4t                                   2/2     Running   0          19h<br>default                nginxweb-7c88f6c77-pck4f                                1/1     Running   0          18h<br>default                nginxweb-7c88f6c77-rv76n                                1/1     Running   0          18h<br>default                nginxweb-7c88f6c77-vb8xj                                1/1     Running   0          18h<br>kube-system            coredns-6766b7b6bb-6dtl7                                1/1     Running   0          22h<br>kube-system            coredns-6766b7b6bb-lrpw7                                1/1     Running   0          22h<br>kube-system            etcd-k8s-master01                                       1/1     Running   0          22h<br>kube-system            kube-apiserver-k8s-master01                             1/1     Running   0          22h<br>kube-system            kube-controller-manager-k8s-master01                    1/1     Running   0          22h<br>kube-system            kube-proxy-6g8dn                                        1/1     Running   0          22h<br>kube-system            kube-proxy-kmzv6                                        1/1     Running   0          20h<br>kube-system            kube-proxy-pj2t5                                        1/1     Running   0          20h<br>kube-system            kube-scheduler-k8s-master01                             1/1     Running   0          22h<br>kubernetes-dashboard   kubernetes-dashboard-api-c787c9d97-5rqvp                1/1     Running   0          41m<br>kubernetes-dashboard   kubernetes-dashboard-auth-7ff7855689-vmltw              1/1     Running   0          41m<br>kubernetes-dashboard   kubernetes-dashboard-kong-79867c9c48-txfql              1/1     Running   0          41m<br>kubernetes-dashboard   kubernetes-dashboard-metrics-scraper-84655b9bd8-mq8h7   1/1     Running   0          41m<br>kubernetes-dashboard   kubernetes-dashboard-web-658946f7f9-crj69               1/1     Running   0          41m<br>tigera-operator        tigera-operator-ccfc44587-vswlt                         1/1     Running   0          20h<br></code></pre></td></tr></table></figure>


<h2 id="6-3-访问Dashboard前的准备"><a href="#6-3-访问Dashboard前的准备" class="headerlink" title="6.3 访问Dashboard前的准备"></a>6.3 访问Dashboard前的准备</h2><p>本节参考自官方文档 </p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/creating-sample-user.md">创建示例用户</a></li>
</ul>
<h3 id="6-3-1-创建示例用户-service-account"><a href="#6-3-1-创建示例用户-service-account" class="headerlink" title="6.3.1 创建示例用户 service-account"></a>6.3.1 创建示例用户 service-account</h3><p>创建dashboard-service-account.yaml文件</p>
<figure class="hljs highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ServiceAccount</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">admin-user</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">kubernetes-dashboard</span><br></code></pre></td></tr></table></figure>

<p>创建示例用户service-account命令</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubectl create -f dashboard-service-account.yaml</span><br></code></pre></td></tr></table></figure>


<h3 id="6-3-2-创建-ClusterRoleBinding"><a href="#6-3-2-创建-ClusterRoleBinding" class="headerlink" title="6.3.2 创建 ClusterRoleBinding"></a>6.3.2 创建 ClusterRoleBinding</h3><p>创建dashboard-cluster-role-binding.yaml文件</p>
<figure class="hljs highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">rbac.authorization.k8s.io/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterRoleBinding</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">admin-user</span><br><span class="hljs-attr">roleRef:</span><br>  <span class="hljs-attr">apiGroup:</span> <span class="hljs-string">rbac.authorization.k8s.io</span><br>  <span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterRole</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">cluster-admin</span><br><span class="hljs-attr">subjects:</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">kind:</span> <span class="hljs-string">ServiceAccount</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">admin-user</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">kubernetes-dashboard</span><br></code></pre></td></tr></table></figure>

<p>创建 ClusterRoleBinding</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建 ClusterRoleBinding</span><br>root@k8s-master01:~<span class="hljs-comment"># kubectl create -f dashboard-cluster-role-binding.yaml</span><br></code></pre></td></tr></table></figure>



<p>创建dashboard-admin-user.yaml 文件</p>
<figure class="hljs highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ServiceAccount</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">admin-user</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">kubernetes-dashboard</span><br><span class="hljs-meta">---</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">rbac.authorization.k8s.io/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterRoleBinding</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">admin-user</span><br><span class="hljs-attr">roleRef:</span><br>  <span class="hljs-attr">apiGroup:</span> <span class="hljs-string">rbac.authorization.k8s.io</span><br>  <span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterRole</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">cluster-admin</span><br><span class="hljs-attr">subjects:</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">kind:</span> <span class="hljs-string">ServiceAccount</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">admin-user</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">kubernetes-dashboard</span><br></code></pre></td></tr></table></figure>

<p>创建 ServiceAccount、ClusterRoleBinding</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~/.cache/helm/repository<span class="hljs-comment"># kubectl create -f /home/acanx/Dashboard/dashboard-admin-user.yaml</span><br><br>serviceaccount/admin-user created<br>clusterrolebinding.rbac.authorization.k8s.io/admin-user created<br></code></pre></td></tr></table></figure>

<h4 id="6-3-3-获取-ServiceAccount-的-Bearer-Token（短期访问的Token令牌）"><a href="#6-3-3-获取-ServiceAccount-的-Bearer-Token（短期访问的Token令牌）" class="headerlink" title="6.3.3 获取 ServiceAccount 的 Bearer Token（短期访问的Token令牌）"></a>6.3.3 获取 ServiceAccount 的 Bearer Token（短期访问的Token令牌）</h4><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 生成toke命令</span><br>root@k8s-master01:~/.cache/helm/repository<span class="hljs-comment"># kubectl -n kubernetes-dashboard create token admin-user</span><br><br>eyJhbGciOiJSUzI1NiIsImtpZCI6IjZPMURRc2RoVjl0YWJnUGU2RDVyLTRKblhybnhBaG1oS3JoVGNBTjh6UkkifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNzQyNzMxMjUwLCJpYXQiOjE3NDI3Mjc2NTAsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwianRpIjoiYWM2NWZiNTItNjViMi00ZmQ5LWI4OTctMzQ4NjI4N2UzYTlmIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsInNlcnZpY2VhY2NvdW50Ijp7Im5hbWUiOiJhZG1pbi11c2VyIiwidWlkIjoiNTBhNzgwZTYtODgzOC00ODI1LTk5ODktMzdhYTE0ZjM5ZjlkIn19LCJuYmYiOjE3NDI3Mjc2NTAsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlcm5ldGVzLWRhc2hib2FyZDphZG1pbi11c2VyIn0.9j0DPg2sKuVfODjWBxxXN3-r1GmXCGV58LULx81fiCwE5IdCp0LK4to0T35c55yiZjkW2fc7l01k6V7uKFTCGiJ3TDJn_1JJe5lZpWBWXSWoO_q-1nkMgniGPowieHEny3ZU1wm-Kk-nrr2CYZKhXShGDbRxpnjAPf1X0aB6lAzPt59GKVYpPaMYhcEBMMT_ASZrGLYrNR31UpbEXf2UP9Cgyh9m5vpA48FOJKZNt8FRq20egHWlWCw4a4PPb261w81vcWWB1bwTHIw-8CyNZjptrPVX06ch4DT-eX5No5jr8kh2gCiq--bARESxjgDjCebBS8O96NpKRWtQMQbFAQ<br></code></pre></td></tr></table></figure>

<p>获取到的toke是类似上述的字符串</p>
<h4 id="6-3-4-获取-ServiceAccount-的长期-Bearer-Token-（长期Token）"><a href="#6-3-4-获取-ServiceAccount-的长期-Bearer-Token-（长期Token）" class="headerlink" title="6.3.4 获取 ServiceAccount 的长期 Bearer Token （长期Token）"></a>6.3.4 获取 ServiceAccount 的长期 Bearer Token （长期Token）</h4><ul>
<li>创建dashboard-secret.yaml文件</li>
</ul>
<figure class="hljs highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Secret</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">admin-user</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">kubernetes-dashboard</span><br>  <span class="hljs-attr">annotations:</span><br>    <span class="hljs-attr">kubernetes.io/service-account.name:</span> <span class="hljs-string">&quot;admin-user&quot;</span>   <br><span class="hljs-attr">type:</span> <span class="hljs-string">kubernetes.io/service-account-token</span>  <br></code></pre></td></tr></table></figure>

<ul>
<li>获取 ServiceAccount 的长期 Bearer Token </li>
</ul>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建</span><br>root@k8s-master01:~<span class="hljs-comment"># kubectl create -f /home/acanx/Dashboard/dashboard-secret.yaml</span><br><br><span class="hljs-comment"># 获取对应的token令牌</span><br>root@k8s-master01:~<span class="hljs-comment"># kubectl get secret admin-user -n kubernetes-dashboard -o jsonpath=&quot;&#123;.data.token&#125;&quot; | base64 -d</span><br><br>eyJhbGciOiJSUzI1NiIsImtpZCI6IjZPMURRc2RoVjl0YWJnUGU2RDVyLTRKblhybnhBaG1oS3JoVGNBTjh6UkkifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiI1MGE3ODBlNi04ODM4LTQ4MjUtOTk4OS0zN2FhMTRmMzlmOWQiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.UG-iAoiCRrMeUePUi5ryn4tUOhFC94eTv_THHkrT_XZhUwC-IHqy9zkmi20tfQ-jnSnzy9_H9Z_auNw6Y4VtGB6pUs7srk6X9AIr4JDrScEVSMLbLXyCsdwGKbAaQJ8n2KA0J_pXibAiaQ77vCIDs9A4HXjn-T7GhoWEeswAcZF1N1SYbDyMxC-paMKb2I5CxL6pxtgWXuPCFkHxVnzeAT9Pswj-q0_Htr46U0Ieyo3dEBVGoOE4FA56UCYEnIfIv-OHXHytcxdaETrKl22EWleAYYENQy82qrdn8eCMK9ahOQyvCFORUbltJWP0hRkIRoMSGx1gD1DMHWMd6T9IRw<br></code></pre></td></tr></table></figure>



<h3 id="6-4-正式访问Dashboard"><a href="#6-4-正式访问Dashboard" class="headerlink" title="6.4 正式访问Dashboard"></a>6.4 正式访问Dashboard</h3><p>参考资料 <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq719779232/article/details/145212142">Kubernetes 集群中安装和配置 Kubernetes Dashboard</a></p>
<h3 id="6-4-1-方式一：使用-Port-Forwarding进行命令行代理"><a href="#6-4-1-方式一：使用-Port-Forwarding进行命令行代理" class="headerlink" title="6.4.1 方式一：使用 Port Forwarding进行命令行代理"></a>6.4.1 方式一：使用 Port Forwarding进行命令行代理</h3><p>Port Forwarding 是一种临时性的解决方案，它允许你通过本地机器上的端口直接访问集群内部的服务。这对于开发人员来说非常方便，因为他们不需要对外暴露服务即可进行调试或测试。</p>
<h4 id="6-4-1-1-开启访问"><a href="#6-4-1-1-开启访问" class="headerlink" title="6.4.1.1 开启访问"></a>6.4.1.1 开启访问</h4><p>通过 Port Forwarding 访问 Dashboard，需要先执行如下命令：</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl -n kubernetes-dashboard port-forward svc/kubernetes-dashboard 8443:443<br></code></pre></td></tr></table></figure>

<p>这将Dashboard在 <a target="_blank" rel="noopener" href="https://localhost:8443/">https://localhost:8443</a> 上可用。</p>
<h4 id="6-4-1-2-优点与缺点"><a href="#6-4-1-2-优点与缺点" class="headerlink" title="6.4.1.2 优点与缺点"></a>6.4.1.2 优点与缺点</h4><ul>
<li><p>这种方式的优点在于方法简单易用，无需更改任何集群配置，适合小规模测试或个人使用。但仅限于执行命令的本地机器，它是临时的，关闭终端后连接即断开，无法在其他机器上访问，并且每次使用时都需要手动开启端口转发。</p>
</li>
<li><p>也就是说，无法直接在集群外部访问，此方案不适合本次（集群外访问）实际访问场景，因此需要调整采用其他方案</p>
</li>
</ul>
<h3 id="6-4-2-方式二：修改服务类型为-NodePort"><a href="#6-4-2-方式二：修改服务类型为-NodePort" class="headerlink" title="6.4.2 方式二：修改服务类型为 NodePort"></a>6.4.2 方式二：修改服务类型为 NodePort</h3><h4 id="6-4-2-1-方法概述"><a href="#6-4-2-1-方法概述" class="headerlink" title="6.4.2.1 方法概述"></a>6.4.2.1 方法概述</h4><ul>
<li><p>NodePort 允许 Kubernetes 服务在各个集群节点的特定端口上对外暴露。这使得用户能够通过任意节点的 IP 地址和指定 NodePort 进行访问 Dashboard。（范围通常是 30000-32767），从而允许外部流量通过该端口进入集群并访问指定的服务。</p>
</li>
<li><p>也就是支持集群外部访问</p>
</li>
</ul>
<h4 id="6-4-2-2-开启访问"><a href="#6-4-2-2-开启访问" class="headerlink" title="6.4.2.2 开启访问"></a>6.4.2.2 开启访问</h4><p>编辑 Dashboard 的服务配置，将其类型更改为 NodePort：</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubectl patch svc kubernetes-dashboard-kong-proxy -n kubernetes-dashboard --type=&#x27;json&#x27; -p &#x27;[&#123;&quot;op&quot;:&quot;replace&quot;,&quot;path&quot;:&quot;/spec/type&quot;,&quot;value&quot;:&quot;NodePort&quot;&#125;]&#x27;</span><br><span class="hljs-comment"># TODO 若需要指定端口，可以指定一个固定的 nodePort：</span><br>root@k8s-master01:~<span class="hljs-comment"># kubectl patch svc kubernetes-dashboard-kong-proxy -n kubernetes-dashboard --type=&#x27;json&#x27; -p &#x27;[&#123;&quot;op&quot;:&quot;add&quot;,&quot;path&quot;:&quot;/spec/ports/0/nodePort&quot;,&quot;value&quot;:30000&#125;]&#x27;</span><br></code></pre></td></tr></table></figure>

<p>以下是实际操作及结果：</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubectl patch svc kubernetes-dashboard-kong-proxy -n kubernetes-dashboard --type=&#x27;json&#x27; -p &#x27;[&#123;&quot;op&quot;:&quot;replace&quot;,&quot;path&quot;:&quot;/spec/type&quot;,&quot;value&quot;:&quot;NodePort&quot;&#125;]&#x27;</span><br><br>service/kubernetes-dashboard-kong-proxy patched<br>root@k8s-master01:~<span class="hljs-comment"># kubectl get svc -A</span><br><br>NAMESPACE              NAME                                   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                  AGE<br>calico-apiserver       calico-api                             ClusterIP   10.109.219.68    &lt;none&gt;        443/TCP                  21h<br>calico-system          calico-kube-controllers-metrics        ClusterIP   None             &lt;none&gt;        9094/TCP                 20h<br>calico-system          calico-typha                           ClusterIP   10.104.149.150   &lt;none&gt;        5473/TCP                 21h<br>default                kubernetes                             ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP                  23h<br>default                nginxweb-service                       NodePort    10.106.65.218    &lt;none&gt;        80:30080/TCP             19h<br>kube-system            kube-dns                               ClusterIP   10.96.0.10       &lt;none&gt;        53/UDP,53/TCP,9153/TCP   23h<br>kubernetes-dashboard   kubernetes-dashboard-api               ClusterIP   10.104.42.174    &lt;none&gt;        8000/TCP                 128m<br>kubernetes-dashboard   kubernetes-dashboard-auth              ClusterIP   10.98.125.185    &lt;none&gt;        8000/TCP                 128m<br>kubernetes-dashboard   kubernetes-dashboard-external          NodePort    10.101.246.117   &lt;none&gt;        443:30011/TCP            7m8s<br>kubernetes-dashboard   kubernetes-dashboard-kong-proxy        NodePort    10.110.23.250    &lt;none&gt;        443:31094/TCP            128m<br>kubernetes-dashboard   kubernetes-dashboard-metrics-scraper   ClusterIP   10.102.211.164   &lt;none&gt;        8000/TCP                 128m<br>kubernetes-dashboard   kubernetes-dashboard-web               ClusterIP   10.107.236.126   &lt;none&gt;        8000/TCP                 128m<br><br><span class="hljs-comment"># 相关的命令1</span><br>root@k8s-master01:~<span class="hljs-comment"># kubectl get svc -A | grep dash</span><br><br>kubernetes-dashboard   kubernetes-dashboard-api               ClusterIP   10.104.42.174    &lt;none&gt;        8000/TCP                 166m<br>kubernetes-dashboard   kubernetes-dashboard-auth              ClusterIP   10.98.125.185    &lt;none&gt;        8000/TCP                 166m<br>kubernetes-dashboard   kubernetes-dashboard-external          NodePort    10.101.246.117   &lt;none&gt;        443:30011/TCP            44m<br>kubernetes-dashboard   kubernetes-dashboard-kong-proxy        NodePort    10.110.23.250    &lt;none&gt;        443:31094/TCP            166m<br>kubernetes-dashboard   kubernetes-dashboard-metrics-scraper   ClusterIP   10.102.211.164   &lt;none&gt;        8000/TCP                 166m<br>kubernetes-dashboard   kubernetes-dashboard-web               ClusterIP   10.107.236.126   &lt;none&gt;        8000/TCP                 166m<br><br><span class="hljs-comment"># 相关的命令2</span><br>root@k8s-master01:~<span class="hljs-comment"># kubectl get svc -A -n kubernetes-dashboard</span><br><br>NAMESPACE              NAME                                   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                  AGE<br>calico-apiserver       calico-api                             ClusterIP   10.109.219.68    &lt;none&gt;        443/TCP                  21h<br>calico-system          calico-kube-controllers-metrics        ClusterIP   None             &lt;none&gt;        9094/TCP                 21h<br>calico-system          calico-typha                           ClusterIP   10.104.149.150   &lt;none&gt;        5473/TCP                 21h<br>default                kubernetes                             ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP                  24h<br>default                nginxweb-service                       NodePort    10.106.65.218    &lt;none&gt;        80:30080/TCP             20h<br>kube-system            kube-dns                               ClusterIP   10.96.0.10       &lt;none&gt;        53/UDP,53/TCP,9153/TCP   24h<br>kubernetes-dashboard   kubernetes-dashboard-api               ClusterIP   10.104.42.174    &lt;none&gt;        8000/TCP                 165m<br>kubernetes-dashboard   kubernetes-dashboard-auth              ClusterIP   10.98.125.185    &lt;none&gt;        8000/TCP                 165m<br>kubernetes-dashboard   kubernetes-dashboard-external          NodePort    10.101.246.117   &lt;none&gt;        443:30011/TCP            44m<br>kubernetes-dashboard   kubernetes-dashboard-kong-proxy        NodePort    10.110.23.250    &lt;none&gt;        443:31094/TCP            165m<br>kubernetes-dashboard   kubernetes-dashboard-metrics-scraper   ClusterIP   10.102.211.164   &lt;none&gt;        8000/TCP                 165m<br>kubernetes-dashboard   kubernetes-dashboard-web               ClusterIP   10.107.236.126   &lt;none&gt;        8000/TCP                 165m<br><br></code></pre></td></tr></table></figure>



<p>如果显示您的连接不是私密连接，在当前页面用键盘输入thisisunsafe,不是在地址栏输入，就直接输入，页面即会自动刷新进入网页。不行就多输入几次，但是要确保输入是正确的。具体请查看这篇<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq719779232/article/details/144852360">博客</a></p>
<h4 id="6-4-2-4-访问Kubernetes-Dashboard-Web页面"><a href="#6-4-2-4-访问Kubernetes-Dashboard-Web页面" class="headerlink" title="6.4.2.4 访问Kubernetes Dashboard Web页面"></a>6.4.2.4 访问Kubernetes Dashboard Web页面</h4><p>可以看到随机开放了31094端口访问，浏览器中打开 <a target="_blank" rel="noopener" href="https://192.168.11.161:31094/">https://192.168.11.161:31094</a> 测试（忽略不是私密连接的提示后）可以正常打开，输入token后能够正常登录。</p>
<p><img src="/Node/imgs/03_02/Dashboard-Load.png" alt="Kubernetes-Dashboard-HomePage"></p>
<p><img src="/Node/imgs/03_02/Dashboard.png" alt="Kubernetes-Dashboard-HomePage"></p>
<h4 id="6-4-2-5-优点与缺点"><a href="#6-4-2-5-优点与缺点" class="headerlink" title="6.4.2.5 优点与缺点"></a>6.4.2.5 优点与缺点</h4><ul>
<li><p>这种方法一旦配置完成，只要集群存在就可以持续访问，提供了长期稳定的访问途径；同时可以直接通过任意节点 IP 加上指定端口号来访问服务，易于访问。</p>
</li>
<li><p>但是，它也带来了较高的安全风险，如果未正确配置防火墙规则，可能会导致服务被未经授权的人访问；</p>
</li>
<li><p>此外，还需要选择一个未被占用的端口，因此有一定的端口限制。</p>
</li>
</ul>
<h4 id="6-4-2-6-参考资料"><a href="#6-4-2-6-参考资料" class="headerlink" title="6.4.2.6 参考资料"></a>6.4.2.6 参考资料</h4><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/kubernetes/dashboard/blob/kubernetes-dashboard-7.11.1/README.md">kubernetes-dashboard-7.11.1/README.md</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/kubernetes/dashboard/tree/master/docs/user/accessing-dashboard">访问仪表板</a></li>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV15UsSeDEZA/">69.Kubernetes(k8s)手把手教程—部署Dashboard以图形化方式管理Kubernetes</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/renshengdezheli/p/17513879.html">Kubernetes(k8s) Web-UI界面(一)：部署和访问仪表板(Dashboard)</a></li>
<li><a target="_blank" rel="noopener" href="https://www.oiox.cn/index.php/archives/428/">二进制安装Kubernetes（k8s）v1.32.0</a></li>
</ul>
<h3 id="6-5-清理和后续步骤"><a href="#6-5-清理和后续步骤" class="headerlink" title="6.5 清理和后续步骤"></a>6.5 清理和后续步骤</h3><p>删除管理员ServiceAccount和ClusterRoleBinding。</p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># kubectl -n kubernetes-dashboard delete serviceaccount admin-user</span><br>root@k8s-master01:~<span class="hljs-comment"># kubectl -n kubernetes-dashboard delete clusterrolebinding admin-user</span><br></code></pre></td></tr></table></figure>

<p>了解有关如何在 Kubernetes 中授予/拒绝权限的更多信息，阅读官方<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/reference/access-authn-authz/authentication/">身份验证</a>和<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/reference/access-authn-authz/authorization/">授权</a>文档。</p>
<h1 id="七、-实际部署过程中遇到的问题"><a href="#七、-实际部署过程中遇到的问题" class="headerlink" title="七、 实际部署过程中遇到的问题"></a>七、 实际部署过程中遇到的问题</h1><h3 id="7-1-1操作系统重启后无法使用原账户登录"><a href="#7-1-1操作系统重启后无法使用原账户登录" class="headerlink" title="7.1.1操作系统重启后无法使用原账户登录"></a>7.1.1操作系统重启后无法使用原账户登录</h3><h3 id="7-1-2-kubeadm初始化失败，抛出错误"><a href="#7-1-2-kubeadm初始化失败，抛出错误" class="headerlink" title="7.1.2 kubeadm初始化失败，抛出错误"></a>7.1.2 kubeadm初始化失败，抛出错误</h3><h3 id="7-1-3-安装如遇到错误，需要修改配置，关闭kubelet"><a href="#7-1-3-安装如遇到错误，需要修改配置，关闭kubelet" class="headerlink" title="7.1.3 安装如遇到错误，需要修改配置，关闭kubelet"></a>7.1.3 安装如遇到错误，需要修改配置，关闭kubelet</h3><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># sudo rm -rf /etc/kubernetes/manifests/kube-apiserver.yaml</span><br>~<span class="hljs-comment"># sudo rm -rf /etc/kubernetes/manifests/kube-controller-manager.yaml</span><br>~<span class="hljs-comment"># sudo rm -rf /etc/kubernetes/manifests/kube-scheduler.yaml</span><br>~<span class="hljs-comment"># sudo rm -rf /etc/kubernetes/manifests/etcd.yaml</span><br><br>~<span class="hljs-comment"># sudo rm -rf /etc/kubernetes/manifests/kube-apiserver.yaml &amp;&amp; sudo rm -rf /etc/kubernetes/manifests/kube-controller-manager.yaml &amp;&amp; sudo rm -rf /etc/kubernetes/manifests/kube-scheduler.yaml &amp;&amp; sudo rm -rf /etc/kubernetes/manifests/etcd.yaml</span><br><br>sudo netstat -tulnp | grep :10250<br>sudo lsof -i :10250<br><br>sudo <span class="hljs-built_in">kill</span> 2832<br>sudo <span class="hljs-built_in">kill</span> -9 1234<br><br>~<span class="hljs-comment"># systemctl status kubelet</span><br>~<span class="hljs-comment"># systemctl stop kubelet</span><br></code></pre></td></tr></table></figure>

<h4 id="7-1-3-2-重新初始化-Kubernetes-集群"><a href="#7-1-3-2-重新初始化-Kubernetes-集群" class="headerlink" title="7.1.3.2 重新初始化 Kubernetes 集群"></a>7.1.3.2 重新初始化 Kubernetes 集群</h4><ul>
<li>步骤 1：重置 kubeadm\2：清理残留文件</li>
</ul>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># sudo kubeadm reset -f &amp;&amp; sudo rm -rf /etc/kubernetes /var/lib/etcd /var/lib/kubelet</span><br></code></pre></td></tr></table></figure>


<ul>
<li> <a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_51510236/article/details/136329885">https://blog.csdn.net/m0_51510236/article/details/136329885</a></li>
</ul>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">root@k8s-master01:~<span class="hljs-comment"># sudo kubeadm init \</span><br>--apiserver-advertise-address=192.168.11.161 \<br>--apiserver-cert-extra-sans=k8s-master01 \<br>--image-repository=registry.aliyuncs.com/google_containers \<br>--kubernetes-version=v1.32.3 \<br>--service-cidr=10.96.0.0/12 \<br>--pod-network-cidr=10.244.0.0/16 \<br>--cri-socket=unix:///run/containerd/containerd.sock \<br>--cgroup-driver=systemd \<br>--upload-certs \<br>--v=9<br></code></pre></td></tr></table></figure>




<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs bash">Mar 22 13:26:21 k8s-master01 kubelet[9760]: E0322 13:26:21.545465    9760 pod_workers.go:1301] <span class="hljs-string">&quot;Error syncing pod, skipping&quot;</span> err=<span class="hljs-string">&quot;failed to \&quot;CreatePodSandbox\&quot; for \&quot;kube-controller-manager-k8s-master01_kube-system(19dfb154dd163834eef61b7252703fed)\&quot; with CreatePodSandboxError: \&quot;Failed to create sandbox for pod \\\&quot;kube-controller-manager-k8s-master01_kube-system(19dfb154dd163834eef61b7252703fed)\\\&quot;: rpc error: code = Unknown desc = failed to start sandbox \\\&quot;623e76469b34076613d313938932728b1c6e63d0951c4c1a1a7563332c35b2e2\\\&quot;: failed to create containerd task: failed to create shim task: OCI runtime create failed: unable to retrieve OCI runtime error (open /run/containerd/io.containerd.runtime.v2.task/k8s.io/623e76469b34076613d313938932728b1c6e63d0951c4c1a1a7563332c35b2e2/log.json: no such file or directory): exec: \\\&quot;runc\\\&quot;: executable file not found in <span class="hljs-variable">$PATH</span>\&quot;&quot;</span> pod=<span class="hljs-string">&quot;kube-system/kube-controller-manager-k8s-master01&quot;</span> podUID=<span class="hljs-string">&quot;19dfb154dd163834eef61b7252703fed&quot;</span><br>Mar 22 13:26:23 k8s-master01 kubelet[9760]: E0322 13:26:23.120378    9760 controller.go:145] <span class="hljs-string">&quot;Failed to ensure lease exists, will retry&quot;</span> err=<span class="hljs-string">&quot;Get \&quot;https://192.168.11.161:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/k8s-master01?timeout=10s\&quot;: dial tcp 192.168.11.161:6443: connect: connection refused&quot;</span> interval=<span class="hljs-string">&quot;7s&quot;</span><br>Mar 22 13:26:23 k8s-master01 kubelet[9760]: I0322 13:26:23.327532    9760 kubelet_node_status.go:75] <span class="hljs-string">&quot;Attempting to register node&quot;</span> node=<span class="hljs-string">&quot;k8s-master01&quot;</span><br>Mar 22 13:26:23 k8s-master01 kubelet[9760]: E0322 13:26:23.328029    9760 kubelet_node_status.go:107] <span class="hljs-string">&quot;Unable to register node with API server&quot;</span> err=<span class="hljs-string">&quot;Post \&quot;https://192.168.11.161:6443/api/v1/nodes\&quot;: dial tcp 192.168.11.161:6443: connect: connection refused&quot;</span> node=<span class="hljs-string">&quot;k8s-master01&quot;</span><br>Mar 22 13:26:25 k8s-master01 kubelet[9760]: W0322 13:26:25.039914    9760 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSIDriver: Get <span class="hljs-string">&quot;https://192.168.11.161:6443/apis/storage.k8s.io/v1/csidrivers?limit=500&amp;resourceVersion=0&quot;</span>: dial tcp 192.168.11.161:6443: connect: connection refused<br>Mar 22 13:26:25 k8s-master01 kubelet[9760]: E0322 13:26:25.040030    9760 reflector.go:166] <span class="hljs-string">&quot;Unhandled Error&quot;</span> err=<span class="hljs-string">&quot;k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get \&quot;https://192.168.11.161:6443/apis/storage.k8s.io/v1/csidrivers?limit=500&amp;resourceVersion=0\&quot;: dial tcp 192.168.11.161:6443: connect: connection refused&quot;</span> logger=<span class="hljs-string">&quot;UnhandledError&quot;</span><br>Mar 22 13:26:26 k8s-master01 kubelet[9760]: W0322 13:26:26.039053    9760 reflector.go:569] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Service: Get <span class="hljs-string">&quot;https://192.168.11.161:6443/api/v1/services?fieldSelector=spec.clusterIP%21%3DNone&amp;limit=500&amp;resourceVersion=0&quot;</span>: dial tcp 192.168.11.161:6443: connect: connection refused<br>Mar 22 13:26:26 k8s-master01 kubelet[9760]: E0322 13:26:26.039171    9760 reflector.go:166] <span class="hljs-string">&quot;Unhandled Error&quot;</span> err=<span class="hljs-string">&quot;k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Service: failed to list *v1.Service: Get \&quot;https://192.168.11.161:6443/api/v1/services?fieldSelector=spec.clusterIP%21%3DNone&amp;limit=500&amp;resourceVersion=0\&quot;: dial tcp 192.168.11.161:6443: connect: connection refused&quot;</span> logger=<span class="hljs-string">&quot;UnhandledError&quot;</span><br>Mar 22 13:26:26 k8s-master01 kubelet[9760]: E0322 13:26:26.450839    9760 kubelet.go:3190] <span class="hljs-string">&quot;No need to create a mirror pod, since failed to get node info from the cluster&quot;</span> err=<span class="hljs-string">&quot;node \&quot;k8s-master01\&quot; not found&quot;</span> node=<span class="hljs-string">&quot;k8s-master01&quot;</span><br>Mar 22 13:26:26 k8s-master01 kubelet[9760]: E0322 13:26:26.451717    9760 dns.go:153] <span class="hljs-string">&quot;Nameserver limits exceeded&quot;</span> err=<span class="hljs-string">&quot;Nameserver limits were exceeded, some nameservers have been omitted, the applied nameserver line is: 119.29.29.29 114.114.114.114 8.8.8.8&quot;</span><br>Mar 22 13:26:26 k8s-master01 kubelet[9760]: E0322 13:26:26.547499    9760 log.go:32] <span class="hljs-string">&quot;RunPodSandbox from runtime service failed&quot;</span> err=<span class="hljs-string">&quot;rpc error: code = Unknown desc = failed to start sandbox \&quot;c54802a9d762ba695f68d28021ea9339eb8e9845d41161d6fa1f9bfb4d811c54\&quot;: failed to create containerd task: failed to create shim task: OCI runtime create failed: unable to retrieve OCI runtime error (open /run/containerd/io.containerd.runtime.v2.task/k8s.io/c54802a9d762ba695f68d28021ea9339eb8e9845d41161d6fa1f9bfb4d811c54/log.json: no such file or directory): exec: \&quot;runc\&quot;: executable file not found in <span class="hljs-variable">$PATH</span>&quot;</span><br>Mar 22 13:26:26 k8s-master01 kubelet[9760]: E0322 13:26:26.547575    9760 kuberuntime_sandbox.go:72] <span class="hljs-string">&quot;Failed to create sandbox for pod&quot;</span> err=<span class="hljs-string">&quot;rpc error: code = Unknown desc = failed to start sandbox \&quot;c54802a9d762ba695f68d28021ea9339eb8e9845d41161d6fa1f9bfb4d811c54\&quot;: failed to create containerd task: failed to create shim task: OCI runtime create failed: unable to retrieve OCI runtime error (open /run/containerd/io.containerd.runtime.v2.task/k8s.io/c54802a9d762ba695f68d28021ea9339eb8e9845d41161d6fa1f9bfb4d811c54/log.json: no such file or directory): exec: \&quot;runc\&quot;: executable file not found in <span class="hljs-variable">$PATH</span>&quot;</span> pod=<span class="hljs-string">&quot;kube-system/kube-apiserver-k8s-master01&quot;</span><br>Mar 22 13:26:26 k8s-master01 kubelet[9760]: E0322 13:26:26.547611    9760 kuberuntime_manager.go:1237] <span class="hljs-string">&quot;CreatePodSandbox for pod failed&quot;</span> err=<span class="hljs-string">&quot;rpc error: code = Unknown desc = failed to start sandbox \&quot;c54802a9d762ba695f68d28021ea9339eb8e9845d41161d6fa1f9bfb4d811c54\&quot;: failed to create containerd task: failed to create shim task: OCI runtime create failed: unable to retrieve OCI runtime error (open /run/containerd/io.containerd.runtime.v2.task/k8s.io/c54802a9d762ba695f68d28021ea9339eb8e9845d41161d6fa1f9bfb4d811c54/log.json: no such file or directory): exec: \&quot;runc\&quot;: executable file not found in <span class="hljs-variable">$PATH</span>&quot;</span> pod=<span class="hljs-string">&quot;kube-system/kube-apiserver-k8s-master01&quot;</span><br>Mar 22 13:26:26 k8s-master01 kubelet[9760]: E0322 13:26:26.547680    9760 pod_workers.go:1301] <span class="hljs-string">&quot;Error syncing pod, skipping&quot;</span> err=<span class="hljs-string">&quot;failed to \&quot;CreatePodSandbox\&quot; for \&quot;kube-apiserver-k8s-master01_kube-system(843638c9eef6e3d63d22d53c9d990887)\&quot; with CreatePodSandboxError: \&quot;Failed to create sandbox for pod \\\&quot;kube-apiserver-k8s-master01_kube-system(843638c9eef6e3d63d22d53c9d990887)\\\&quot;: rpc error: code = Unknown desc = failed to start sandbox \\\&quot;c54802a9d762ba695f68d28021ea9339eb8e9845d41161d6fa1f9bfb4d811c54\\\&quot;: failed to create containerd task: failed to create shim task: OCI runtime create failed: unable to retrieve OCI runtime error (open /run/containerd/io.containerd.runtime.v2.task/k8s.io/c54802a9d762ba695f68d28021ea9339eb8e9845d41161d6fa1f9bfb4d811c54/log.json: no such file or directory): exec: \\\&quot;runc\\\&quot;: executable file not found in <span class="hljs-variable">$PATH</span>\&quot;&quot;</span> pod=<span class="hljs-string">&quot;kube-system/kube-apiserver-k8s-master01&quot;</span> podUID=<span class="hljs-string">&quot;843638c9eef6e3d63d22d53c9d990887&quot;</span><br>Mar 22 13:26:29 k8s-master01 kubelet[9760]: E0322 13:26:29.498553    9760 eviction_manager.go:292] <span class="hljs-string">&quot;Eviction manager: failed to get summary stats&quot;</span> err=<span class="hljs-string">&quot;failed to get node info: node \&quot;k8s-master01\&quot; not found&quot;</span><br>Mar 22 13:26:30 k8s-master01 kubelet[9760]: E0322 13:26:30.122192    9760 controller.go:145] <span class="hljs-string">&quot;Failed to ensure lease exists, will retry&quot;</span> err=<span class="hljs-string">&quot;Get \&quot;https://192.168.11.161:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/k8s-master01?timeout=10s\&quot;: dial tcp 192.168.11.161:6443: connect: connection refused&quot;</span> interval=<span class="hljs-string">&quot;7s&quot;</span><br>Mar 22 13:26:30 k8s-master01 kubelet[9760]: I0322 13:26:30.329597    9760 kubelet_node_status.go:75] <span class="hljs-string">&quot;Attempting to register node&quot;</span> node=<span class="hljs-string">&quot;k8s-master01&quot;</span><br>Mar 22 13:26:30 k8s-master01 kubelet[9760]: E0322 13:26:30.330070    9760 kubelet_node_status.go:107] <span class="hljs-string">&quot;Unable to register node with API server&quot;</span> err=<span class="hljs-string">&quot;Post \&quot;https://192.168.11.161:6443/api/v1/nodes\&quot;: dial tcp 192.168.11.161:6443: connect: connection refused&quot;</span> node=<span class="hljs-string">&quot;k8s-master01&quot;</span><br>Mar 22 13:26:30 k8s-master01 kubelet[9760]: E0322 13:26:30.450085    9760 kubelet.go:3190] <span class="hljs-string">&quot;No need to create a mirror pod, since failed to get node info from the cluster&quot;</span> err=<span class="hljs-string">&quot;node \&quot;k8s-master01\&quot; not found&quot;</span> node=<span class="hljs-string">&quot;k8s-master01&quot;</span><br>Mar 22 13:26:30 k8s-master01 kubelet[9760]: E0322 13:26:30.450964    9760 dns.go:153] <span class="hljs-string">&quot;Nameserver limits exceeded&quot;</span> err=<span class="hljs-string">&quot;Nameserver limits were exceeded, some nameservers have been omitted, the applied nameserver line is: 119.29.29.29 114.114.114.114 8.8.8.8&quot;</span><br>Mar 22 13:26:30 k8s-master01 kubelet[9760]: E0322 13:26:30.548988    9760 log.go:32] <span class="hljs-string">&quot;RunPodSandbox from runtime service failed&quot;</span> err=<span class="hljs-string">&quot;rpc error: code = Unknown desc = failed to start sandbox \&quot;f8b4188ebe49ae964cfbbb1837c3899194dede9e323889d10636e4002993581b\&quot;: failed to create containerd task: failed to create shim task: OCI runtime create failed: unable to retrieve OCI runtime error (open /run/containerd/io.containerd.runtime.v2.task/k8s.io/f8b4188ebe49ae964cfbbb1837c3899194dede9e323889d10636e4002993581b/log.json: no such file or directory): exec: \&quot;runc\&quot;: executable file not found in <span class="hljs-variable">$PATH</span>&quot;</span><br>Mar 22 13:26:30 k8s-master01 kubelet[9760]: E0322 13:26:30.549096    9760 kuberuntime_sandbox.go:72] <span class="hljs-string">&quot;Failed to create sandbox for pod&quot;</span> err=<span class="hljs-string">&quot;rpc error: code = Unknown desc = failed to start sandbox \&quot;f8b4188ebe49ae964cfbbb1837c3899194dede9e323889d10636e4002993581b\&quot;: failed to create containerd task: failed to create shim task: OCI runtime create failed: unable to retrieve OCI runtime error (open /run/containerd/io.containerd.runtime.v2.task/k8s.io/f8b4188ebe49ae964cfbbb1837c3899194dede9e323889d10636e4002993581b/log.json: no such file or directory): exec: \&quot;runc\&quot;: executable file not found in <span class="hljs-variable">$PATH</span>&quot;</span> pod=<span class="hljs-string">&quot;kube-system/kube-scheduler-k8s-master01&quot;</span><br>Mar 22 13:26:30 k8s-master01 kubelet[9760]: E0322 13:26:30.549145    9760 kuberuntime_manager.go:1237] <span class="hljs-string">&quot;CreatePodSandbox for pod failed&quot;</span> err=<span class="hljs-string">&quot;rpc error: code = Unknown desc = failed to start sandbox \&quot;f8b4188ebe49ae964cfbbb1837c3899194dede9e323889d10636e4002993581b\&quot;: failed to create containerd task: failed to create shim task: OCI runtime create failed: unable to retrieve OCI runtime error (open /run/containerd/io.containerd.runtime.v2.task/k8s.io/f8b4188ebe49ae964cfbbb1837c3899194dede9e323889d10636e4002993581b/log.json: no such file or directory): exec: \&quot;runc\&quot;: executable file not found in <span class="hljs-variable">$PATH</span>&quot;</span> pod=<span class="hljs-string">&quot;kube-system/kube-scheduler-k8s-master01&quot;</span><br>Mar 22 13:26:30 k8s-master01 kubelet[9760]: E0322 13:26:30.549256    9760 pod_workers.go:1301] <span class="hljs-string">&quot;Error syncing pod, skipping&quot;</span> err=<span class="hljs-string">&quot;failed to \&quot;CreatePodSandbox\&quot; for \&quot;kube-scheduler-k8s-master01_kube-system(c7ec3024ac27f675ae60ec998a90ce85)\&quot; with CreatePodSandboxError: \&quot;Failed to create sandbox for pod \\\&quot;kube-scheduler-k8s-master01_kube-system(c7ec3024ac27f675ae60ec998a90ce85)\\\&quot;: rpc error: code = Unknown desc = failed to start sandbox \\\&quot;f8b4188ebe49ae964cfbbb1837c3899194dede9e323889d10636e4002993581b\\\&quot;: failed to create containerd task: failed to create shim task: OCI runtime create failed: unable to retrieve OCI runtime error (open /run/containerd/io.containerd.runtime.v2.task/k8s.io/f8b4188ebe49ae964cfbbb1837c3899194dede9e323889d10636e4002993581b/log.json: no such file or directory): exec: \\\&quot;runc\\\&quot;: executable file not found in <span class="hljs-variable">$PATH</span>\&quot;&quot;</span> pod=<span class="hljs-string">&quot;kube-system/kube-scheduler-k8s-master01&quot;</span> podUID=<span class="hljs-string">&quot;c7ec3024ac27f675ae60ec998a90ce85&quot;</span><br>Mar 22 13:26:31 k8s-master01 kubelet[9760]: E0322 13:26:31.073491    9760 event.go:368] <span class="hljs-string">&quot;Unable to write event (may retry after sleeping)&quot;</span> err=<span class="hljs-string">&quot;Post \&quot;https://192.168.11.161:6443/api/v1/namespaces/default/events\&quot;: dial tcp 192.168.11.161:6443: connect: connection refused&quot;</span> event=<span class="hljs-string">&quot;&amp;Event&#123;ObjectMeta:&#123;k8s-master01.182f0852158da106  default    0 0001-01-01 00:00:00 +0000 UTC &lt;nil&gt; &lt;nil&gt; map[] map[] [] [] []&#125;,InvolvedObject:ObjectReference&#123;Kind:Node,Namespace:,Name:k8s-master01,UID:k8s-master01,APIVersion:,ResourceVersion:,FieldPath:,&#125;,Reason:NodeHasSufficientPID,Message:Node k8s-master01 status is now: NodeHasSufficientPID,Source:EventSource&#123;Component:kubelet,Host:k8s-master01,&#125;,FirstTimestamp:2025-03-22 13:18:49.45761511 +0800 CST m=+0.101712151,LastTimestamp:2025-03-22 13:18:49.45761511 +0800 CST m=+0.101712151,Count:1,Type:Normal,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kubelet,ReportingInstance:k8s-master01,&#125;&quot;</span><br><br></code></pre></td></tr></table></figure>



<h3 id="7-1-4-Kubernets集群中部署calico网络插件时kubectl-get-pods-n-tigera-operator命令一直显示pod为ImagePullBackOff状态"><a href="#7-1-4-Kubernets集群中部署calico网络插件时kubectl-get-pods-n-tigera-operator命令一直显示pod为ImagePullBackOff状态" class="headerlink" title="7.1.4 Kubernets集群中部署calico网络插件时kubectl get pods -n tigera-operator命令一直显示pod为ImagePullBackOff状态"></a>7.1.4 Kubernets集群中部署calico网络插件时kubectl get pods -n tigera-operator命令一直显示pod为ImagePullBackOff状态</h3><figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># kubectl describe pod tigera-operator-ccfc44587-vswlt -n tigera-operator</span><br></code></pre></td></tr></table></figure>

<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># kubectl get pods -n tigera-operator -o wide</span><br></code></pre></td></tr></table></figure>

<p>查到“Failed to pull image “quay.io/tigera/operator:v1.36.5”: failed to pull and unpack image “quay.io/tigera/operator:v1.36.5”: failed to copy: read tcp 192.168.11.166:53828-&gt;23.60.96.137:443: read: connection reset by peer<br>”<br>需要手动拉取镜像或者增加镜像源（参考<a target="_blank" rel="noopener" href="https://blog.csdn.net/nxg810251/article/details/145170594%E4%B8%AD%E7%9A%84config.toml%E6%96%87%E4%BB%B6%E7%9A%84Line206~Line219%E4%B8%AD%E7%9A%84%E9%85%8D%E7%BD%AE%EF%BC%89">https://blog.csdn.net/nxg810251/article/details/145170594中的config.toml文件的Line206~Line219中的配置）</a> </p>
<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># sudo systemctl daemon-reload &amp;&amp; sudo systemctl restart containerd &amp;&amp; sudo systemctl restart kubelet</span><br></code></pre></td></tr></table></figure>

<figure class="hljs highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~<span class="hljs-comment"># systemctl daemon-reload &amp;&amp; systemctl restart containerd</span><br></code></pre></td></tr></table></figure>


<h4 id="7-1-4-3-参考："><a href="#7-1-4-3-参考：" class="headerlink" title="7.1.4.3 参考："></a>7.1.4.3 参考：</h4><ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_40444270/article/details/132543441">K8s的Pod出现Init:ImagePullBackOff问题的解决(以calico为例)</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/nxg810251/article/details/145170594">Kubernetes1.32版本搭建【超详细】</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_42434261/article/details/144539712">Kubernetes1.32版本搭建【极简版】</a></li>
</ul>
<h1 id="八、-总结"><a href="#八、-总结" class="headerlink" title="八、 总结"></a>八、 总结</h1><h2 id="8-1-可以继续优化的流程"><a href="#8-1-可以继续优化的流程" class="headerlink" title="8.1 可以继续优化的流程"></a>8.1 可以继续优化的流程</h2><h3 id="8-1-1-虚拟机镜像准备"><a href="#8-1-1-虚拟机镜像准备" class="headerlink" title="8.1.1 虚拟机镜像准备"></a>8.1.1 虚拟机镜像准备</h3><h3 id="8-1-2-containerd版本选择"><a href="#8-1-2-containerd版本选择" class="headerlink" title="8.1.2 containerd版本选择"></a>8.1.2 containerd版本选择</h3><h3 id="8-1-3-镜像源加速"><a href="#8-1-3-镜像源加速" class="headerlink" title="8.1.3 镜像源加速"></a>8.1.3 镜像源加速</h3><h3 id="8-1-4-网络配置"><a href="#8-1-4-网络配置" class="headerlink" title="8.1.4 网络配置"></a>8.1.4 网络配置</h3>
    </main>
    <footer class="post-footer">
      
      
      <div class="post-tags">
        
        
        
        
        <a class="post-tag button" href="/Blog/tags/Kubernetes/" style="background: #fc6423;" rel="tag"><i class="fas fa-tags"></i>Kubernetes</a>
        
        <a class="post-tag button" href="/Blog/tags/Ubuntu/" style="background: #a3bb54;" rel="tag"><i class="fas fa-tags"></i>Ubuntu</a>
        
        <a class="post-tag button" href="/Blog/tags/containerd/" style="background: #47aaff;" rel="tag"><i class="fas fa-tags"></i>containerd</a>
        
        <a class="post-tag button" href="/Blog/tags/Calico/" style="background: #fc6423;" rel="tag"><i class="fas fa-tags"></i>Calico</a>
        
        <a class="post-tag button" href="/Blog/tags/Helm/" style="background: #a3bb54;" rel="tag"><i class="fas fa-tags"></i>Helm</a>
        
        <a class="post-tag button" href="/Blog/tags/KubernetesDashboard/" style="background: #47aaff;" rel="tag"><i class="fas fa-tags"></i>KubernetesDashboard</a>
        
        <a class="post-tag button" href="/Blog/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/" style="background: #fc6423;" rel="tag"><i class="fas fa-tags"></i>云原生</a>
        
        <a class="post-tag button" href="/Blog/tags/K8S/" style="background: #a3bb54;" rel="tag"><i class="fas fa-tags"></i>K8S</a>
        
        <a class="post-tag button" href="/Blog/tags/PVE/" style="background: #47aaff;" rel="tag"><i class="fas fa-tags"></i>PVE</a>
        
      </div>
      
    </footer>
  </article>
  
  
<div class="reward" id="reward">
  <p>坚持原创技术分享，您的支持是我前进的动力！</p>
  <button id="reward-button" class="button" disable="enable">打赏</button>
  <div id="qr" class="qr" style="display: none;">
    
    
    
  </div>
</div>


  
  
  <div class="post-nav">
    <div class="post-nav-next post-nav-item">
      
      <a href="/Blog/2025/03/20/%E4%BD%BF%E7%94%A8MKDocs%E5%8F%91%E5%B8%83Markdown%E6%96%87%E6%A1%A3/" rel="next" title="使用MkDocs发布Markdown文档"><i class="fas fa-angle-left"></i><span class="nav-title">使用MkDocs发布Markdown文档</span></a>
      
    </div>
    <div class="post-nav-prev post-nav-item">
      
    </div>
  </div>
  
  
</div>

          </div>
          
          
          
<aside class="sidebar" id="sidebar" style="background: url(/Blog/images/sidebar_background.png);">
  
  <div class="search">
    <div class="form-group">
      <i class="fas fa-search"></i><input type="search" id="search-input" name="q" results="0" placeholder="搜索" class="form-control"/>
    </div>
  </div>
  <div class="search-result-box" id="search-result"></div>
  
  
<div class="info sidebar-item" id="info">
  
  <img class="author-avatar" src="/Blog/images/avatar.png" alt="ACANX">
  
  <h1 class="author-name">ACANX</h1>
  <h2 class="author-description"> 面朝大海的静态博客 <a target="_blank" rel="noopener" href="https://blog.acanx.com">另一个博客</a></h2>
  <div class="site-count">
    
    <div class="archives-count">
      <div class="site-count-title">归档</div>
      <div><a href="/Blog/archives/">31</a></div>
    </div>
    
    
    
    <span class="site-count-divider divider">|</span>
    
    <div class="categories-count">
      <div class="site-count-title">分类</div>
      <div><a href="/Blog/categories/">8</a></div>
    </div>
    
    
    
    <span class="site-count-divider divider">|</span>
    
    <div class="tags-count">
      <div class="site-count-title">标签</div>
      <div><a href="/Blog/tags/">41</a></div>
    </div>
    
  </div>
  
  <div class="rss">
    <a class="rss-link button sidebar-item" href="/Blog/atom.xml"><i class="fas fa-rss"></i>RSS</a>
  </div>
  
</div>


  <div class="sidebar-sticky">
    
    




<hr>
<div class="post-toc sidebar-item" id="toc-div">
  <div><i class="fas fa-list-ol"></i>文章目录</div>
  <div class="post-toc-content"><ol class="list-group toc"><li class="toc-item toc-level-1"><a class="list-group-item toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-text">前言</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#1-1-%E5%89%8D%E7%BD%AE%E5%87%86%E5%A4%87"><span class="toc-text">1.1 前置准备</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#1-1-1-%E5%89%8D%E7%BD%AE%E4%BE%9D%E8%B5%96%E8%BD%AF%E4%BB%B6%E5%8F%8A%E7%89%A9%E6%96%99%E5%87%86%E5%A4%87"><span class="toc-text">1.1.1 前置依赖软件及物料准备</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#1-1-2-K8S%E9%9B%86%E7%BE%A4%E7%BD%91%E7%BB%9CIP%E8%A7%84%E5%88%92"><span class="toc-text">1.1.2 K8S集群网络IP规划</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#1-1-3-%E4%B8%BB%E6%9C%BA%E7%A1%AC%E4%BB%B6%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E"><span class="toc-text">1.1.3 主机硬件配置说明</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#1-2-%E4%B8%BB%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="toc-text">1.2 主机系统基础环境准备</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#1-2-1-%E6%AD%A3%E5%BC%8F%E5%AE%89%E8%A3%85%E5%89%8D%EF%BC%8C%E7%B3%BB%E7%BB%9F%E9%9C%80%E8%A6%81%E6%A3%80%E6%9F%A5%E5%8F%8A%E5%87%86%E5%A4%87%E4%BB%A5%E4%B8%8B%E6%93%8D%E4%BD%9C"><span class="toc-text">1.2.1 正式安装前，系统需要检查及准备以下操作</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#1-2-2-%E5%BC%80%E5%90%AFSSH%E8%BF%9C%E7%A8%8B%E7%99%BB%E5%BD%95%E6%9C%8D%E5%8A%A1"><span class="toc-text">1.2.2 开启SSH远程登录服务</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#1-3-%E9%9B%86%E7%BE%A4%E4%B8%BB%E6%9C%BA%E9%85%8D%E7%BD%AE"><span class="toc-text">1.3 集群主机配置</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#1-3-1-%E4%B8%BB%E6%9C%BA%E5%90%8D%E9%85%8D%E7%BD%AE"><span class="toc-text">1.3.1 主机名配置</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#1-3-2-%E4%B8%BB%E6%9C%BAIP%E5%9C%B0%E5%9D%80%E9%85%8D%E7%BD%AE"><span class="toc-text">1.3.2 主机IP地址配置</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#1-3-3-%E4%B8%BB%E6%9C%BA%E5%90%8D%E4%B8%8EIP%E5%9C%B0%E5%9D%80%E8%A7%A3%E6%9E%90"><span class="toc-text">1.3.3 主机名与IP地址解析</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#1-3-4-%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5%E9%85%8D%E7%BD%AE"><span class="toc-text">1.3.4 时间同步配置</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#1-3-5-%E9%85%8D%E7%BD%AE%E5%86%85%E6%A0%B8%E8%BD%AC%E5%8F%91%E5%8F%8A%E7%BD%91%E6%A1%A5%E8%BF%87%E6%BB%A4"><span class="toc-text">1.3.5 配置内核转发及网桥过滤</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#1-3-6-%E5%AE%89%E8%A3%85ipset%E5%8F%8Aipvsadm"><span class="toc-text">1.3.6 安装ipset及ipvsadm</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#1-3-7-%E5%85%B3%E9%97%ADSWAP%E5%88%86%E5%8C%BA"><span class="toc-text">1.3.7 关闭SWAP分区</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="list-group-item toc-link" href="#%E4%BA%8C%E3%80%81K8S%E9%9B%86%E7%BE%A4%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6-Containerd-%E5%87%86%E5%A4%87"><span class="toc-text">二、K8S集群容器运行时 Containerd 准备</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#2-1-Containerd%E9%83%A8%E7%BD%B2%E6%96%87%E4%BB%B6%E8%8E%B7%E5%8F%96"><span class="toc-text">2.1 Containerd部署文件获取</span></a></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#2-2-Containerd%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%94%9F%E6%88%90%E5%B9%B6%E4%BF%AE%E6%94%B9"><span class="toc-text">2.2 Containerd配置文件生成并修改</span></a></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#2-3-Containerd%E5%90%AF%E5%8A%A8%E5%8F%8A%E5%BC%80%E6%9C%BA%E8%87%AA%E5%90%AF%E5%8A%A8"><span class="toc-text">2.3 Containerd启动及开机自启动</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="list-group-item toc-link" href="#%E4%B8%89%E3%80%81K8S%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2"><span class="toc-text">三、K8S集群部署</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#3-1-K8S%E9%9B%86%E7%BE%A4%E8%BD%AF%E4%BB%B6apt%E6%BA%90%E5%87%86%E5%A4%87"><span class="toc-text">3.1 K8S集群软件apt源准备</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#%E6%B7%BB%E5%8A%A0-Kubernetes-apt-%E4%BB%93%E5%BA%93"><span class="toc-text">添加 Kubernetes apt 仓库</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-4"><a class="list-group-item toc-link" href="#K8S%E7%A4%BE%E5%8C%BA"><span class="toc-text">K8S社区</span></a></li><li class="toc-item toc-level-4"><a class="list-group-item toc-link" href="#%E9%98%BF%E9%87%8C%E4%BA%91"><span class="toc-text">阿里云</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#3-2-K8S%E9%9B%86%E7%BE%A4%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E5%8F%8Akubelet%E9%85%8D%E7%BD%AE"><span class="toc-text">3.2 K8S集群软件安装及kubelet配置</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#3-2-1-k8s%E9%9B%86%E7%BE%A4%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85"><span class="toc-text">3.2.1 k8s集群软件安装</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#3-2-2-%E9%85%8D%E7%BD%AEkubelet"><span class="toc-text">3.2.2 配置kubelet</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#3-3-K8S%E9%9B%86%E7%BE%A4%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-text">3.3 K8S集群初始化</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#3-3-1-%E6%9F%A5%E7%9C%8B%E7%89%88%E6%9C%AC"><span class="toc-text">3.3.1 查看版本</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#3-3-2-%E7%94%9F%E6%88%90%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-text">3.3.2 生成部署配置文件</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-4"><a class="list-group-item toc-link" href="#%E4%BD%BF%E7%94%A8kubernetes%E7%A4%BE%E5%8C%BA%E7%89%88%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93"><span class="toc-text">使用kubernetes社区版容器镜像仓库</span></a></li><li class="toc-item toc-level-4"><a class="list-group-item toc-link" href="#%E4%BD%BF%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93"><span class="toc-text">使用阿里云容器镜像仓库</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#3-3-3-%E6%9F%A5%E7%9C%8B%E5%B9%B6%E4%B8%8B%E8%BD%BD%E9%95%9C%E5%83%8F"><span class="toc-text">3.3.3 查看并下载镜像</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-4"><a class="list-group-item toc-link" href="#%E6%9F%A5%E7%9C%8B%E5%8F%8A%E4%BD%BF%E7%94%A8Kubernetes%E7%A4%BE%E5%8C%BA%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93%E4%B8%8B%E8%BD%BD%E9%95%9C%E5%83%8F"><span class="toc-text">查看及使用Kubernetes社区镜像仓库下载镜像</span></a></li><li class="toc-item toc-level-4"><a class="list-group-item toc-link" href="#%E6%9F%A5%E7%9C%8B%E5%8F%8A%E4%BD%BF%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93%E4%B8%8B%E8%BD%BD%E9%95%9C%E5%83%8F"><span class="toc-text">查看及使用阿里云容器镜像仓库下载镜像</span></a></li><li class="toc-item toc-level-4"><a class="list-group-item toc-link" href="#%E6%9F%A5%E7%9C%8B%E4%B8%8B%E8%BD%BD%E7%9A%84%E9%95%9C%E5%83%8F"><span class="toc-text">查看下载的镜像</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#3-3-4-%E4%BD%BF%E7%94%A8%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%88%9D%E5%A7%8B%E5%8C%96K8S%E9%9B%86%E7%BE%A4"><span class="toc-text">3.3.4 使用部署配置文件初始化K8S集群</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#3-4-%E5%87%86%E5%A4%87kubectl%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-text">3.4 准备kubectl配置文件</span></a></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#3-5-%E5%B7%A5%E4%BD%9C%E8%8A%82%E7%82%B9%E5%8A%A0%E5%85%A5%E9%9B%86%E7%BE%A4"><span class="toc-text">3.5 工作节点加入集群</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#k8s-worker01%E8%8A%82%E7%82%B9%E5%8A%A0%E5%85%A5%E9%9B%86%E7%BE%A4"><span class="toc-text">k8s-worker01节点加入集群</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#k8s-worker02%E8%8A%82%E7%82%B9%E5%8A%A0%E5%85%A5%E9%9B%86%E7%BE%A4"><span class="toc-text">k8s-worker02节点加入集群</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#3-6-%E9%AA%8C%E8%AF%81K8S%E9%9B%86%E7%BE%A4%E8%8A%82%E7%82%B9%E6%98%AF%E5%90%A6%E5%8F%AF%E7%94%A8"><span class="toc-text">3.6 验证K8S集群节点是否可用</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="list-group-item toc-link" href="#%E5%9B%9B%E3%80%81K8S%E9%9B%86%E7%BE%A4%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6calico%E9%83%A8%E7%BD%B2"><span class="toc-text">四、K8S集群网络插件calico部署</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#4-1-%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E5%AE%89%E8%A3%85tigera-operator"><span class="toc-text">4.1 第一步：安装tigera-operator</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#4-1-1-%E8%BE%93%E5%87%BA%E5%86%85%E5%AE%B9%EF%BC%9A"><span class="toc-text">4.1.1 输出内容：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#4-2-%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A%E5%AE%89%E8%A3%85calico-system"><span class="toc-text">4.2 第二步：安装calico-system</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#4-2-1-%E4%B8%8B%E8%BD%BDcustom-resources-yaml"><span class="toc-text">4.2.1 下载custom-resources.yaml</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#4-2-2-%E4%BF%AE%E6%94%B9custom-resources-yaml%E4%B8%AD%E7%9A%84%E7%BD%91%E6%AE%B5cidr%E9%85%8D%E7%BD%AE"><span class="toc-text">4.2.2 修改custom-resources.yaml中的网段cidr配置</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#4-2-3-%E5%BA%94%E7%94%A8%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%EF%BC%8C%E8%BF%9B%E8%A1%8C%E9%83%A8%E7%BD%B2"><span class="toc-text">4.2.3 应用部署配置文件，进行部署</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#4-2-4-%E6%A3%80%E6%9F%A5calico%E5%AE%89%E8%A3%85%E7%BB%93%E6%9E%9C"><span class="toc-text">4.2.4 检查calico安装结果</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="list-group-item toc-link" href="#%E4%BA%94%E3%80%81%E9%83%A8%E7%BD%B2Nginx%E5%BA%94%E7%94%A8%E9%AA%8C%E8%AF%81K8S%E9%9B%86%E7%BE%A4%E5%8F%AF%E7%94%A8%E6%80%A7"><span class="toc-text">五、部署Nginx应用验证K8S集群可用性</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#5-1-%E9%85%8D%E7%BD%AENginxWeb%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6nginx-website-yaml"><span class="toc-text">5.1 配置NginxWeb部署配置文件nginx-website.yaml</span></a></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#5-2-%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4%E9%83%A8%E7%BD%B2nginx%E6%9C%8D%E5%8A%A1"><span class="toc-text">5.2 执行命令部署nginx服务</span></a></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#5-3-%E6%A3%80%E6%9F%A5%E9%83%A8%E7%BD%B2%E7%BB%93%E6%9E%9C"><span class="toc-text">5.3 检查部署结果</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#5-3-1-%E6%B5%8B%E8%AF%95K8S%E9%9B%86%E7%BE%A4%E5%86%85%E8%AE%BF%E9%97%AE"><span class="toc-text">5.3.1 测试K8S集群内访问</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#5-3-2-%E6%B5%8B%E8%AF%95%E9%9B%86%E7%BE%A4%E5%A4%96%E8%AE%BF%E9%97%AE"><span class="toc-text">5.3.2 测试集群外访问</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="list-group-item toc-link" href="#%E5%85%AD%E3%80%81-%E9%83%A8%E7%BD%B2Kubernetes-Dashboard%E5%BA%94%E7%94%A8"><span class="toc-text">六、 部署Kubernetes Dashboard应用</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#6-1-%E5%AE%89%E8%A3%85Helm"><span class="toc-text">6.1 安装Helm</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#6-1-1-Helm%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%B8%8B%E8%BD%BD"><span class="toc-text">6.1.1 Helm介绍及下载</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#6-1-2-Helm%E5%AE%89%E8%A3%85"><span class="toc-text">6.1.2 Helm安装</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#6-2-%E5%AE%89%E8%A3%85kubernetes-dashboard"><span class="toc-text">6.2 安装kubernetes-dashboard</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#6-2-1-%E6%B7%BB%E5%8A%A0-kubernetes-dashboard-%E4%BB%93%E5%BA%93"><span class="toc-text">6.2.1 添加 kubernetes-dashboard 仓库</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#6-2-2-%E4%BD%BF%E7%94%A8-kubernetes-dashboard-Chart-%E9%83%A8%E7%BD%B2%E5%90%8D%E4%B8%BA%E2%80%9Ckubernetes-dashboard%E2%80%9D-%E7%9A%84-Helm-Release"><span class="toc-text">6.2.2 使用 kubernetes-dashboard Chart 部署名为“kubernetes-dashboard” 的 Helm Release</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-4"><a class="list-group-item toc-link" href="#%E6%9F%A5%E7%9C%8Bkubernetes-dashboard%E7%9B%B8%E5%85%B3%E7%9A%84pod%E7%9A%84%E5%AE%89%E8%A3%85%E6%83%85%E5%86%B5"><span class="toc-text">查看kubernetes-dashboard相关的pod的安装情况</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#6-3-%E8%AE%BF%E9%97%AEDashboard%E5%89%8D%E7%9A%84%E5%87%86%E5%A4%87"><span class="toc-text">6.3 访问Dashboard前的准备</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#6-3-1-%E5%88%9B%E5%BB%BA%E7%A4%BA%E4%BE%8B%E7%94%A8%E6%88%B7-service-account"><span class="toc-text">6.3.1 创建示例用户 service-account</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#6-3-2-%E5%88%9B%E5%BB%BA-ClusterRoleBinding"><span class="toc-text">6.3.2 创建 ClusterRoleBinding</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-4"><a class="list-group-item toc-link" href="#6-3-3-%E8%8E%B7%E5%8F%96-ServiceAccount-%E7%9A%84-Bearer-Token%EF%BC%88%E7%9F%AD%E6%9C%9F%E8%AE%BF%E9%97%AE%E7%9A%84Token%E4%BB%A4%E7%89%8C%EF%BC%89"><span class="toc-text">6.3.3 获取 ServiceAccount 的 Bearer Token（短期访问的Token令牌）</span></a></li><li class="toc-item toc-level-4"><a class="list-group-item toc-link" href="#6-3-4-%E8%8E%B7%E5%8F%96-ServiceAccount-%E7%9A%84%E9%95%BF%E6%9C%9F-Bearer-Token-%EF%BC%88%E9%95%BF%E6%9C%9FToken%EF%BC%89"><span class="toc-text">6.3.4 获取 ServiceAccount 的长期 Bearer Token （长期Token）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#6-4-%E6%AD%A3%E5%BC%8F%E8%AE%BF%E9%97%AEDashboard"><span class="toc-text">6.4 正式访问Dashboard</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#6-4-1-%E6%96%B9%E5%BC%8F%E4%B8%80%EF%BC%9A%E4%BD%BF%E7%94%A8-Port-Forwarding%E8%BF%9B%E8%A1%8C%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%BB%A3%E7%90%86"><span class="toc-text">6.4.1 方式一：使用 Port Forwarding进行命令行代理</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-4"><a class="list-group-item toc-link" href="#6-4-1-1-%E5%BC%80%E5%90%AF%E8%AE%BF%E9%97%AE"><span class="toc-text">6.4.1.1 开启访问</span></a></li><li class="toc-item toc-level-4"><a class="list-group-item toc-link" href="#6-4-1-2-%E4%BC%98%E7%82%B9%E4%B8%8E%E7%BC%BA%E7%82%B9"><span class="toc-text">6.4.1.2 优点与缺点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#6-4-2-%E6%96%B9%E5%BC%8F%E4%BA%8C%EF%BC%9A%E4%BF%AE%E6%94%B9%E6%9C%8D%E5%8A%A1%E7%B1%BB%E5%9E%8B%E4%B8%BA-NodePort"><span class="toc-text">6.4.2 方式二：修改服务类型为 NodePort</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-4"><a class="list-group-item toc-link" href="#6-4-2-1-%E6%96%B9%E6%B3%95%E6%A6%82%E8%BF%B0"><span class="toc-text">6.4.2.1 方法概述</span></a></li><li class="toc-item toc-level-4"><a class="list-group-item toc-link" href="#6-4-2-2-%E5%BC%80%E5%90%AF%E8%AE%BF%E9%97%AE"><span class="toc-text">6.4.2.2 开启访问</span></a></li><li class="toc-item toc-level-4"><a class="list-group-item toc-link" href="#6-4-2-4-%E8%AE%BF%E9%97%AEKubernetes-Dashboard-Web%E9%A1%B5%E9%9D%A2"><span class="toc-text">6.4.2.4 访问Kubernetes Dashboard Web页面</span></a></li><li class="toc-item toc-level-4"><a class="list-group-item toc-link" href="#6-4-2-5-%E4%BC%98%E7%82%B9%E4%B8%8E%E7%BC%BA%E7%82%B9"><span class="toc-text">6.4.2.5 优点与缺点</span></a></li><li class="toc-item toc-level-4"><a class="list-group-item toc-link" href="#6-4-2-6-%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-text">6.4.2.6 参考资料</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#6-5-%E6%B8%85%E7%90%86%E5%92%8C%E5%90%8E%E7%BB%AD%E6%AD%A5%E9%AA%A4"><span class="toc-text">6.5 清理和后续步骤</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="list-group-item toc-link" href="#%E4%B8%83%E3%80%81-%E5%AE%9E%E9%99%85%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-text">七、 实际部署过程中遇到的问题</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#7-1-1%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E5%90%AF%E5%90%8E%E6%97%A0%E6%B3%95%E4%BD%BF%E7%94%A8%E5%8E%9F%E8%B4%A6%E6%88%B7%E7%99%BB%E5%BD%95"><span class="toc-text">7.1.1操作系统重启后无法使用原账户登录</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#7-1-2-kubeadm%E5%88%9D%E5%A7%8B%E5%8C%96%E5%A4%B1%E8%B4%A5%EF%BC%8C%E6%8A%9B%E5%87%BA%E9%94%99%E8%AF%AF"><span class="toc-text">7.1.2 kubeadm初始化失败，抛出错误</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#7-1-3-%E5%AE%89%E8%A3%85%E5%A6%82%E9%81%87%E5%88%B0%E9%94%99%E8%AF%AF%EF%BC%8C%E9%9C%80%E8%A6%81%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%EF%BC%8C%E5%85%B3%E9%97%ADkubelet"><span class="toc-text">7.1.3 安装如遇到错误，需要修改配置，关闭kubelet</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-4"><a class="list-group-item toc-link" href="#7-1-3-2-%E9%87%8D%E6%96%B0%E5%88%9D%E5%A7%8B%E5%8C%96-Kubernetes-%E9%9B%86%E7%BE%A4"><span class="toc-text">7.1.3.2 重新初始化 Kubernetes 集群</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#7-1-4-Kubernets%E9%9B%86%E7%BE%A4%E4%B8%AD%E9%83%A8%E7%BD%B2calico%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6%E6%97%B6kubectl-get-pods-n-tigera-operator%E5%91%BD%E4%BB%A4%E4%B8%80%E7%9B%B4%E6%98%BE%E7%A4%BApod%E4%B8%BAImagePullBackOff%E7%8A%B6%E6%80%81"><span class="toc-text">7.1.4 Kubernets集群中部署calico网络插件时kubectl get pods -n tigera-operator命令一直显示pod为ImagePullBackOff状态</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-4"><a class="list-group-item toc-link" href="#7-1-4-3-%E5%8F%82%E8%80%83%EF%BC%9A"><span class="toc-text">7.1.4.3 参考：</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="list-group-item toc-link" href="#%E5%85%AB%E3%80%81-%E6%80%BB%E7%BB%93"><span class="toc-text">八、 总结</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#8-1-%E5%8F%AF%E4%BB%A5%E7%BB%A7%E7%BB%AD%E4%BC%98%E5%8C%96%E7%9A%84%E6%B5%81%E7%A8%8B"><span class="toc-text">8.1 可以继续优化的流程</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#8-1-1-%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%95%9C%E5%83%8F%E5%87%86%E5%A4%87"><span class="toc-text">8.1.1 虚拟机镜像准备</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#8-1-2-containerd%E7%89%88%E6%9C%AC%E9%80%89%E6%8B%A9"><span class="toc-text">8.1.2 containerd版本选择</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#8-1-3-%E9%95%9C%E5%83%8F%E6%BA%90%E5%8A%A0%E9%80%9F"><span class="toc-text">8.1.3 镜像源加速</span></a></li><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#8-1-4-%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE"><span class="toc-text">8.1.4 网络配置</span></a></li></ol></li></ol></li></ol></div>
</div>



    
    
    
<hr>
<div class="social-link sidebar-item">
  <div><i class="far fa-address-card"></i>社交链接</p></div>
  <ul>
    
    <li><i class="fas fa-envelope"></i><a href="mailto:email@emailhost" target="_blank">E-Mail</a></li>
    
    <li><i class="fab fa-blog"></i><a href="https://blog.acanx.com/" target="_blank">Blog</a></li>
    
    <li><i class="fab fa-blog"></i><a href="https://acanx.github.io/Blog/" target="_blank">Blog</a></li>
    
    <li><i class="fab fa-weibo"></i><a href="https://weibo.com/" target="_blank">Weibo</a></li>
    
  </ul>
</div>


    
    
    
<hr>
<div class="blogroll sidebar-item">
  <div><i class="fas fa-link"></i>友情链接</div>
  <ul>
    
    <li><a href="https://acanx.github.io/Node/" target="_blank">Node</a></li>
    
  </ul>
</div>


    
  </div>
</aside>


          
        </div>
      </div>
    </main>
    
<footer id="footer" class="footer" style="background: #33363b;">
  <div class="container">
    <div class="back-to-top">
      <a id="back-to-top"><i class="fas fa-angle-double-up"></i></a>
    </div>
    <div class="footer-container">
      <div class="footer-left">
        <div class="copyright">
          <span class="author">ACANX</span><span class="year"><i class="far fa-copyright"></i>2025</span>
        </div>
        
        
<div class="busuanzi">
  <span id="busuanzi_container_site_pv"><i class="fas fa-eye"></i><span id="busuanzi_value_site_pv"></span></span><span id="busuanzi_container_site_uv"><i class="fas fa-user"></i><span id="busuanzi_value_site_uv"></span></span><span id="busuanzi_container_page_pv"><i class="far fa-file-alt"></i><span id="busuanzi_value_page_pv"></span></span>
</div>


        
      </div>
      <div class="footer-right">
        <div class="custom-info">
          
          托管于<i class="fab fa-github-alt"></i><a href="https://pages.github.com/" target="_blank">GitHub Pages</a>
          
        </div>
        <div class="powered-by">
          由 <a href="https://hexo.io/" target="_blank">Hexo</a> 强力驱动 | 主题 <a href="https://github.com/AlynxZhou/hexo-theme-aria/" target="_blank">ARIA</a>
        </div>
      </div>
    </div>
  </div>
</footer>


  </body>
</html>
